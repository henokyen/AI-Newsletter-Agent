Agree & Join LinkedIn 
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy). 
[ Skip to main content ](https://www.linkedin.com/posts/marie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3?utm_source=share&utm_medium=member_desktop/#main-content) [ LinkedIn ](https://www.linkedin.com/?trk=public_post_nav-header-logo)
  * [ Articles  ](https://www.linkedin.com/pulse/topics/home/?trk=public_post_guest_nav_menu_articles)
  * [ People  ](https://www.linkedin.com/pub/dir/+/+?trk=public_post_guest_nav_menu_people)
  * [ Learning  ](https://www.linkedin.com/learning/search?trk=public_post_guest_nav_menu_learning)
  * [ Jobs  ](https://www.linkedin.com/jobs/search?trk=public_post_guest_nav_menu_jobs)
  * [ Games  ](https://www.linkedin.com/games?trk=public_post_guest_nav_menu_games)


[ Join now ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_nav-header-join) [ Sign in ](https://www.linkedin.com/login?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&fromSignIn=true&trk=public_post_nav-header-signin)
#  Marie Stephen Leoâ€™s Post
[ ![View profile for Marie Stephen Leo](https://media.licdn.com/dms/image/v2/C4D03AQHQaF15RYIjkg/profile-displayphoto-shrink_400_400/profile-displayphoto-shrink_400_400/0/1516863550707?e=2147483647&v=beta&t=QpBdwMt10lYCFflgC3axi9LItsBO-f5iybKYF5kojoY) ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_feed-actor-image)
[ Marie Stephen Leo ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_feed-actor-name) Marie Stephen Leo is an Influencer
Data & AI @ Sephora | Linkedin Top Voice 
11mo  Edited 
  * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)


"I want to buy perfume less than $50" and "I want to buy perfume less than $100" are very close in vector space, but responding to the first question with a product that costs $80 creates a bad experience. Yet, this is a fundamental limitation of current vector similarity search-based Retrieval Augmented Generation (RAG) used in many LLM chatbots today. Thankfully, most vector DBs have implemented capabilities to filter the vector similarity search results using some metadata filters. For example, if you index a list of book descriptions in your vector DB, you might also attach metadata regarding the book's author, year of publication, genre, price, etc. So, the technology exists, but how do you extract the exact value to apply to these metadata filters from the user's natural language query? Enter the Self-Query Retriever from [LangChain](https://www.linkedin.com/company/langchain?trk=public_post-text) ([https://lnkd.in/gCis723F](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgCis723F&urlhash=AzmE&trk=public_post-text)) or [LlamaIndex](https://www.linkedin.com/company/llamaindex?trk=public_post-text) ([https://lnkd.in/gVUk-nFX](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgVUk-nFX&urlhash=JkVu&trk=public_post-text)) but is also straightforward to implement from scratch: 1. Construct a filter extraction prompt instructing an LLM to extract filter conditions and values in a standard format: e.g., "gt" for greater than, "eq" for equal, etc. See the detailed prompt here: [https://lnkd.in/gBBFHMX4](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgBBFHMX4&urlhash=sl-6&trk=public_post-text). Customising the examples to your exact metadata is very important to improve reliability! 2. Send this prompt and the user's question to an LLM and parse the response. The output is the extracted metadata filters in a generic vectorDB-agnostic format. For example, if your user's question is "I want to buy perfume less than $50," the output would look like "lt(price,50)." 3. Use Langchain's translators to convert it to your required vector DB format. A complete list of supported vector DBs is here: [https://lnkd.in/gq3x68vi](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgq3x68vi&urlhash=idT5&trk=public_post-text) 4. Finally, you can directly use the translated format in your vector DB query to filter the retrieved documents by the metadata fields. In reality, the self-query retriever adds latency to your app, so you'd want to use the fastest LLM possible. GPT3.5 is excellent for this task, but it may still not be fast enough, and I suspect a small, quantized, open-source model might be your best bet. Let me know in the comments if you have any suggestions for trying! For more details on the generic filter format to vectorDB-specific filter format, look at the code in the method visit_structured_query for the [Qdrant](https://de.linkedin.com/company/qdrant?trk=public_post-text) translator here: [https://lnkd.in/gY6hQtT9](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgY6hQtT9&urlhash=7DX5&trk=public_post-text) Edit: thereâ€™s discussion about using Knowledge Graphs in the comments that are worth checking out! Instead of converting userâ€™s natural language question into a vectorDB metadata filter query, youâ€™d convert it to a graph cypher query and execute against a graphDB. A very similar but slightly different concept to the gist of my post. Follow me for more tips on building successful ML and LLM products! Medium: [https://lnkd.in/g2jAJn5](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg2jAJn5&urlhash=dzUT&trk=public_post-text) X: [https://lnkd.in/g_JbKEkM](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg_JbKEkM&urlhash=7SSJ&trk=public_post-text) [#generativeai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#nlp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text) [#artificialintelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post-text) [#mlops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post-text) [#llmops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmops&trk=public_post-text)
[ 828  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_social-actions-reactions) [ 65 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment-cta)
Share 
  * Copy
  * LinkedIn
  * Facebook
  * Twitter


[ ](https://www.linkedin.com/in/kurtcagle?trk=public_post_comment_actor-image)
[ Kurt Cagle ](https://www.linkedin.com/in/kurtcagle?trk=public_post_comment_actor-name)
Editor In Chief @ The Cagle Report | Ontologist | Author | Iconoclast
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Or you query a knowledge graph that can do this calculation in its sleep via RAG and have it find EXACTLY what you need.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 16 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 17 Reactions 
[ ](https://ca.linkedin.com/in/dfindlay?trk=public_post_comment_actor-image)
[ Dave Findlay ](https://ca.linkedin.com/in/dfindlay?trk=public_post_comment_actor-name)
Data & Technology Leader
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


This seems like the most expensive (computationally and financially) way to solve this problem. A simple faceted search using tech that Sephor likely has licensed already would meet this need, be quicker to implement, more stable, cost less to maintain etc.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 2 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 3 Reactions 
[ ](https://es.linkedin.com/in/jacob-kratzsch?trk=public_post_comment_actor-image)
[ Jacob Kratzsch ](https://es.linkedin.com/in/jacob-kratzsch?trk=public_post_comment_actor-name)
Product @ IU | generative AI & LLMs | Purpose first, ego second
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


See this is what I don't get about these hype. We have such great technology now but just because it's great doesn't mean you now need to slot it on every single task. Everything gen AI. This actually leads to worse products as in your case. You don't need semantic search for a simple price filter. This is solved already. Drop-down or slider in standartized shop environment. Easy peasy. But now the customer has to type a full sentence and this needs to be interpreted by the AI correctly (less then 100% accuracy opposing to a logical system) and on top you now semantically search for a product that somehow relates to perfumes or price. So a perfume that is similar to "buying" "perfumes" or "price" instead of retrieving a full list. Likely unintended likely lower NPS than just Standart Filter it. But certainly higher complexity. There is absolutely no need for gen AI here. Pls let's not advocate for this kind of BS (pardon my language) and use this powerful tech for meaningful stuff.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 12 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 13 Reactions 
[ ](https://pk.linkedin.com/in/zubairahmed-ai?trk=public_post_comment_actor-image)
[ Zubair A. ](https://pk.linkedin.com/in/zubairahmed-ai?trk=public_post_comment_actor-name)
Founder & Lead AI Engineer Rewisdom AI - Enabling Businesses to Evolve with AI
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


I would generally avoid a round-trip to an LLM for filtering my vector database, perhaps until it's a small local LLM to help with latency and cost reduction across 1000s of user queries
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 4 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 5 Reactions 
[ ](https://in.linkedin.com/in/ritobrotoseth?trk=public_post_comment_actor-image)
[ Ritobroto Seth ](https://in.linkedin.com/in/ritobrotoseth?trk=public_post_comment_actor-name)
Engineering at Spotnana | Remote | Backend Developer | AI | Langchain | Java
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


For point 2, I would like to recommend the instructor library too. [https://github.com/jxnl/instructor](https://github.com/jxnl/instructor?trk=public_post_comment-text) It can convert text into a structured output by extracting the information based on the provided Pydantic model. I have played around with this library a bit and it worked pretty well in my case.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 5 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 6 Reactions 
[ ](https://uk.linkedin.com/in/jon-cooke-096bb0?trk=public_post_comment_actor-image)
[ Jon Cooke ](https://uk.linkedin.com/in/jon-cooke-096bb0?trk=public_post_comment_actor-name)
AI Digital Twins | Simulate business ideas in minutes with AI, real data and Data Object Graphs (DOGs) | Agent DOG Handler | Composable Enterprises with Data Product Pyramid | Data Product Workshop podcast co-host
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


[Marie Stephen Leo](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_comment-text) It strikes this is a classic natural language understanding Intent (intention behind user query) plus slot filling (key elements in user query) problem that could be achieved with two parts 1) Using a much smaller focused transformer encoder model (Small Language model) to create the intent and slots as a structured query object e.g. "I want to buy perfume less than $50" -> {"intent" : "buy", 'slots': { 'product': 'perfume', 'amount': '500', 'qualifier': '<' } } 2) Then transform the query to execute in a more traditional data store query (although one could use a vector store but one call also use a Graph or traditional DB ) E.g. [https://huggingface.co/ConvLab/bert-base-nlu](https://huggingface.co/ConvLab/bert-base-nlu?trk=public_post_comment-text) and [https://github.com/monologg/JointBERT](https://github.com/monologg/JointBERT?trk=public_post_comment-text) Thoughts?
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 2 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 3 Reactions 
[ ](https://www.linkedin.com/in/antonio-bray?trk=public_post_comment_actor-image)
[ Antonio Bray ](https://www.linkedin.com/in/antonio-bray?trk=public_post_comment_actor-name)
Founder, President, Chief Visionary Officer and Chief Technology Officer at AudioOne, Inc
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Beautiful . Definetly helpful. We use #langchain with #pinecone in both AudioOne FYI and [ASK](https://www.linkedin.com/company/u-ask-me?trk=public_post_comment-text) and store a lot of #metadata. This filter method will definitely come in hamdy, especially for news and podcasts specific dates/times/episodes and the creators/publishers behind them. Thanks [Marie Stephen Leo](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_comment-text). #langchain #vectordatabase #rag
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 1 Reaction ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 2 Reactions 
[ ](https://www.linkedin.com/in/juansequeda?trk=public_post_comment_actor-image)
[ Juan Sequeda ](https://www.linkedin.com/in/juansequeda?trk=public_post_comment_actor-name)
Principal Scientist & Head of AI Lab at data.world; co-host of Catalog & Cocktails, the honest, no-bs, non-salesy data podcast. Scientist. Interests: Knowledge Graphs, AI, LLMs, Data Integration & Data Catalogs
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


You are asking a structured question. Why do this in a similarity space? Users expect accurate answers. Take a look at using Knowledge Graphs as a means to answer questions over structured data. Weâ€™ve done a lot of research in this space [https://arxiv.org/abs/2311.07509](https://arxiv.org/abs/2311.07509?trk=public_post_comment-text) And to clarify, itâ€™s both vector db AND knowledge graphs. They work perfectly together. But we do need to understand the use cases for each one.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 26 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 27 Reactions 
[ ](https://in.linkedin.com/in/arun-rajesh-balakrishnan-6b113016?trk=public_post_comment_actor-image)
[ Arun Rajesh Balakrishnan ](https://in.linkedin.com/in/arun-rajesh-balakrishnan-6b113016?trk=public_post_comment_actor-name)
AI ML | Generative AI | Stress Testing |Collection Analytics | R/Python | Six Sigma BB
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


[Marie Stephen Leo](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_comment-text) any similar kind of example using Ollama models and FAISS / Chroma db ? 
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 2 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 3 Reactions 
[ ](https://www.linkedin.com/in/ryan-siegler-816207102?trk=public_post_comment_actor-image)
[ Ryan Siegler ](https://www.linkedin.com/in/ryan-siegler-816207102?trk=public_post_comment_actor-name)
GenAI | Vector DBs | Data Science | Emerging Technology Advocate
11mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Very insightful post! This is a great way to improve retrieval accuracy. Aside from creating filters on queries, have you seen any use-cases where the data/chunks to be ingested in a vector db are automatically tagged with relevant metadata?
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reply) [ 3 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_comment_reactions) 4 Reactions 
[ See more comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_see-more-comments)
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_feed-cta-banner-cta)
##  More Relevant Posts 
  * [](https://www.linkedin.com/posts/kmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr)
[ ](https://ca.linkedin.com/in/kmaurinjones?trk=public_post_feed-actor-image)
[ Kai Maurin-Jones, MDSCL ](https://ca.linkedin.com/in/kmaurinjones?trk=public_post_feed-actor-name)
Applied AI Developer @Klick | AI Engineer | Quantitative Linguistics | Forever Builder 
11mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Very interesting! I've encountered this type of issue with traditional semantic searching many times so this is a great proposal
[ ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_reshare_feed-actor-image)
[ Marie Stephen Leo ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_reshare_feed-actor-name) Marie Stephen Leo is an Influencer
Data & AI @ Sephora | Linkedin Top Voice 
11mo  Edited 
"I want to buy perfume less than $50" and "I want to buy perfume less than $100" are very close in vector space, but responding to the first question with a product that costs $80 creates a bad experience. Yet, this is a fundamental limitation of current vector similarity search-based Retrieval Augmented Generation (RAG) used in many LLM chatbots today. Thankfully, most vector DBs have implemented capabilities to filter the vector similarity search results using some metadata filters. For example, if you index a list of book descriptions in your vector DB, you might also attach metadata regarding the book's author, year of publication, genre, price, etc. So, the technology exists, but how do you extract the exact value to apply to these metadata filters from the user's natural language query? Enter the Self-Query Retriever from [LangChain](https://www.linkedin.com/company/langchain?trk=public_post_reshare-text) ([https://lnkd.in/gCis723F](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgCis723F&urlhash=AzmE&trk=public_post_reshare-text)) or [LlamaIndex](https://www.linkedin.com/company/llamaindex?trk=public_post_reshare-text) ([https://lnkd.in/gVUk-nFX](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgVUk-nFX&urlhash=JkVu&trk=public_post_reshare-text)) but is also straightforward to implement from scratch: 1. Construct a filter extraction prompt instructing an LLM to extract filter conditions and values in a standard format: e.g., "gt" for greater than, "eq" for equal, etc. See the detailed prompt here: [https://lnkd.in/gBBFHMX4](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgBBFHMX4&urlhash=sl-6&trk=public_post_reshare-text). Customising the examples to your exact metadata is very important to improve reliability! 2. Send this prompt and the user's question to an LLM and parse the response. The output is the extracted metadata filters in a generic vectorDB-agnostic format. For example, if your user's question is "I want to buy perfume less than $50," the output would look like "lt(price,50)." 3. Use Langchain's translators to convert it to your required vector DB format. A complete list of supported vector DBs is here: [https://lnkd.in/gq3x68vi](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgq3x68vi&urlhash=idT5&trk=public_post_reshare-text) 4. Finally, you can directly use the translated format in your vector DB query to filter the retrieved documents by the metadata fields. In reality, the self-query retriever adds latency to your app, so you'd want to use the fastest LLM possible. GPT3.5 is excellent for this task, but it may still not be fast enough, and I suspect a small, quantized, open-source model might be your best bet. Let me know in the comments if you have any suggestions for trying! For more details on the generic filter format to vectorDB-specific filter format, look at the code in the method visit_structured_query for the [Qdrant](https://de.linkedin.com/company/qdrant?trk=public_post_reshare-text) translator here: [https://lnkd.in/gY6hQtT9](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgY6hQtT9&urlhash=7DX5&trk=public_post_reshare-text) Edit: thereâ€™s discussion about using Knowledge Graphs in the comments that are worth checking out! Instead of converting userâ€™s natural language question into a vectorDB metadata filter query, youâ€™d convert it to a graph cypher query and execute against a graphDB. A very similar but slightly different concept to the gist of my post. Follow me for more tips on building successful ML and LLM products! Medium: [https://lnkd.in/g2jAJn5](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg2jAJn5&urlhash=dzUT&trk=public_post_reshare-text) X: [https://lnkd.in/g_JbKEkM](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg_JbKEkM&urlhash=7SSJ&trk=public_post_reshare-text) [#generativeai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post_reshare-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#nlp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post_reshare-text) [#artificialintelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post_reshare-text) [#mlops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post_reshare-text) [#llmops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmops&trk=public_post_reshare-text)
[ 7  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fkmaurinjones_very-interesting-ive-encountered-this-type-activity-7185259801860308992-ArCr&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/antonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32)
[ ](https://www.linkedin.com/in/antonio-bray?trk=public_post_feed-actor-image)
[ Antonio Bray ](https://www.linkedin.com/in/antonio-bray?trk=public_post_feed-actor-name)
Founder, President, Chief Visionary Officer and Chief Technology Officer at AudioOne, Inc 
11mo  Edited 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Beautiful . Definetly helpful. We use [#langchain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) with [#pinecone](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fpinecone&trk=public_post-text) in both AudioOne FYI and [ASK](https://www.linkedin.com/company/u-ask-me?trk=public_post-text) and store a lot of [#metadata](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmetadata&trk=public_post-text). This filter method will definitely come in hamdy, especially for news and podcasts specific dates/times/episodes and the creators/publishers behind them. Thanks [Marie Stephen Leo](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post-text). [#langchain](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Flangchain&trk=public_post-text) [#vectordatabase](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fvectordatabase&trk=public_post-text) [#rag](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Frag&trk=public_post-text)
[ ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_reshare_feed-actor-image)
[ Marie Stephen Leo ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_reshare_feed-actor-name) Marie Stephen Leo is an Influencer
Data & AI @ Sephora | Linkedin Top Voice 
11mo  Edited 
"I want to buy perfume less than $50" and "I want to buy perfume less than $100" are very close in vector space, but responding to the first question with a product that costs $80 creates a bad experience. Yet, this is a fundamental limitation of current vector similarity search-based Retrieval Augmented Generation (RAG) used in many LLM chatbots today. Thankfully, most vector DBs have implemented capabilities to filter the vector similarity search results using some metadata filters. For example, if you index a list of book descriptions in your vector DB, you might also attach metadata regarding the book's author, year of publication, genre, price, etc. So, the technology exists, but how do you extract the exact value to apply to these metadata filters from the user's natural language query? Enter the Self-Query Retriever from [LangChain](https://www.linkedin.com/company/langchain?trk=public_post_reshare-text) ([https://lnkd.in/gCis723F](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgCis723F&urlhash=AzmE&trk=public_post_reshare-text)) or [LlamaIndex](https://www.linkedin.com/company/llamaindex?trk=public_post_reshare-text) ([https://lnkd.in/gVUk-nFX](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgVUk-nFX&urlhash=JkVu&trk=public_post_reshare-text)) but is also straightforward to implement from scratch: 1. Construct a filter extraction prompt instructing an LLM to extract filter conditions and values in a standard format: e.g., "gt" for greater than, "eq" for equal, etc. See the detailed prompt here: [https://lnkd.in/gBBFHMX4](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgBBFHMX4&urlhash=sl-6&trk=public_post_reshare-text). Customising the examples to your exact metadata is very important to improve reliability! 2. Send this prompt and the user's question to an LLM and parse the response. The output is the extracted metadata filters in a generic vectorDB-agnostic format. For example, if your user's question is "I want to buy perfume less than $50," the output would look like "lt(price,50)." 3. Use Langchain's translators to convert it to your required vector DB format. A complete list of supported vector DBs is here: [https://lnkd.in/gq3x68vi](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgq3x68vi&urlhash=idT5&trk=public_post_reshare-text) 4. Finally, you can directly use the translated format in your vector DB query to filter the retrieved documents by the metadata fields. In reality, the self-query retriever adds latency to your app, so you'd want to use the fastest LLM possible. GPT3.5 is excellent for this task, but it may still not be fast enough, and I suspect a small, quantized, open-source model might be your best bet. Let me know in the comments if you have any suggestions for trying! For more details on the generic filter format to vectorDB-specific filter format, look at the code in the method visit_structured_query for the [Qdrant](https://de.linkedin.com/company/qdrant?trk=public_post_reshare-text) translator here: [https://lnkd.in/gY6hQtT9](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgY6hQtT9&urlhash=7DX5&trk=public_post_reshare-text) Edit: thereâ€™s discussion about using Knowledge Graphs in the comments that are worth checking out! Instead of converting userâ€™s natural language question into a vectorDB metadata filter query, youâ€™d convert it to a graph cypher query and execute against a graphDB. A very similar but slightly different concept to the gist of my post. Follow me for more tips on building successful ML and LLM products! Medium: [https://lnkd.in/g2jAJn5](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg2jAJn5&urlhash=dzUT&trk=public_post_reshare-text) X: [https://lnkd.in/g_JbKEkM](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg_JbKEkM&urlhash=7SSJ&trk=public_post_reshare-text) [#generativeai](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fgenerativeai&trk=public_post_reshare-text) [#llm](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#nlp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post_reshare-text) [#artificialintelligence](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fartificialintelligence&trk=public_post_reshare-text) [#mlops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmlops&trk=public_post_reshare-text) [#llmops](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmops&trk=public_post_reshare-text)
[ 3  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fantonio-bray_langchain-pinecone-metadata-activity-7185143124300550144-Fn32&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/research-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw)
[ ](https://au.linkedin.com/company/research-graph?trk=public_post_feed-actor-image)
[ Research Graph ](https://au.linkedin.com/company/research-graph?trk=public_post_feed-actor-name)
217 followers 
11mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fresearch-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning Article Link: [https://lnkd.in/g7MjvmZe](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fg7MjvmZe&urlhash=Onte&trk=public_post-text) GitHub Code: [https://pllava.github.io/](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fpllava%2Egithub%2Eio%2F&urlhash=nFl-&trk=public_post-text) What is this paper about? This work describes a novel model, PLLaVA, that enhances video understanding and captioning by fine-tuning image-language pre-trained models to the video data domain. The task at hand targets the development of video applications that will generate coherent natural language descriptions of video content. Why this study was deemed necessary? The study is based on the ground that current methods in video-language understanding need too much computational power and data, hence slowing the progress. The researchers wanted to find a simpler, less resource-intensive way to improve video understanding tasks. What is the innovation? The developed PLLaVA follows a pooling strategy to manage visual features effectively across video frames. This help to reducing the impact of overly main features and improving the quality of video description. How does it work (Methods)? PLLaVA extends prior image-language models by average pooling of the features temporally. It reduces the complexity and size of the data that each model has to handle and process, while maintaining crucial information. What were the key findings? Some of the major findings include that the model, PLLaVA, reaches state-of-the-art performance on several benchmarks for video question answering and captioning tasks. It has shown the best performance to date on several benchmark datasets for video question answering and captioning, clearly justifying the effectiveness of this pooling approach. The paper makes major contributions to the introduction of an efficient pooling method to video data and the successful adaptation of image-based models for video understanding, which significantly improves performance without needing a large amount of computational resources. What is the result? And what are some possible future tasks and limitations? Results show that PLLaVA produces accurate and dense video captions, outperforming all previous models such as Open-Sora GPT-4 for accuracy and detail. In so doing, the paper takes into account limitations that may include the dependence on the quality of video datasets and potential issues of scaling when applying the model to extremely large datasets. Reference: Xu, L., Zhao, Y., Zhou, D., Lin, Z., Ng, S. K., & Feng, J. (2024, April 25). PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning. [arXiv.org](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2FarXiv%2Eorg&urlhash=i0A8&trk=public_post-text). DOI: 10.48550/arXiv.2404.16994
[ 1  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fresearch-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fresearch-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fresearch-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fresearch-graph_pllava-parameter-free-llava-extension-from-activity-7191248138391687168-6Ukw&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/balaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2)
[ ](https://in.linkedin.com/in/balaramakrishna-kamma-8341k?trk=public_post_feed-actor-image)
[ Balaramakrishna Kamma ](https://in.linkedin.com/in/balaramakrishna-kamma-8341k?trk=public_post_feed-actor-name)
Programmer Analyst @ BILVANTIS TECHNOLOGIES | Full-stack Web Development, AI Integration 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbalaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
The image depicts a system for document retrieval and recommendation using an embedding model. The key components are: 1. Query 2. Encoding 3. Embedding model 4. Vector database 5. Similarity search 6. Final response Let's dive into each component in more detail: 1. Query: The query represents the user's search request or information need. This could be a keyword, phrase, or more complex natural language input. 2. Encoding: The query is first encoded, likely using some natural language processing technique, to convert the textual input into a numerical representation that can be processed by the embedding model. 3. Embedding model: The embedding model is a machine learning model that takes the encoded query and the textual content of documents as input and transforms them into high-dimensional vector representations. These vector embeddings capture the semantic meaning and relationships between the input text. 4. Vector database: The vector representations of the documents are stored in a specialized database optimized for efficient similarity search, known as a vector database. This allows for quick retrieval of the most relevant documents given a query vector. 5. Similarity search: Once the query has been encoded into a vector, the system performs a similarity search against the vectors stored in the database. This involves computing the distance or similarity between the query vector and each document vector, often using techniques like cosine similarity or Euclidean distance. 6. Final response: The result of the similarity search is a list of the most relevant documents, ranked by their similarity to the query. This final response is then returned to the user, providing them with the information they were seeking. The key advantages of this architecture are: -> Efficient information retrieval by leveraging vector embeddings and similarity search -> Ability to capture semantic relationships between text, beyond just keyword matching -> Scalability using a specialized vector database -> Potential for personalization and contextualization by incorporating user data into the embedding model 
[ 21  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbalaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbalaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbalaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbalaramakrishna-kamma-8341k_the-image-depicts-a-system-for-document-retrieval-activity-7288794946591985665-XYa2&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/olafkopp_seo-activity-7236634868745400321-bqlx)
[ ](https://de.linkedin.com/in/olafkopp?trk=public_post_feed-actor-image)
[ âœŒï¸Olaf Kopp â˜€ï¸ ](https://de.linkedin.com/in/olafkopp?trk=public_post_feed-actor-name)
Co Founder Aufgesang ğŸš€SEO+LLMO/GEO+Semantic Search+ E-E-A-TğŸ”Customer Journey Management+Content MarketingğŸ¤“Founder SEO Research SuiteğŸ based in ğŸ‡©ğŸ‡ª & ğŸ‡µğŸ‡¹ 
6mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
ğŸ”¥âœŒï¸The most important ranking methods for modern search enginesğŸ‘‡[#seo](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fseo&trk=public_post-text) Modern search engines can rank search results in different ways. In my new blogpost I introduce Vector Ranking, BM25, and Semantic Ranking as methods used in information retrieval and search engines to rank and retrieve documents or pieces of content based on their relevance to a query. Key Takeaways: BM25: A probabilistic algorithm known for its efficacy in traditional keyword matching and computational efficiency. ğŸ“Excels in scenarios demanding precision and recall with low computational overhead. Vector Ranking: Utilizes vector space models to assess document similarity through geometrical relationships. ğŸ“Effective for content-based recommendations and document similarity searches. Semantic Ranking: Employs advanced NLP models like BERT to understand context and semantics. ğŸ“Ideal for complex, natural language queries and understanding deeper meanings. Hybrid Ranking Solutions: Combines different models to cater to diverse query types, ensuring speed and accuracy. ğŸ“Balances speed with precision by using BM25 for quick filtering and semantic models for detailed contextual ranking. For more details read the full post here ğŸ‘‡ [https://lnkd.in/eahYqumD](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FeahYqumD&urlhash=TZPf&trk=public_post-text)
[ 26  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_social-actions-reactions) [ 1 Comment ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Folafkopp_seo-activity-7236634868745400321-bqlx&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/muhsabrys_%F0%9D%90%93%F0%9D%90%A1%F0%9D%90%9E-%F0%9D%90%86%F0%9D%90%9E%F0%9D%90%A7%F0%9D%90%9E%F0%9D%90%AB%F0%9D%90%9A%F0%9D%90%AD%F0%9D%90%A2%F0%9D%90%AF%F0%9D%90%9E-%F0%9D%90%8B%F0%9D%90%9E%F0%9D%90%B1%F0%9D%90%A2%F0%9D%90%9C%F0%9D%90%A8%F0%9D%90%A7-activity-7287653098221641728-YSme)
[ ](https://www.linkedin.com/in/muhsabrys?trk=public_post_feed-actor-image)
[ Muhammad S. Abdo ](https://www.linkedin.com/in/muhsabrys?trk=public_post_feed-actor-name)
AI4Language | NLP Researcher | Dual PhD Student in Computational Linguistics and Middle Eastern Languages and Cultures 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmuhsabrys_%25F0%259D%2590%2593%25F0%259D%2590%25A1%25F0%259D%2590%259E-%25F0%259D%2590%2586%25F0%259D%2590%259E%25F0%259D%2590%25A7%25F0%259D%2590%259E%25F0%259D%2590%25AB%25F0%259D%2590%259A%25F0%259D%2590%25AD%25F0%259D%2590%25A2%25F0%259D%2590%25AF%25F0%259D%2590%259E-%25F0%259D%2590%258B%25F0%259D%2590%259E%25F0%259D%2590%25B1%25F0%259D%2590%25A2%25F0%259D%2590%259C%25F0%259D%2590%25A8%25F0%259D%2590%25A7-activity-7287653098221641728-YSme&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
ğ“ğ¡ğ ğ†ğğ§ğğ«ğšğ­ğ¢ğ¯ğ ğ‹ğğ±ğ¢ğœğ¨ğ§ ğ“ğ¡ğğ¨ğ«ğ² (ğ†ğ‹ğ“), which was posited by James Pustejovsky (1991), is a framework for modeling word meaning in a manner that goes beyond traditional lexicons. The theory addresses how words can exhibit flexible meanings in different contexts while maintaining systematic behavior. Put simply, GLT aims to explain how we can "give an infinite number of senses to words with finite means". ğ—ğ—²ğ˜† ğ—˜ğ—¹ğ—²ğ—ºğ—²ğ—»ğ˜ğ˜€ ğ—¼ğ—³ ğ—šğ—Ÿğ—§: 1. ğ—”ğ—¿ğ—´ğ˜‚ğ—ºğ—²ğ—»ğ˜ ğ—¦ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²: Defines the number and nature of arguments associated with a lexical item, such as subjects and objects. For instance, the verb "eat" necessitates an agent (the eater) and a theme (the food). 2. ğ—˜ğ˜ƒğ—²ğ—»ğ˜ ğ—¦ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²: Unveils the internal composition of events that are denoted by verbs or predicates. For example, the verb "build" entails a process leading to a resultant state. 3. ğ—¤ğ˜‚ğ—®ğ—¹ğ—¶ğ—® ğ—¦ğ˜ğ—¿ğ˜‚ğ—°ğ˜ğ˜‚ğ—¿ğ—²: Encompasses four distinct "qualia roles" that elucidate the semantic essence of a word; these are: - ğ˜¾ğ’ğ™£ğ’”ğ™©ğ’Šğ™©ğ’–ğ™©ğ’Šğ™«ğ’†: Defines the material composition, like a book being made of paper. - ğ™ğ’ğ™§ğ’ğ™–ğ’: Identifies the categorical or typological aspect, as seen in a knife being a cutting tool. - ğ‘»ğ™šğ’ğ™ğ’„: Explores the purpose or function, such as a knife's role in cutting. - ğ˜¼ğ’ˆğ™šğ’ğ™©ğ’Šğ™«ğ’†: Traces the origin or creator, like an author writing a book. 4. ğ—Ÿğ—²ğ˜…ğ—¶ğ—°ğ—®ğ—¹ ğ—œğ—»ğ—µğ—²ğ—¿ğ—¶ğ˜ğ—®ğ—»ğ—°ğ—²: Establishes the hierarchical relationships between lexical items, enabling the sharing of attributes. GLT Applications: - ğ—£ğ—¼ğ—¹ğ˜†ğ˜€ğ—²ğ—ºğ˜†: The word "book" can signify a physical object or its contents. GLT clarifies this through Qualia Structure, where the constitutive role pertains to the physical entity and the formal role to its content. - ğ—–ğ—¼ğ—²ğ—¿ğ—°ğ—¶ğ—¼ğ—»: In "The student finished the book," the verb "finish" typically pertains to events. Here, "book" is coerced to imply "reading the book" by considering its telic. - ğ— ğ—²ğ˜ğ—¼ğ—»ğ˜†ğ—ºğ˜†: The turkey sandwich is waiting for his check: The phrase turkey sandwich refers to a customer who ordered it, based on context and the telic role (the function of a sandwich in a restaurant context). GLT is widely used in Natural Language Processing tasks to model lexical semantics dynamically, as in: ğ‘¾ğ’ğ’“ğ’… ğ‘ºğ’†ğ’ğ’”ğ’† ğ‘«ğ’Šğ’”ğ’‚ğ’ğ’ƒğ’Šğ’ˆğ’–ğ’‚ğ’•ğ’Šğ’ğ’ (ğ‘¾ğ‘ºğ‘«): Disambiguating meanings based on Qualia roles and context. ğ‘ºğ’†ğ’ğ’‚ğ’ğ’•ğ’Šğ’„ ğ‘¹ğ’ğ’ğ’† ğ‘³ğ’‚ğ’ƒğ’†ğ’ğ’Šğ’ğ’ˆ (ğ‘ºğ‘¹ğ‘³): Identifying arguments and their roles in predicates. Reference Book: [https://lnkd.in/gi3KMPWz](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2Fgi3KMPWz&urlhash=X7Wb&trk=public_post-text) ACL Article: [https://lnkd.in/gP6GTsDa](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgP6GTsDa&urlhash=amKZ&trk=public_post-text)
[ 21  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmuhsabrys_%25F0%259D%2590%2593%25F0%259D%2590%25A1%25F0%259D%2590%259E-%25F0%259D%2590%2586%25F0%259D%2590%259E%25F0%259D%2590%25A7%25F0%259D%2590%259E%25F0%259D%2590%25AB%25F0%259D%2590%259A%25F0%259D%2590%25AD%25F0%259D%2590%25A2%25F0%259D%2590%25AF%25F0%259D%2590%259E-%25F0%259D%2590%258B%25F0%259D%2590%259E%25F0%259D%2590%25B1%25F0%259D%2590%25A2%25F0%259D%2590%259C%25F0%259D%2590%25A8%25F0%259D%2590%25A7-activity-7287653098221641728-YSme&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmuhsabrys_%25F0%259D%2590%2593%25F0%259D%2590%25A1%25F0%259D%2590%259E-%25F0%259D%2590%2586%25F0%259D%2590%259E%25F0%259D%2590%25A7%25F0%259D%2590%259E%25F0%259D%2590%25AB%25F0%259D%2590%259A%25F0%259D%2590%25AD%25F0%259D%2590%25A2%25F0%259D%2590%25AF%25F0%259D%2590%259E-%25F0%259D%2590%258B%25F0%259D%2590%259E%25F0%259D%2590%25B1%25F0%259D%2590%25A2%25F0%259D%2590%259C%25F0%259D%2590%25A8%25F0%259D%2590%25A7-activity-7287653098221641728-YSme&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmuhsabrys_%25F0%259D%2590%2593%25F0%259D%2590%25A1%25F0%259D%2590%259E-%25F0%259D%2590%2586%25F0%259D%2590%259E%25F0%259D%2590%25A7%25F0%259D%2590%259E%25F0%259D%2590%25AB%25F0%259D%2590%259A%25F0%259D%2590%25AD%25F0%259D%2590%25A2%25F0%259D%2590%25AF%25F0%259D%2590%259E-%25F0%259D%2590%258B%25F0%259D%2590%259E%25F0%259D%2590%25B1%25F0%259D%2590%25A2%25F0%259D%2590%259C%25F0%259D%2590%25A8%25F0%259D%2590%25A7-activity-7287653098221641728-YSme&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmuhsabrys_%25F0%259D%2590%2593%25F0%259D%2590%25A1%25F0%259D%2590%259E-%25F0%259D%2590%2586%25F0%259D%2590%259E%25F0%259D%2590%25A7%25F0%259D%2590%259E%25F0%259D%2590%25AB%25F0%259D%2590%259A%25F0%259D%2590%25AD%25F0%259D%2590%25A2%25F0%259D%2590%25AF%25F0%259D%2590%259E-%25F0%259D%2590%258B%25F0%259D%2590%259E%25F0%259D%2590%25B1%25F0%259D%2590%25A2%25F0%259D%2590%259C%25F0%259D%2590%25A8%25F0%259D%2590%25A7-activity-7287653098221641728-YSme&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/abdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a)
[ ](https://in.linkedin.com/in/abdul-rauf-112612155?trk=public_post_feed-actor-image)
[ Abdul Rauf ](https://in.linkedin.com/in/abdul-rauf-112612155?trk=public_post_feed-actor-name)
AI & ML Enthusiast || LLMs || Chatbots || RAG || NLP || MLOps || Data Science || Msc Data Science from AMU . 
11mo  Edited 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fabdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
ğŸ” Excited to share our latest project(Movie Verse)! that I have developed with my partner Vaishnavi Singh. We've developed an advanced search engine algorithm tailored for retrieving subtitles based on user queries. Our approach combines natural language processing and machine learning techniques to enhance relevance and accuracy of search results. Let's dive into the details: ğŸ“š Semantic Search Engines: Keyword-Based Search Engine: Relies on exact keyword matches. Semantic Search Engines: Understands the meaning and context of queries and documents. ğŸ”‘ Core Logic: Preprocessing: Clean and vectorize subtitle documents and user queries. Cosine Similarity Calculation: Compute similarity between document vectors and user query vector. ğŸ’» Step-by-Step Process: Part 1: Ingesting Documents Read and decode subtitle data from the provided database. Applied appropriate cleaning steps and experimented with BOW/TFIDF for keyword-based and BERT-based SentenceTransformers for semantic search engine. Implemented a Document Chunker to handle large documents efficiently. Stored embeddings in a ChromaDB database. Part 2: Retrieving Documents Preprocessed user queries and created query embeddings. Calculated similarity scores using cosine distance to return the most relevant documents. ğŸš€ Our algorithm leverages state-of-the-art techniques to deliver precise search results, ensuring users find exactly what they need. Special thanks to [Kanav Bansal](https://in.linkedin.com/in/kanavbansal?trk=public_post-text) for his guidance and to [Innomatics Research Labs](https://in.linkedin.com/school/innomatics-research-labs/?trk=public_post-text) for providing us the opportunity. Additionally, we've integrated a user-friendly frontend using Streamlit for seamless query experience. Check out the full post and download the subtitle data to experience the power of advanced search firsthand! [#SearchEngine](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsearchengine&trk=public_post-text) [#NLP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#SemanticSearch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsemanticsearch&trk=public_post-text) [#SubtitleSearch](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsubtitlesearch&trk=public_post-text) ğŸ“ğŸ”ğŸ¤–
â€¦more 
Play Video
Video Player is loading.
Loaded: 0%
PlayBack to start
Stream Type LIVE
Current Time 0:00
/
Duration 0:00
1x
Playback Rate
Show Captions
Mute
Fullscreen
[ 8  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fabdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fabdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fabdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fabdul-rauf-112612155_searchengine-nlp-machinelearning-activity-7189553085357162496-Lm4a&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/edumunozsala_llmzoomcamp-llm-searchengine-activity-7218527718001299456-4cKP)
[ ](https://es.linkedin.com/in/edumunozsala/en?trk=public_post_feed-actor-image)
[ Eduardo MuÃ±oz ](https://es.linkedin.com/in/edumunozsala/en?trk=public_post_feed-actor-name)
Software Architecture | Data Engineer | Project Management Lead | Machine Learning | NLP | ITSM Manager 
8mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fedumunozsala_llmzoomcamp-llm-searchengine-activity-7218527718001299456-4cKP&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
ğŸ‡ Semantic Search, and Vector Search ğŸ“– How search engines work: When a query is entered into a search engine, a series of algorithms are triggered to deliver relevant results. These algorithms analyze the query, match it with indexed web content, and rank the results based on relevance and quality. Essentially, search engines function as digital librarians, sorting through vast amounts of web pages to present the most pertinent information. ğŸ“Œ Semantic search: Semantic search enhances information retrieval by understanding the deeper meaning behind queries. Unlike traditional keyword matching, semantic search interprets user intent and context, which leads to more accurate and relevant results. It excels in recognizing synonyms and variations of terms, ensuring users find what they seek even if their input differs slightly from indexed terms. This approach is particularly effective for broad concepts and nuanced language. ğŸ—“ Vector Search: Vector search is a powerful method for navigating and exploring extensive datasets by converting data into geometric representations called vectors. These vectors numerically represent the essence of content, such as words, phrases, or documents. Vector search measures similarity and relationships between entities with high precision, making it efficient for handling large datasets and enhancing content relevance through advanced data representation. âš– Semantic search vs. Vector search: While both semantic and vector search have unique strengths, their synergy can create a robust information retrieval system. âœ… Semantic search: Excels in understanding user intent and context, making it ideal for queries involving nuanced language or broad concepts. â˜‘ Vector Search: Efficiently processes vast datasets and leverages machine learning to enhance content relevance. ğŸš€ Combining semantic search's deep query understanding with vector search's precise data representation can balance precision and scalability, resulting in a powerful and efficient information retrieval system. [#llmzoomcamp](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllmzoomcamp&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#searchengine](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fsearchengine&trk=public_post-text) [#NLP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fedumunozsala_llmzoomcamp-llm-searchengine-activity-7218527718001299456-4cKP&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fedumunozsala_llmzoomcamp-llm-searchengine-activity-7218527718001299456-4cKP&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fedumunozsala_llmzoomcamp-llm-searchengine-activity-7218527718001299456-4cKP&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/usabilitysmith_researchers-at-the-university-of-wisconsin-madison-activity-7214124673557569536-zcTY)
[ ](https://www.linkedin.com/in/usabilitysmith?trk=public_post_feed-actor-image)
[ Andrew Smith ](https://www.linkedin.com/in/usabilitysmith?trk=public_post_feed-actor-name)
AI Developer Freelance 
9mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fusabilitysmith_researchers-at-the-university-of-wisconsin-madison-activity-7214124673557569536-zcTY&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Researchers at the University of Wisconsin-Madison Propose a Finetuning Approach Utilizing a Carefully Designed Synthetic Dataset Comprising Numerical Key-Value Retrieval Tasks [https://lnkd.in/gPESrw-2](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FgPESrw-2&urlhash=fv5B&trk=public_post-text) The Challenge of LLMs in Handling Long-context Inputs Large language models (LLMs) like GPT-3.5 Turbo and Mistral 7B struggle with accurately retrieving information and maintaining reasoning capabilities across extensive textual data. This limitation hampers their effectiveness in tasks that require processing and reasoning over long passages, such as multi-document question answering (MDQA) and flexible length question answering (FLenQA). Enhancing LLMsâ€™ Performance in Long-context Settings Current methods to enhance the performance of LLMs in long-context settings typically involve finetuning on real-world datasets. However, these datasets often include outdated or irrelevant information, leading to inaccuracies. LLMs tend to exhibit a â€œlost-in-the-middleâ€ behavior, where their performance is optimal at the beginning or end of the input context but deteriorates for information in the middle. The Proposed Solution: Synthetic Dataset Finetuning A team of researchers from the University of Wisconsin-Madison proposes a novel finetuning approach utilizing a carefully designed synthetic dataset to address these challenges. This dataset comprises numerical key-value retrieval tasks designed to enhance the LLMsâ€™ ability to handle long contexts more effectively. By using synthetic data that avoids the pitfalls of outdated or irrelevant information, the researchers aim to improve LLMsâ€™ information retrieval and reasoning capabilities without introducing hallucinations. Impact and Results Experiments demonstrate that this approach significantly enhances the performance of LLMs in long-context tasks. For example, finetuning GPT-3.5 Turbo on the synthetic data resulted in a 10.5% improvement on the 20 documents MDQA benchmark at the tenth position. Moreover, this method mitigates the â€œlost-in-the-middleâ€ phenomenon and reduces the primacy bias, leading to more accurate information retrieval across the entire input context. The Potential of Synthetic Datasets in Overcoming Limitations The study introduces an innovative approach to finetuning LLMs using synthetic data, significantly enhancing their performance in long-context settings. The proposed method demonstrates substantial improvements over traditional finetuning techniques by addressing the â€œlost-in-the-middleâ€ phenomenon and reducing primacy bias. This research highlights the potential of synthetic datasets in overcoming the limitations of real-world data, paving the way for more effective and reliable LLMs in handling extensive textual information. Evolve Your Company with AI Discover how AI can redefine yo...
## [ Researchers at the University of Wisconsin-Madison Propose a Finetuning Approach Utilizing a Carefully Designed Synthetic Dataset Comprising Numerical Key-Value Retrieval Tasks https://itinai.com/researchers-at-the-university-of-wisconsin-madison-propose-a-finetuning-approach-utilizing-a-carefully-designed-synthetic-dataset-comprising-numerical-key-value-retrieval-tasks/ The Challenge of ...  https://itinai.com  ](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fitinai%2Ecom%2Fresearchers-at-the-university-of-wisconsin-madison-propose-a-finetuning-approach-utilizing-a-carefully-designed-synthetic-dataset-comprising-numerical-key-value-retrieval-tasks%2F&urlhash=WNrj&trk=public_post_feed-article-content)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fusabilitysmith_researchers-at-the-university-of-wisconsin-madison-activity-7214124673557569536-zcTY&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fusabilitysmith_researchers-at-the-university-of-wisconsin-madison-activity-7214124673557569536-zcTY&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fusabilitysmith_researchers-at-the-university-of-wisconsin-madison-activity-7214124673557569536-zcTY&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/mateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo)
[ ](https://br.linkedin.com/in/mateus-g-lima?trk=public_post_feed-actor-image)
[ Mateus GuimarÃ£es Lima ](https://br.linkedin.com/in/mateus-g-lima?trk=public_post_feed-actor-name)
AI/ML Engineer | Data Scientist | M.Sc. in Artificial Intelligence Candidate @ UT Austin 
2mo  Edited 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Hi everyone, I'm trying something new and will share a review of an interesting paper I read each week. This week, I want to discuss the "Mixture-of-Agents Enhances Large Language Model Capabilities" (link to the paper: [https://lnkd.in/dG9_NqSp](https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Flnkd%2Ein%2FdG9_NqSp&urlhash=SBPc&trk=public_post-text)). It's a fascinating study that explores how to boost Large Language Model (LLM) performance by combining the strengths of multiple models, and it was worth sharing! The core idea revolves around something the authors call the "collaborativeness of LLMs." Essentially, LLMs perform better when they can reference outputs from other models, even if those outputs aren't top-notch by themselves The researchers introduce a Mixture-of-Agents (MoA) framework that leverages this concept. Here's how it works: â€¢ They use a layered architecture where each layer contains multiple LLM agents â€¢ Each agent in a layer takes the outputs from agents in the previous layer and uses them as auxiliary information when generating its own response â€¢ This process is repeated iteratively across several layers, refining the responses at each step â€¢ Performance metrics and diversity considerations guide the selection of models for each layer to improve overall response quality. What's really impressive is the performance boost they achieved. The MoA model outperformed even GPT-4 Omni on benchmarks like AlpacaEval 2.0, MT-Bench, and FLASK. For instance, using only open-source models, their MoA achieved a 65.1% win rate on AlpacaEval 2.0, compared to 57.5% for GPT-4 Omni They also have a cost-effective version called MoA-Lite that still beat GPT-4o by 1.8% on the same benchmark. The paper also digs into the inner workings of MoA. Here are some of the insights I found most interesting: â€¢ MoA outperforms simple LLM rankers, which means the final aggregator isn't just picking the best response but is synthesizing a better response through a sophisticated aggregation process. â€¢ Having more diverse LLMs as proposers consistently led to better results. â€¢ Some models are better at being proposers, while others are better at being aggregators. For instance, WizardLM excels as a proposer, while GPT-4o, Qwen1.5, and LLaMA-3 are effective as both proposers and aggregators. â€¢ Their approach is also effective for math-related reasoning tasks. â€¢ The MoA framework can be more cost-effective than using models like GPT-4 Turbo and can achieve comparable performance at a much lower cost In conclusion, this paper presents a compelling approach for leveraging multiple LLMs to achieve state-of-the-art results. It seems like a promising way to move forward, especially given the potential cost savings. Iâ€™d highly recommend checking out the paper if you are interested in this area of research! Iâ€™ll be back next week with another interesting paper review. [#LLMs](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllms&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) [#NLP](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fnlp&trk=public_post-text) [#MixtureofAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmixtureofagents&trk=public_post-text)
[ 6  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fmateus-g-lima_llms-ai-machinelearning-activity-7288216221718663168-tsdo&trk=public_post_feed-cta-banner-cta)


![](https://media.licdn.com/dms/image/v2/D5616AQFouEsMeEG6DA/profile-displaybackgroundimage-shrink_200_800/profile-displaybackgroundimage-shrink_200_800/0/1702861618024?e=2147483647&v=beta&t=AauWp6FG_M4N0ViUPvsgBzuSQC5hiHBlko2pQ_lsGQs)
![Marie Stephen Leo](https://media.licdn.com/dms/image/v2/C4D03AQHQaF15RYIjkg/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1516863550845?e=2147483647&v=beta&t=VSImr8zHrydAWo52_LMZulwN7WWsP5etANhy6e3Apjs)
14,955 followers 
  * [ 280 Posts ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Fmarie-stephen-leo%2Frecent-activity%2F&trk=public_post_follow-posts)


[ View Profile ](https://sg.linkedin.com/in/marie-stephen-leo?trk=public_post_follow-view-profile) [ Connect ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7185079313191301120&trk=public_post_follow)
##  Explore topics 
  * [ Sales ](https://www.linkedin.com/pulse/topics/sales-s5/)
  * [ Marketing ](https://www.linkedin.com/pulse/topics/marketing-s2461/)
  * [ IT Services ](https://www.linkedin.com/pulse/topics/it-services-s57547/)
  * [ Business Administration ](https://www.linkedin.com/pulse/topics/business-administration-s50111/)
  * [ HR Management ](https://www.linkedin.com/pulse/topics/hr-management-s50359/)
  * [ Engineering ](https://www.linkedin.com/pulse/topics/engineering-s166/)
  * [ Soft Skills ](https://www.linkedin.com/pulse/topics/soft-skills-s2976/)
  * [ See All ](https://www.linkedin.com/pulse/topics/home/)


  * LinkedIn Â© 2025
  * [ About ](https://about.linkedin.com?trk=d_public_post_footer-about)
  * [ Accessibility ](https://www.linkedin.com/accessibility?trk=d_public_post_footer-accessibility)
  * [ User Agreement ](https://www.linkedin.com/legal/user-agreement?trk=d_public_post_footer-user-agreement)
  * [ Privacy Policy ](https://www.linkedin.com/legal/privacy-policy?trk=d_public_post_footer-privacy-policy)
  * [ Your California Privacy Choices ](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_public_post_footer-california-privacy-rights-act)
  * [ Cookie Policy ](https://www.linkedin.com/legal/cookie-policy?trk=d_public_post_footer-cookie-policy)
  * [ Copyright Policy ](https://www.linkedin.com/legal/copyright-policy?trk=d_public_post_footer-copyright-policy)
  * [ Brand Policy ](https://brand.linkedin.com/policies?trk=d_public_post_footer-brand-policy)
  * [ Guest Controls ](https://www.linkedin.com/psettings/guest-controls?trk=d_public_post_footer-guest-controls)
  * [ Community Guidelines ](https://www.linkedin.com/legal/professional-community-policies?trk=d_public_post_footer-community-guide)
  *     * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic) 
    * à¦¬à¦¾à¦‚à¦²à¦¾ (Bangla) 
    * ÄŒeÅ¡tina (Czech) 
    * Dansk (Danish) 
    * Deutsch (German) 
    * Î•Î»Î»Î·Î½Î¹ÎºÎ¬ (Greek) 
    * **English (English)**
    * EspaÃ±ol (Spanish) 
    * ÙØ§Ø±Ø³ÛŒ (Persian) 
    * Suomi (Finnish) 
    * FranÃ§ais (French) 
    * à¤¹à¤¿à¤‚à¤¦à¥€ (Hindi) 
    * Magyar (Hungarian) 
    * Bahasa Indonesia (Indonesian) 
    * Italiano (Italian) 
    * ×¢×‘×¨×™×ª (Hebrew) 
    * æ—¥æœ¬èª (Japanese) 
    * í•œêµ­ì–´ (Korean) 
    * à¤®à¤°à¤¾à¤ à¥€ (Marathi) 
    * Bahasa Malaysia (Malay) 
    * Nederlands (Dutch) 
    * Norsk (Norwegian) 
    * à¨ªà©°à¨œà¨¾à¨¬à©€ (Punjabi) 
    * Polski (Polish) 
    * PortuguÃªs (Portuguese) 
    * RomÃ¢nÄƒ (Romanian) 
    * Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian) 
    * Svenska (Swedish) 
    * à°¤à±†à°²à±à°—à± (Telugu) 
    * à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ (Thai) 
    * Tagalog (Tagalog) 
    * TÃ¼rkÃ§e (Turkish) 
    * Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° (Ukrainian) 
    * Tiáº¿ng Viá»‡t (Vietnamese) 
    * ç®€ä½“ä¸­æ–‡ (Chinese (Simplified)) 
    * æ­£é«”ä¸­æ–‡ (Chinese (Traditional)) 
Language 


![](https://static.licdn.com/aero-v1/sc/h/5k9cgtx8rhoyqkcxfoncu1svl)
##  Sign in to view more content 
Create your free account or sign in to continue your search 
Continue with GoogleContinue with Google
Sign in 
##  Welcome back 
Email or phone 
Password 
Show
[Forgot password?](https://www.linkedin.com/uas/request-password-reset?trk=public_post_contextual-sign-in-modal_sign-in-modal_forgot_password) Sign in 
or 
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy). 
Continue with GoogleContinue with Google
New to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)
or 
New to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Fmarie-stephen-leo_generativeai-llm-nlp-activity-7185079313191301120-k-C3&trk=public_post_contextual-sign-in-modal_join-link)
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy). 
