[Skip to content](https://github.com/arcee-ai/mergekit/#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Farcee-ai%2Fmergekit%2F)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Farcee-ai%2Fmergekit%2F)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=arcee-ai%2Fmergekit) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/arcee-ai/mergekit/) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/arcee-ai/mergekit/) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/arcee-ai/mergekit/) to refresh your session. Dismiss alert
{{ message }}
[ arcee-ai ](https://github.com/arcee-ai) / **[mergekit](https://github.com/arcee-ai/mergekit) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Farcee-ai%2Fmergekit) You must be signed in to change notification settings
  * [ Fork 521 ](https://github.com/login?return_to=%2Farcee-ai%2Fmergekit)
  * [ Star  5.5k ](https://github.com/login?return_to=%2Farcee-ai%2Fmergekit)


Tools for merging pretrained large language models. 
### License
[ View license ](https://github.com/arcee-ai/mergekit/blob/main/LICENSE)
[ 5.5k stars ](https://github.com/arcee-ai/mergekit/stargazers) [ 521 forks ](https://github.com/arcee-ai/mergekit/forks) [ Branches ](https://github.com/arcee-ai/mergekit/branches) [ Tags ](https://github.com/arcee-ai/mergekit/tags) [ Activity ](https://github.com/arcee-ai/mergekit/activity)
[ Star  ](https://github.com/login?return_to=%2Farcee-ai%2Fmergekit)
[ Notifications ](https://github.com/login?return_to=%2Farcee-ai%2Fmergekit) You must be signed in to change notification settings
  * [ Code ](https://github.com/arcee-ai/mergekit)
  * [ Issues 198 ](https://github.com/arcee-ai/mergekit/issues)
  * [ Pull requests 14 ](https://github.com/arcee-ai/mergekit/pulls)
  * [ Discussions ](https://github.com/arcee-ai/mergekit/discussions)
  * [ Actions ](https://github.com/arcee-ai/mergekit/actions)
  * [ Security ](https://github.com/arcee-ai/mergekit/security)
  * [ Insights ](https://github.com/arcee-ai/mergekit/pulse)


Additional navigation options
  * [ Code  ](https://github.com/arcee-ai/mergekit)
  * [ Issues  ](https://github.com/arcee-ai/mergekit/issues)
  * [ Pull requests  ](https://github.com/arcee-ai/mergekit/pulls)
  * [ Discussions  ](https://github.com/arcee-ai/mergekit/discussions)
  * [ Actions  ](https://github.com/arcee-ai/mergekit/actions)
  * [ Security  ](https://github.com/arcee-ai/mergekit/security)
  * [ Insights  ](https://github.com/arcee-ai/mergekit/pulse)


# arcee-ai/mergekit
main
[Branches](https://github.com/arcee-ai/mergekit/branches)[Tags](https://github.com/arcee-ai/mergekit/tags)
[](https://github.com/arcee-ai/mergekit/branches)[](https://github.com/arcee-ai/mergekit/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[250 Commits](https://github.com/arcee-ai/mergekit/commits/main/)[](https://github.com/arcee-ai/mergekit/commits/main/)  
[.github/workflows](https://github.com/arcee-ai/mergekit/tree/main/.github/workflows "This path skips through empty directories")| [.github/workflows](https://github.com/arcee-ai/mergekit/tree/main/.github/workflows "This path skips through empty directories")  
[docs](https://github.com/arcee-ai/mergekit/tree/main/docs "docs")| [docs](https://github.com/arcee-ai/mergekit/tree/main/docs "docs")  
[examples](https://github.com/arcee-ai/mergekit/tree/main/examples "examples")| [examples](https://github.com/arcee-ai/mergekit/tree/main/examples "examples")  
[mergekit](https://github.com/arcee-ai/mergekit/tree/main/mergekit "mergekit")| [mergekit](https://github.com/arcee-ai/mergekit/tree/main/mergekit "mergekit")  
[tests](https://github.com/arcee-ai/mergekit/tree/main/tests "tests")| [tests](https://github.com/arcee-ai/mergekit/tree/main/tests "tests")  
[.gitignore](https://github.com/arcee-ai/mergekit/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/arcee-ai/mergekit/blob/main/.gitignore ".gitignore")  
[.pre-commit-config.yaml](https://github.com/arcee-ai/mergekit/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](https://github.com/arcee-ai/mergekit/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")  
[CLA.md](https://github.com/arcee-ai/mergekit/blob/main/CLA.md "CLA.md")| [CLA.md](https://github.com/arcee-ai/mergekit/blob/main/CLA.md "CLA.md")  
[LICENSE](https://github.com/arcee-ai/mergekit/blob/main/LICENSE "LICENSE")| [LICENSE](https://github.com/arcee-ai/mergekit/blob/main/LICENSE "LICENSE")  
[README.md](https://github.com/arcee-ai/mergekit/blob/main/README.md "README.md")| [README.md](https://github.com/arcee-ai/mergekit/blob/main/README.md "README.md")  
[notebook.ipynb](https://github.com/arcee-ai/mergekit/blob/main/notebook.ipynb "notebook.ipynb")| [notebook.ipynb](https://github.com/arcee-ai/mergekit/blob/main/notebook.ipynb "notebook.ipynb")  
[pyproject.toml](https://github.com/arcee-ai/mergekit/blob/main/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/arcee-ai/mergekit/blob/main/pyproject.toml "pyproject.toml")  
View all files  
## Repository files navigation
  * [README](https://github.com/arcee-ai/mergekit/)
  * [License](https://github.com/arcee-ai/mergekit/)


# mergekit
[](https://github.com/arcee-ai/mergekit/#mergekit)
`mergekit` is a toolkit for merging pre-trained language models. `mergekit` uses an out-of-core approach to perform unreasonably elaborate merges in resource-constrained situations. Merges can be run entirely on CPU or accelerated with as little as 8 GB of VRAM. Many merging algorithms are supported, with more coming as they catch my attention.
## Contents
[](https://github.com/arcee-ai/mergekit/#contents)
  * [Why Merge Models?](https://github.com/arcee-ai/mergekit/#why-merge-models)
  * [Features](https://github.com/arcee-ai/mergekit/#features)
  * [Installation](https://github.com/arcee-ai/mergekit/#installation)
  * [Usage](https://github.com/arcee-ai/mergekit/#usage)
  * [Merge Configuration](https://github.com/arcee-ai/mergekit/#merge-configuration)
    * [Parameter Specification](https://github.com/arcee-ai/mergekit/#parameter-specification)
    * [Tokenizer Configuration](https://github.com/arcee-ai/mergekit/#tokenizer-configuration)
    * [Chat Template Configuration](https://github.com/arcee-ai/mergekit/#chat-template-configuration)
    * [Examples](https://github.com/arcee-ai/mergekit/#examples)
  * [Merge Methods](https://github.com/arcee-ai/mergekit/#merge-methods)
  * [LoRA extraction](https://github.com/arcee-ai/mergekit/#lora-extraction)
  * [Mixture of Experts merging](https://github.com/arcee-ai/mergekit/#mixture-of-experts-merging)
  * [Evolutionary merge methods](https://github.com/arcee-ai/mergekit/#evolutionary-merge-methods)
  * [Merge in the Cloud](https://github.com/arcee-ai/mergekit/#-merge-in-the-cloud-)
  * [Citation](https://github.com/arcee-ai/mergekit/#citation)


## Why Merge Models?
[](https://github.com/arcee-ai/mergekit/#why-merge-models)
Model merging is a powerful technique that allows combining the strengths of different models without the computational overhead of ensembling or the need for additional training. By operating directly in the weight space of models, merging can:
  * Combine multiple specialized models into a single versatile model
  * Transfer capabilities between models without access to training data
  * Find optimal trade-offs between different model behaviors
  * Improve performance while maintaining inference costs
  * Create new capabilities through creative model combinations


Unlike traditional ensembling which requires running multiple models, merged models maintain the same inference cost as a single model while often achieving comparable or superior performance.
## Features
[](https://github.com/arcee-ai/mergekit/#features)
Key features of `mergekit` include:
  * Supports Llama, Mistral, GPT-NeoX, StableLM, and more
  * Many [merge methods](https://github.com/arcee-ai/mergekit/#merge-methods)
  * GPU or CPU execution
  * Lazy loading of tensors for low memory use
  * Interpolated gradients for parameter values (inspired by Gryphe's [BlockMerge_Gradient](https://github.com/Gryphe/BlockMerge_Gradient) script)
  * Piecewise assembly of language models from layers ("Frankenmerging")
  * [Mixture of Experts merging](https://github.com/arcee-ai/mergekit/#mixture-of-experts-merging)
  * [LORA extraction](https://github.com/arcee-ai/mergekit/#lora-extraction)
  * [Evolutionary merge methods](https://github.com/arcee-ai/mergekit/#evolutionary-merge-methods)


🌐 GUI Launch Alert 🤗 - We are excited to announce the launch of a mega-GPU backed graphical user interface for mergekit in Arcee! This GUI simplifies the merging process, making it more accessible to a broader audience. Check it out and contribute at the [Arcee App](https://app.arcee.ai). There is also a [Hugging Face Space](https://huggingface.co/mergekit-community) with limited amounts of GPUs.
## Installation
[](https://github.com/arcee-ai/mergekit/#installation)
```
git clone https://github.com/arcee-ai/mergekit.git
cd mergekit
pip install -e . # install the package and make scripts available
```

If the above fails with the error of:
```
ERROR: File "setup.py" or "setup.cfg" not found. Directory cannot be installed in editable mode:
(A "pyproject.toml" file was found, but editable mode currently requires a setuptools-based build.)

```

You may need to upgrade pip to > 21.3 with the command `python3 -m pip install --upgrade pip`
## Usage
[](https://github.com/arcee-ai/mergekit/#usage)
The script `mergekit-yaml` is the main entry point for `mergekit`. It takes a YAML configuration file and an output path, like so:
```
mergekit-yaml path/to/your/config.yml ./output-model-directory [--cuda] [--lazy-unpickle] [--allow-crimes] [... other options]
```

This will run the merge and write your merged model to `./output-model-directory`.
For more information on the arguments accepted by `mergekit-yaml` run the command `mergekit-yaml --help`.
### Uploading to Huggingface
[](https://github.com/arcee-ai/mergekit/#uploading-to-huggingface)
When you have a merged model you're happy with, you may want to share it on the Hugging Face Hub. `mergekit` generates a `README.md` for your merge with some basic information for a model card. You can edit it to include more details about your merge, like giving it a good name or explaining what it's good at; rewrite it entirely; or use the generated `README.md` as-is. It is also possible to edit your `README.md` online once it has been uploaded to the Hub.
Once you're happy with your model card and merged model, you can upload it to the Hugging Face Hub using the [huggingface_hub](https://huggingface.co/docs/huggingface_hub/index) Python library.
```
# log in to huggingface with an access token (must have write permission)
huggingface-cli login
# upload your model
huggingface-cli upload your_hf_username/my-cool-model ./output-model-directory .
```

The [documentation](https://huggingface.co/docs/huggingface_hub/guides/cli#huggingface-cli-upload) for `huggingface_hub` goes into more detail about other options for uploading.
## Merge Configuration
[](https://github.com/arcee-ai/mergekit/#merge-configuration)
Merge configurations are YAML documents specifying the operations to perform in order to produce your merged model. Below are the primary elements of a configuration file:
  * `merge_method`: Specifies the method to use for merging models. See [Merge Methods](https://github.com/arcee-ai/mergekit/#merge-methods) for a list.
  * `slices`: Defines slices of layers from different models to be used. This field is mutually exclusive with `models`.
  * `models`: Defines entire models to be used for merging. This field is mutually exclusive with `slices`.
  * `base_model`: Specifies the base model used in some merging methods.
  * `parameters`: Holds various parameters such as weights and densities, which can also be specified at different levels of the configuration.
  * `dtype`: Specifies the data type used for the merging operation.
  * `tokenizer` or `tokenizer_source`: Determines how to construct a tokenizer for the merged model.
  * `chat_template`: Specifies a chat template for the merged model.


### Parameter Specification
[](https://github.com/arcee-ai/mergekit/#parameter-specification)
Parameters are flexible and can be set with varying precedence. They can be specified conditionally using tensor name filters, which allows finer control such as differentiating between attention heads and fully connected layers.
Parameters can be specified as:
  * **Scalars** : Single floating-point values.
  * **Gradients** : List of floating-point values, specifying an interpolated gradient.


The parameters can be set at different levels, with decreasing precedence as follows:
  1. `slices.*.sources.parameters` - applying to a specific input slice
  2. `slices.*.parameters` - applying to a specific output slice
  3. `models.*.parameters` or `input_model_parameters` - applying to any tensors coming from specific input models
  4. `parameters` - catchall


### Tokenizer Configuration
[](https://github.com/arcee-ai/mergekit/#tokenizer-configuration)
The tokenizer behavior can be configured in two ways: using the new `tokenizer` field (recommended) or the legacy `tokenizer_source` field (maintained for backward compatibility). These fields are mutually exclusive - you should use one or the other, not both.
#### Modern Configuration (tokenizer)
[](https://github.com/arcee-ai/mergekit/#modern-configuration-tokenizer)
The `tokenizer` field provides fine-grained control over vocabulary and embeddings:
```
tokenizer:
 source: "union" # or "base" or a specific model path
 tokens:     # Optional: configure specific tokens
  <token_name>:
   source: ... # Specify embedding source
   force: false # Optional: force this embedding for all models
 pad_to_multiple_of: null # Optional: pad vocabulary size
```

##### Tokenizer Source
[](https://github.com/arcee-ai/mergekit/#tokenizer-source)
The `source` field determines the vocabulary of the output model:
  * `union`: Combine vocabularies from all input models (default)
  * `base`: Use vocabulary from the base model
  * `"path/to/model"`: Use vocabulary from a specific model


##### Token Embedding Handling
[](https://github.com/arcee-ai/mergekit/#token-embedding-handling)
When merging models with different vocabularies, mergekit uses smart defaults to handle token embeddings:
  * If a token exists in the base model, its embedding is used as the default
  * If only one model has the token, that model's embedding is used
  * Otherwise, an average of all available embeddings is used


You can override these defaults for specific tokens:
```
tokenizer:
 source: union
 tokens:
  # Use embedding from a specific model
  <|im_start|>:
   source: "path/to/chatml/model"
  # Force a specific embedding for all models
  <|special|>:
   source: "path/to/model"
   force: true
  # Map a token to another model's token embedding
  <|renamed_token|>:
   source:
    kind: "model_token"
    model: "path/to/model"
    token: "<|original_token|>" # or use token_id: 1234
```

##### Practical Example
[](https://github.com/arcee-ai/mergekit/#practical-example)
Here's how you might preserve both Llama 3 Instruct and ChatML prompt formats when merging models:
```
tokenizer:
 source: union
 tokens:
  # ChatML tokens
  <|im_start|>:
   source: "chatml_model"
  <|im_end|>:
   source: "chatml_model"
  # Llama 3 tokens - force original embeddings
  <|start_header_id|>:
   source: "llama3_model"
   force: true
  <|end_header_id|>:
   source: "llama3_model"
   force: true
  <|eot_id|>:
   source: "llama3_model"
   force: true
```

#### Legacy Configuration (tokenizer_source)
[](https://github.com/arcee-ai/mergekit/#legacy-configuration-tokenizer_source)
For backward compatibility, the `tokenizer_source` field is still supported:
```
tokenizer_source: "union" # or "base" or a model path
```

This provides basic tokenizer selection but lacks the fine-grained control of the modern `tokenizer` field.
### Chat Template Configuration
[](https://github.com/arcee-ai/mergekit/#chat-template-configuration)
The optional `chat_template` field allows overriding the chat template used for the merged model.
```
chat_template: "auto" # or a template name or Jinja2 template
```

Options include:
  * `"auto"`: Automatically select the most common template among input models
  * Built-in templates: `"alpaca"`, `"chatml"`, `"llama3"`, `"mistral"`, `"exaone"`
  * A Jinja2 template string for custom formatting


### Examples
[](https://github.com/arcee-ai/mergekit/#examples)
Several examples of merge configurations are available in [`examples/`](https://github.com/arcee-ai/mergekit/blob/main/examples).
## Merge Methods
[](https://github.com/arcee-ai/mergekit/#merge-methods)
A quick overview of the currently supported merge methods:
Method | `merge_method` value | Multi-Model | Uses base model  
---|---|---|---  
Linear ([Model Soups](https://arxiv.org/abs/2203.05482)) | `linear` | ✅ | ❌  
SLERP | `slerp` | ❌ | ✅  
Nearswap | `nearswap` | ❌ | ✅  
[Task Arithmetic](https://arxiv.org/abs/2212.04089) | `task_arithmetic` | ✅ | ✅  
[TIES](https://arxiv.org/abs/2306.01708) | `ties` | ✅ | ✅  
[DARE](https://arxiv.org/abs/2311.03099) [TIES](https://arxiv.org/abs/2306.01708) | `dare_ties` | ✅ | ✅  
[DARE](https://arxiv.org/abs/2311.03099) [Task Arithmetic](https://arxiv.org/abs/2212.04089) | `dare_linear` | ✅ | ✅  
Passthrough | `passthrough` | ❌ | ❌  
[Model Breadcrumbs](https://arxiv.org/abs/2312.06795) | `breadcrumbs` | ✅ | ✅  
[Model Breadcrumbs](https://arxiv.org/abs/2312.06795) + [TIES](https://arxiv.org/abs/2306.01708) | `breadcrumbs_ties` | ✅ | ✅  
[Model Stock](https://arxiv.org/abs/2403.19522) | `model_stock` | ✅ | ✅  
NuSLERP | `nuslerp` | ❌ | ✅  
[DELLA](https://arxiv.org/abs/2406.11617) | `della` | ✅ | ✅  
[DELLA](https://arxiv.org/abs/2406.11617) [Task Arithmetic](https://arxiv.org/abs/2212.04089) | `della_linear` | ✅ | ✅  
[SCE](https://arxiv.org/abs/2408.07990) | `sce` | ✅ | ✅  
### Linear
[](https://github.com/arcee-ai/mergekit/#linear)
The classic merge method - a simple weighted average.
Parameters:
  * `weight` - relative (or absolute if `normalize=False`) weighting of a given tensor
  * `normalize` - if true, the weights of all models contributing to a tensor will be normalized. Default behavior.


### SLERP
[](https://github.com/arcee-ai/mergekit/#slerp)
Spherically interpolate the parameters of two models. One must be set as `base_model`.
Parameters:
  * `t` - interpolation factor. At `t=0` will return `base_model`, at `t=1` will return the other one.


### Nearswap
[](https://github.com/arcee-ai/mergekit/#nearswap)
Interpolates base model with secondary model if similarity is below t. Accepts two models.
Parameters:
  * `t` - similarity threshold


### [Task Arithmetic](https://arxiv.org/abs/2212.04089)
[](https://github.com/arcee-ai/mergekit/#task-arithmetic)
Computes "task vectors" for each model by subtracting a base model. Merges the task vectors linearly and adds back the base. Works great for models that were fine tuned from a common ancestor. Also a super useful mental framework for several of the more involved merge methods.
Parameters: same as [Linear](https://github.com/arcee-ai/mergekit/#linear), plus:
  * `lambda` - scaling factor applied after weighted sum of task vectors


### [TIES](https://arxiv.org/abs/2306.01708)
[](https://github.com/arcee-ai/mergekit/#ties)
Builds on the task arithmetic framework. Resolves interference between models by sparsifying the task vectors and applying a sign consensus algorithm. Allows you to merge a larger number of models and retain more of their strengths.
Parameters: same as [Task Arithmetic](https://github.com/arcee-ai/mergekit/#task-arithmetic), plus:
  * `density` - fraction of weights in differences from the base model to retain


### [DARE](https://arxiv.org/abs/2311.03099)
[](https://github.com/arcee-ai/mergekit/#dare)
In the same vein as TIES, sparsifies task vectors to reduce interference. Differs in that DARE uses random pruning with a novel rescaling to better match performance of the original models. DARE can be used either with the sign consensus algorithm of TIES (`dare_ties`) or without (`dare_linear`).
Parameters: same as [TIES](https://github.com/arcee-ai/mergekit/#ties) for `dare_ties`, or [Linear](https://github.com/arcee-ai/mergekit/#linear) for `dare_linear`
### Passthrough
[](https://github.com/arcee-ai/mergekit/#passthrough)
`passthrough` is a no-op that simply passes input tensors through unmodified. It is meant to be used for layer-stacking type merges where you have only one input model. Useful for frankenmerging.
### [Model Breadcrumbs](https://arxiv.org/abs/2312.06795)
[](https://github.com/arcee-ai/mergekit/#model-breadcrumbs)
An extension of task arithmetic that discards both small and extremely large differences from the base model. As with DARE, the Model Breadcrumbs algorithm can be used with (`breadcrumbs_ties`) or without (`breadcrumbs`) the sign consensus algorithm of TIES.
Parameters: same as [Task Arithmetic](https://github.com/arcee-ai/mergekit/#task-arithmetic), plus:
  * `density` - fraction of weights in differences from the base model to retain
  * `gamma` - fraction of largest magnitude differences to remove


Note that `gamma` corresponds with the parameter `β` described in the paper, while `density` is the final density of the sparsified tensors (related to `γ` and `β` by `density = 1 - γ - β`). For good default values, try `density: 0.9` and `gamma: 0.01`.
### [Model Stock](https://arxiv.org/abs/2403.19522)
[](https://github.com/arcee-ai/mergekit/#model-stock)
Uses some neat geometric properties of fine tuned models to compute good weights for linear interpolation. Requires at least three models, including a base model.
Parameters:
  * `filter_wise`: if true, weight calculation will be per-row rather than per-tensor. Not recommended.


### NuSLERP
[](https://github.com/arcee-ai/mergekit/#nuslerp)
Spherically interpolate between parameters, but with more options and more sensical configuration! Does not require a base model, but can use one to do spherical interpolation of task vectors. Only works with either two models or two plus a base model.
Parameters:
  * `weight`: relative weighting of a given tensor
  * `nuslerp_flatten`: set to false to do row-wise/column-wise interpolation instead of treating tensors as vectors
  * `nuslerp_row_wise`: SLERP row vectors instead of column vectors


To replicate the behavior of the original `slerp` method, set `weight` to `1-t` and `t` for your first and second model respectively.
### [DELLA](https://arxiv.org/abs/2406.11617)
[](https://github.com/arcee-ai/mergekit/#della)
Building upon DARE, DELLA uses adaptive pruning based on parameter magnitudes. DELLA first ranks parameters in each row of delta parameters and assigns drop probabilities inversely proportional to their magnitudes. This allows it to retain more important changes while reducing interference. After pruning, it rescales the remaining parameters similar to [DARE](https://github.com/arcee-ai/mergekit/#dare). DELLA can be used with (`della`) or without (`della_linear`) the sign elect step of TIES
Parameters: same as [Task Arithmetic](https://github.com/arcee-ai/mergekit/#task-arithmetic), plus:
  * `density` - fraction of weights in differences from the base model to retain
  * `epsilon` - maximum change in drop probability based on magnitude. Drop probabilities assigned will range from `density - epsilon` to `density + epsilon`. (When selecting values for `density` and `epsilon`, ensure that the range of probabilities falls within 0 to 1)


### [SCE](https://arxiv.org/abs/2408.07990)
[](https://github.com/arcee-ai/mergekit/#sce)
SCE introduces adaptive matrix-level merging weights based on parameter variances. SCE first selects the top-k% elements from each parameter matrix that exhibit high variance across all delta parameters. Following this selection, SCE calculates matrix-level merging weights based on the sum of squares of elements in the delta parameters. Finally, it erases minority elements, a step similar to the sign election process in TIES.
Parameters: same as [TIES](https://github.com/arcee-ai/mergekit/#ties), plus:
  * `select_topk` - fraction of elements with the highest variance in the delta parameters to retain.


## LoRA extraction
[](https://github.com/arcee-ai/mergekit/#lora-extraction)
Mergekit allows extracting PEFT-compatible low-rank approximations of finetuned models.
### Usage
[](https://github.com/arcee-ai/mergekit/#usage-1)
```
mergekit-extract-lora --model finetuned_model_id_or_path --base-model base_model_id_or_path --out-path output_path [--no-lazy-unpickle] [--cuda] [--max-rank=desired_rank] [--sv-epsilon=tol]
```

## Mixture of Experts merging
[](https://github.com/arcee-ai/mergekit/#mixture-of-experts-merging)
The `mergekit-moe` script supports merging multiple dense models into a mixture of experts, either for direct use or for further training. For more details see the [`mergekit-moe` documentation](https://github.com/arcee-ai/mergekit/blob/main/docs/moe.md).
## Evolutionary merge methods
[](https://github.com/arcee-ai/mergekit/#evolutionary-merge-methods)
See [`docs/evolve.md`](https://github.com/arcee-ai/mergekit/blob/main/docs/evolve.md) for details.
## ✨ Merge in the Cloud ✨
[](https://github.com/arcee-ai/mergekit/#-merge-in-the-cloud-)
We host merging on Arcee's cloud GPUs - you can launch a cloud merge in the [Arcee App](https://app.arcee.ai). Or through python - grab an ARCEE_API_KEY:
`export ARCEE_API_KEY=<your-api-key>` `pip install -q arcee-py`
```
import arcee
arcee.merge_yaml("bio-merge","./examples/bio-merge.yml")
```

Check your merge status at the [Arcee App](https://app.arcee.ai)
When complete, either deploy your merge:
```
arcee.start_deployment("bio-merge", merging="bio-merge")
```

Or download your merge:
`!arcee merging download bio-merge`
## Citation
[](https://github.com/arcee-ai/mergekit/#citation)
If you find `mergekit` useful in your research, please consider citing the [paper](https://aclanthology.org/2024.emnlp-industry.36/):
```
@inproceedings{goddard-etal-2024-arcees,
  title = "Arcee{'}s {M}erge{K}it: A Toolkit for Merging Large Language Models",
  author = "Goddard, Charles and
   Siriwardhana, Shamane and
   Ehghaghi, Malikeh and
   Meyers, Luke and
   Karpukhin, Vladimir and
   Benedict, Brian and
   McQuade, Mark and
   Solawetz, Jacob",
  editor = "Dernoncourt, Franck and
   Preo{\c{t}}iuc-Pietro, Daniel and
   Shimorina, Anastasia",
  booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track",
  month = nov,
  year = "2024",
  address = "Miami, Florida, US",
  publisher = "Association for Computational Linguistics",
  url = "https://aclanthology.org/2024.emnlp-industry.36",
  doi = "10.18653/v1/2024.emnlp-industry.36",
  pages = "477--485",
  abstract = "The rapid growth of open-source language models provides the opportunity to merge model checkpoints, combining their parameters to improve performance and versatility. Advances in transfer learning have led to numerous task-specific models, which model merging can integrate into powerful multitask models without additional training. MergeKit is an open-source library designed to support this process with an efficient and extensible framework suitable for any hardware. It has facilitated the merging of thousands of models, contributing to some of the world{'}s most powerful open-source model checkpoints. The library is accessible at: https://github.com/arcee-ai/mergekit.",
}
```

## About
Tools for merging pretrained large language models. 
### Topics
[ llama ](https://github.com/topics/llama "Topic: llama") [ llm ](https://github.com/topics/llm "Topic: llm") [ model-merging ](https://github.com/topics/model-merging "Topic: model-merging")
### Resources
[ Readme ](https://github.com/arcee-ai/mergekit/#readme-ov-file)
### License
[ View license ](https://github.com/arcee-ai/mergekit/#License-1-ov-file)
[ Activity](https://github.com/arcee-ai/mergekit/activity)
[ Custom properties](https://github.com/arcee-ai/mergekit/custom-properties)
### Stars
[ **5.5k** stars](https://github.com/arcee-ai/mergekit/stargazers)
### Watchers
[ **58** watching](https://github.com/arcee-ai/mergekit/watchers)
### Forks
[ **521** forks](https://github.com/arcee-ai/mergekit/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Farcee-ai%2Fmergekit&report=arcee-ai+%28user%29)
##  [Releases](https://github.com/arcee-ai/mergekit/releases)
[ 8 tags ](https://github.com/arcee-ai/mergekit/tags)
##  [Packages 0](https://github.com/orgs/arcee-ai/packages?repo_name=mergekit)
No packages published 
##  [Contributors 31](https://github.com/arcee-ai/mergekit/graphs/contributors)
  * [ ![@cg123](https://avatars.githubusercontent.com/u/397199?s=64&v=4) ](https://github.com/cg123)
  * [ ![@tleyden](https://avatars.githubusercontent.com/u/296876?s=64&v=4) ](https://github.com/tleyden)
  * [ ![@thomasgauthier](https://avatars.githubusercontent.com/u/9730392?s=64&v=4) ](https://github.com/thomasgauthier)
  * [ ![@nyxkrage](https://avatars.githubusercontent.com/u/46626618?s=64&v=4) ](https://github.com/nyxkrage)
  * [ ![@MonsterAzi](https://avatars.githubusercontent.com/u/120850865?s=64&v=4) ](https://github.com/MonsterAzi)
  * [ ![@Jacobsolawetz](https://avatars.githubusercontent.com/u/8428198?s=64&v=4) ](https://github.com/Jacobsolawetz)
  * [ ![@shamanez](https://avatars.githubusercontent.com/u/16892570?s=64&v=4) ](https://github.com/shamanez)
  * [ ![@PhilipMay](https://avatars.githubusercontent.com/u/229382?s=64&v=4) ](https://github.com/PhilipMay)
  * [ ![@hannibalhuang](https://avatars.githubusercontent.com/u/535354?s=64&v=4) ](https://github.com/hannibalhuang)
  * [ ![@T145](https://avatars.githubusercontent.com/u/1214129?s=64&v=4) ](https://github.com/T145)
  * [ ![@songyouwei](https://avatars.githubusercontent.com/u/2573291?s=64&v=4) ](https://github.com/songyouwei)
  * [ ![@q5sys](https://avatars.githubusercontent.com/u/4654247?s=64&v=4) ](https://github.com/q5sys)
  * [ ![@metric-space](https://avatars.githubusercontent.com/u/6382230?s=64&v=4) ](https://github.com/metric-space)
  * [ ![@osanseviero](https://avatars.githubusercontent.com/u/7246357?s=64&v=4) ](https://github.com/osanseviero)


[+ 17 contributors](https://github.com/arcee-ai/mergekit/graphs/contributors)
## Languages
  * [ Python 98.8% ](https://github.com/arcee-ai/mergekit/search?l=python)
  * Other 1.2%


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
