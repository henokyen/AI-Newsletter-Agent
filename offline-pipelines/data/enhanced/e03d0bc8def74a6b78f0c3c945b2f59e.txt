[Skip to content](https://github.com/openai/evals/#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals%2F)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals%2F)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=openai%2Fevals) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/openai/evals/) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/openai/evals/) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/openai/evals/) to refresh your session. Dismiss alert
{{ message }}
[ openai ](https://github.com/openai) / **[evals](https://github.com/openai/evals) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2Fopenai%2Fevals) You must be signed in to change notification settings
  * [ Fork 2.7k ](https://github.com/login?return_to=%2Fopenai%2Fevals)
  * [ Star  15.8k ](https://github.com/login?return_to=%2Fopenai%2Fevals)


Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. 
### License
[ View license ](https://github.com/openai/evals/blob/main/LICENSE.md)
[ 15.8k stars ](https://github.com/openai/evals/stargazers) [ 2.7k forks ](https://github.com/openai/evals/forks) [ Branches ](https://github.com/openai/evals/branches) [ Tags ](https://github.com/openai/evals/tags) [ Activity ](https://github.com/openai/evals/activity)
[ Star  ](https://github.com/login?return_to=%2Fopenai%2Fevals)
[ Notifications ](https://github.com/login?return_to=%2Fopenai%2Fevals) You must be signed in to change notification settings
  * [ Code ](https://github.com/openai/evals)
  * [ Issues 96 ](https://github.com/openai/evals/issues)
  * [ Pull requests 49 ](https://github.com/openai/evals/pulls)
  * [ Discussions ](https://github.com/openai/evals/discussions)
  * [ Actions ](https://github.com/openai/evals/actions)
  * [ Projects 0 ](https://github.com/openai/evals/projects)
  * [ Security ](https://github.com/openai/evals/security)
  * [ Insights ](https://github.com/openai/evals/pulse)


Additional navigation options
  * [ Code  ](https://github.com/openai/evals)
  * [ Issues  ](https://github.com/openai/evals/issues)
  * [ Pull requests  ](https://github.com/openai/evals/pulls)
  * [ Discussions  ](https://github.com/openai/evals/discussions)
  * [ Actions  ](https://github.com/openai/evals/actions)
  * [ Projects  ](https://github.com/openai/evals/projects)
  * [ Security  ](https://github.com/openai/evals/security)
  * [ Insights  ](https://github.com/openai/evals/pulse)


# openai/evals
main
[Branches](https://github.com/openai/evals/branches)[Tags](https://github.com/openai/evals/tags)
[](https://github.com/openai/evals/branches)[](https://github.com/openai/evals/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
## History
[688 Commits](https://github.com/openai/evals/commits/main/)[](https://github.com/openai/evals/commits/main/)  
[.github](https://github.com/openai/evals/tree/main/.github ".github")| [.github](https://github.com/openai/evals/tree/main/.github ".github")  
[docs](https://github.com/openai/evals/tree/main/docs "docs")| [docs](https://github.com/openai/evals/tree/main/docs "docs")  
[evals](https://github.com/openai/evals/tree/main/evals "evals")| [evals](https://github.com/openai/evals/tree/main/evals "evals")  
[examples](https://github.com/openai/evals/tree/main/examples "examples")| [examples](https://github.com/openai/evals/tree/main/examples "examples")  
[scripts](https://github.com/openai/evals/tree/main/scripts "scripts")| [scripts](https://github.com/openai/evals/tree/main/scripts "scripts")  
[tests/unit/evals](https://github.com/openai/evals/tree/main/tests/unit/evals "This path skips through empty directories")| [tests/unit/evals](https://github.com/openai/evals/tree/main/tests/unit/evals "This path skips through empty directories")  
[.gitattributes](https://github.com/openai/evals/blob/main/.gitattributes ".gitattributes")| [.gitattributes](https://github.com/openai/evals/blob/main/.gitattributes ".gitattributes")  
[.gitignore](https://github.com/openai/evals/blob/main/.gitignore ".gitignore")| [.gitignore](https://github.com/openai/evals/blob/main/.gitignore ".gitignore")  
[.pre-commit-config.yaml](https://github.com/openai/evals/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](https://github.com/openai/evals/blob/main/.pre-commit-config.yaml ".pre-commit-config.yaml")  
[LICENSE.md](https://github.com/openai/evals/blob/main/LICENSE.md "LICENSE.md")| [LICENSE.md](https://github.com/openai/evals/blob/main/LICENSE.md "LICENSE.md")  
[MANIFEST.in](https://github.com/openai/evals/blob/main/MANIFEST.in "MANIFEST.in")| [MANIFEST.in](https://github.com/openai/evals/blob/main/MANIFEST.in "MANIFEST.in")  
[Makefile](https://github.com/openai/evals/blob/main/Makefile "Makefile")| [Makefile](https://github.com/openai/evals/blob/main/Makefile "Makefile")  
[README.md](https://github.com/openai/evals/blob/main/README.md "README.md")| [README.md](https://github.com/openai/evals/blob/main/README.md "README.md")  
[SECURITY.md](https://github.com/openai/evals/blob/main/SECURITY.md "SECURITY.md")| [SECURITY.md](https://github.com/openai/evals/blob/main/SECURITY.md "SECURITY.md")  
[mypy.ini](https://github.com/openai/evals/blob/main/mypy.ini "mypy.ini")| [mypy.ini](https://github.com/openai/evals/blob/main/mypy.ini "mypy.ini")  
[pyproject.toml](https://github.com/openai/evals/blob/main/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/openai/evals/blob/main/pyproject.toml "pyproject.toml")  
View all files  
## Repository files navigation
  * [README](https://github.com/openai/evals/)
  * [License](https://github.com/openai/evals/)
  * [Security](https://github.com/openai/evals/)


# OpenAI Evals
[](https://github.com/openai/evals/#openai-evals)
> You can now configure and run Evals directly in the OpenAI Dashboard. [Get started →](https://platform.openai.com/docs/guides/evals)
Evals provide a framework for evaluating large language models (LLMs) or systems built using LLMs. We offer an existing registry of evals to test different dimensions of OpenAI models and the ability to write your own custom evals for use cases you care about. You can also use your data to build private evals which represent the common LLMs patterns in your workflow without exposing any of that data publicly.
If you are building with LLMs, creating high quality evals is one of the most impactful things you can do. Without evals, it can be very difficult and time intensive to understand how different model versions might affect your use case. In the words of [OpenAI's President Greg Brockman](https://twitter.com/gdb/status/1733553161884127435):
[![https://x.com/gdb/status/1733553161884127435?s=20](https://private-user-images.githubusercontent.com/35577566/289374940-ce7840ff-43a8-4d88-bb2f-6b207410333b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMzNTcwNjUsIm5iZiI6MTc0MzM1Njc2NSwicGF0aCI6Ii8zNTU3NzU2Ni8yODkzNzQ5NDAtY2U3ODQwZmYtNDNhOC00ZDg4LWJiMmYtNmIyMDc0MTAzMzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzMwVDE3NDYwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM3ZTE0NzU3Nzc3ZmZiYmQxNmMwNzkxZjk4YWU5NDE3N2UzOWM2YjUwNjU4MTNmNjYxYzFiNzE0MzhjMmZmYTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.RfbPIn-sjkjwjAStjJbq3bbGJ92HAtQffDtNmtccb1U)](https://private-user-images.githubusercontent.com/35577566/289374940-ce7840ff-43a8-4d88-bb2f-6b207410333b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDMzNTcwNjUsIm5iZiI6MTc0MzM1Njc2NSwicGF0aCI6Ii8zNTU3NzU2Ni8yODkzNzQ5NDAtY2U3ODQwZmYtNDNhOC00ZDg4LWJiMmYtNmIyMDc0MTAzMzNiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAzMzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMzMwVDE3NDYwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM3ZTE0NzU3Nzc3ZmZiYmQxNmMwNzkxZjk4YWU5NDE3N2UzOWM2YjUwNjU4MTNmNjYxYzFiNzE0MzhjMmZmYTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.RfbPIn-sjkjwjAStjJbq3bbGJ92HAtQffDtNmtccb1U)
## Setup
[](https://github.com/openai/evals/#setup)
To run evals, you will need to set up and specify your [OpenAI API key](https://platform.openai.com/account/api-keys). After you obtain an API key, specify it using the [`OPENAI_API_KEY` environment variable](https://platform.openai.com/docs/quickstart/step-2-setup-your-api-key). Please be aware of the [costs](https://openai.com/pricing) associated with using the API when running evals. You can also run and create evals using [Weights & Biases](https://wandb.ai/wandb_fc/openai-evals/reports/OpenAI-Evals-Demo-Using-W-B-Prompts-to-Run-Evaluations--Vmlldzo0MTI4ODA3).
**Minimum Required Version: Python 3.9**
### Downloading evals
[](https://github.com/openai/evals/#downloading-evals)
Our evals registry is stored using [Git-LFS](https://git-lfs.com/). Once you have downloaded and installed LFS, you can fetch the evals (from within your local copy of the evals repo) with:
```
cd evals
git lfs fetch --all
git lfs pull
```

This will populate all the pointer files under `evals/registry/data`.
You may just want to fetch data for a select eval. You can achieve this via:
```
git lfs fetch --include=evals/registry/data/${your eval}
git lfs pull
```

### Making evals
[](https://github.com/openai/evals/#making-evals)
If you are going to be creating evals, we suggest cloning this repo directly from GitHub and installing the requirements using the following command:
```
pip install -e .
```

Using `-e`, changes you make to your eval will be reflected immediately without having to reinstall.
Optionally, you can install the formatters for pre-committing with:
```
pip install -e .[formatters]
```

Then run `pre-commit install` to install pre-commit into your git hooks. pre-commit will now run on every commit.
If you want to manually run all pre-commit hooks on a repository, run `pre-commit run --all-files`. To run individual hooks use `pre-commit run <hook_id>`.
## Running evals
[](https://github.com/openai/evals/#running-evals)
If you don't want to contribute new evals, but simply want to run them locally, you can install the evals package via pip:
```
pip install evals
```

You can find the full instructions to run existing evals in [`run-evals.md`](https://github.com/openai/evals/blob/main/docs/run-evals.md) and our existing eval templates in [`eval-templates.md`](https://github.com/openai/evals/blob/main/docs/eval-templates.md). For more advanced use cases like prompt chains or tool-using agents, you can use our [Completion Function Protocol](https://github.com/openai/evals/blob/main/docs/completion-fns.md).
We provide the option for you to log your eval results to a Snowflake database, if you have one or wish to set one up. For this option, you will further have to specify the `SNOWFLAKE_ACCOUNT`, `SNOWFLAKE_DATABASE`, `SNOWFLAKE_USERNAME`, and `SNOWFLAKE_PASSWORD` environment variables.
## Writing evals
[](https://github.com/openai/evals/#writing-evals)
We suggest getting starting by:
  * Walking through the process for building an eval: [`build-eval.md`](https://github.com/openai/evals/blob/main/docs/build-eval.md)
  * Exploring an example of implementing custom eval logic: [`custom-eval.md`](https://github.com/openai/evals/blob/main/docs/custom-eval.md)
  * Writing your own completion functions: [`completion-fns.md`](https://github.com/openai/evals/blob/main/docs/completion-fns.md)
  * Review our starter guide for writing evals: [Getting Started with OpenAI Evals](https://cookbook.openai.com/examples/evaluation/getting_started_with_openai_evals)


Please note that we are currently not accepting evals with custom code! While we ask you to not submit such evals at the moment, you can still submit model-graded evals with custom model-graded YAML files.
If you think you have an interesting eval, please open a pull request with your contribution. OpenAI staff actively review these evals when considering improvements to upcoming models.
## FAQ
[](https://github.com/openai/evals/#faq)
Do you have any examples of how to build an eval from start to finish?
  * Yes! These are in the `examples` folder. We recommend that you also read through [`build-eval.md`](https://github.com/openai/evals/blob/main/docs/build-eval.md) in order to gain a deeper understanding of what is happening in these examples.


Do you have any examples of evals implemented in multiple different ways?
  * Yes! In particular, see `evals/registry/evals/coqa.yaml`. We have implemented small subsets of the [CoQA](https://stanfordnlp.github.io/coqa/) dataset for various eval templates to help illustrate the differences.


When I run an eval, it sometimes hangs at the very end (after the final report). What's going on?
  * This is a known issue, but you should be able to interrupt it safely and the eval should finish immediately after.


There's a lot of code, and I just want to spin up a quick eval. Help? OR,
I am a world-class prompt engineer. I choose not to code. How can I contribute my wisdom?
  * If you follow an existing [eval template](https://github.com/openai/evals/blob/main/docs/eval-templates.md) to build a basic or model-graded eval, you don't need to write any evaluation code at all! Just provide your data in JSON format and specify your eval parameters in YAML. [build-eval.md](https://github.com/openai/evals/blob/main/docs/build-eval.md) walks you through these steps, and you can supplement these instructions with the Jupyter notebooks in the `examples` folder to help you get started quickly. Keep in mind, though, that a good eval will inevitably require careful thought and rigorous experimentation!


## Disclaimer
[](https://github.com/openai/evals/#disclaimer)
By contributing to evals, you are agreeing to make your evaluation logic and data under the same MIT license as this repository. You must have adequate rights to upload any data used in an eval. OpenAI reserves the right to use this data in future service improvements to our product. Contributions to OpenAI evals will be subject to our usual Usage Policies: <https://platform.openai.com/docs/usage-policies>.
## About
Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks. 
### Resources
[ Readme ](https://github.com/openai/evals/#readme-ov-file)
### License
[ View license ](https://github.com/openai/evals/#License-1-ov-file)
### Security policy
[ Security policy ](https://github.com/openai/evals/#security-ov-file)
[ Activity](https://github.com/openai/evals/activity)
[ Custom properties](https://github.com/openai/evals/custom-properties)
### Stars
[ **15.8k** stars](https://github.com/openai/evals/stargazers)
### Watchers
[ **267** watching](https://github.com/openai/evals/watchers)
### Forks
[ **2.7k** forks](https://github.com/openai/evals/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fopenai%2Fevals&report=openai+%28user%29)
##  [Contributors 460](https://github.com/openai/evals/graphs/contributors)
  * [ ![@andrew-openai](https://avatars.githubusercontent.com/u/120423412?s=64&v=4) ](https://github.com/andrew-openai)
  * [ ![@rlbayes](https://avatars.githubusercontent.com/u/343165?s=64&v=4) ](https://github.com/rlbayes)
  * [ ![@jwang47](https://avatars.githubusercontent.com/u/1084704?s=64&v=4) ](https://github.com/jwang47)
  * [ ![@ojaffe](https://avatars.githubusercontent.com/u/28544674?s=64&v=4) ](https://github.com/ojaffe)
  * [ ![@JunShern](https://avatars.githubusercontent.com/u/7796965?s=64&v=4) ](https://github.com/JunShern)
  * [ ![@etr2460](https://avatars.githubusercontent.com/u/7409244?s=64&v=4) ](https://github.com/etr2460)
  * [ ![@ianmckenzie-oai](https://avatars.githubusercontent.com/u/140545726?s=64&v=4) ](https://github.com/ianmckenzie-oai)
  * [ ![@logankilpatrick](https://avatars.githubusercontent.com/u/35577566?s=64&v=4) ](https://github.com/logankilpatrick)
  * [ ![@danesherbs](https://avatars.githubusercontent.com/u/7956209?s=64&v=4) ](https://github.com/danesherbs)
  * [ ![@pan93412](https://avatars.githubusercontent.com/u/28441561?s=64&v=4) ](https://github.com/pan93412)
  * [ ![@thesofakillers](https://avatars.githubusercontent.com/u/26286291?s=64&v=4) ](https://github.com/thesofakillers)
  * [ ![@inwaves](https://avatars.githubusercontent.com/u/8530685?s=64&v=4) ](https://github.com/inwaves)
  * [ ![@somerandomguyontheweb](https://avatars.githubusercontent.com/u/50818265?s=64&v=4) ](https://github.com/somerandomguyontheweb)
  * [ ![@james-aung](https://avatars.githubusercontent.com/u/129281094?s=64&v=4) ](https://github.com/james-aung)


[+ 446 contributors](https://github.com/openai/evals/graphs/contributors)
## Languages
  * [ Python 79.4% ](https://github.com/openai/evals/search?l=python)
  * [ Jupyter Notebook 13.5% ](https://github.com/openai/evals/search?l=jupyter-notebook)
  * [ HTML 5.2% ](https://github.com/openai/evals/search?l=html)
  * [ Shell 1.6% ](https://github.com/openai/evals/search?l=shell)
  * [ JavaScript 0.3% ](https://github.com/openai/evals/search?l=javascript)
  * [ Dockerfile 0.0% ](https://github.com/openai/evals/search?l=dockerfile)


## Footer
[ ](https://github.com "GitHub") © 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You can’t perform that action at this time. 
