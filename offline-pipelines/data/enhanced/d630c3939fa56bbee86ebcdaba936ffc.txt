Agree & Join LinkedIn 
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy). 
[ Skip to main content ](https://www.linkedin.com/posts/aurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj?utm_source=share&utm_medium=member_desktop/#main-content) [ LinkedIn ](https://www.linkedin.com/?trk=public_post_nav-header-logo)
  * [ Articles  ](https://www.linkedin.com/pulse/topics/home/?trk=public_post_guest_nav_menu_articles)
  * [ People  ](https://www.linkedin.com/pub/dir/+/+?trk=public_post_guest_nav_menu_people)
  * [ Learning  ](https://www.linkedin.com/learning/search?trk=public_post_guest_nav_menu_learning)
  * [ Jobs  ](https://www.linkedin.com/jobs/search?trk=public_post_guest_nav_menu_jobs)
  * [ Games  ](https://www.linkedin.com/games?trk=public_post_guest_nav_menu_games)


[ Join now ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_nav-header-join) [ Sign in ](https://www.linkedin.com/login?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&fromSignIn=true&trk=public_post_nav-header-signin)
#  Aurimas GriciÅ«nasâ€™ Post
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
  * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)


A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post-text) if you want to get a daily dose of useful AI related content in your feed!
[ 1,361  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_social-actions-reactions) [ 67 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment-cta)
Share 
  * Copy
  * LinkedIn
  * Facebook
  * Twitter


[ ](https://in.linkedin.com/in/pooja-jain-898253106?trk=public_post_comment_actor-image)
[ POOJA JAIN ](https://in.linkedin.com/in/pooja-jain-898253106?trk=public_post_comment_actor-name)
Storyteller | Linkedin Top Voice 2024 | Senior Data Engineer@ Globant | Linkedin Learning Instructor | 2xGCP & AWS Certified | LICAP'2022 
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Helpful post on the AI Agents Memory!! [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_comment-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 4 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 5 Reactions 
[ ](https://in.linkedin.com/in/sukritgoel?trk=public_post_comment_actor-image)
[ Sukrit Goel ](https://in.linkedin.com/in/sukritgoel?trk=public_post_comment_actor-name)
Founder & CEO @InteligenAI
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Thanks for breaking this down so clearly! You made it so much easier to understand how AI agents manage context and past interactions.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 2 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 3 Reactions 
[ ](https://in.linkedin.com/in/shashi-bhushan1?trk=public_post_comment_actor-image)
[ Shashi Bhushan ](https://in.linkedin.com/in/shashi-bhushan1?trk=public_post_comment_actor-name)
Data Analyst | Data Scientist | AI & ML Specialist | GenAI & LLM Enthusiast | Vertex AI Expert | Python | PySpark | Time Series Analysis | Anomaly Detection | GCP | Streamlit | BigQuery | M.Tech (BITS Pilani) | ISO 50001
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Wow, this is like giving our AI agents their own little memory palace! ğŸ° It's fascinating to see how they can remember past interactions (episodic), know their own facts (semantic), follow the rules (procedural), and even juggle short-term tasks like a pro! ğŸ§ ğŸ’¡ Thanks for breaking it down so clearly. Now, if only I could get my own memory to work this efficiently... ğŸ˜… #AI #MemoryGoals #MindBlown
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 4 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 5 Reactions 
[ ](https://fr.linkedin.com/in/fsndzomga/en?trk=public_post_comment_actor-image)
[ Franck N. ](https://fr.linkedin.com/in/fsndzomga/en?trk=public_post_comment_actor-name)
Freelance Senior Consultant - Data | Generative AI | Marketing Analytics
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Once we solve memory, agentic workflows will become uncannily efficient. And it is sure to happen in 2025. Buckle up ! [https://medium.com/thoughts-on-machine-learning/building-powerful-open-source-ai-agents-with-dspy-langgraph-crewai-and-nebius-ai-1-a2b81255b7ea](https://medium.com/thoughts-on-machine-learning/building-powerful-open-source-ai-agents-with-dspy-langgraph-crewai-and-nebius-ai-1-a2b81255b7ea?trk=public_post_comment-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 6 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 7 Reactions 
[ ](https://in.linkedin.com/in/shivani-virdi-115836121?trk=public_post_comment_actor-image)
[ Shivani Virdi ](https://in.linkedin.com/in/shivani-virdi-115836121?trk=public_post_comment_actor-name)
Engineering at Microsoft | Simplifying AI for Everyone | Empowering Productivity with Proven Frameworks and Processes
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Very thorough explanation, [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_comment-text)! I really like the infographic!
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 2 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 3 Reactions 
[ ](https://www.linkedin.com/in/bijit-ghosh-48281a78?trk=public_post_comment_actor-image)
[ Bijit Ghosh ](https://www.linkedin.com/in/bijit-ghosh-48281a78?trk=public_post_comment_actor-name)
CTO - Global Head of Cloud Product & Engineering & AI/ML - at Deutsche Bank
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


The way I see it, When a user interacts with an AI agent, the interaction triggers the retrieval of relevant information from long-term memory (episodic, semantic, and procedural) which is then compiled into a dynamic short-term memory (the prompt) that is sent to the LLM for processing and response generation. This process enables the agent to utilize past experiences and stored knowledge to provide contextually relevant answers.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 5 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 6 Reactions 
[ ](https://fr.linkedin.com/in/mzmmoazam?trk=public_post_comment_actor-image)
[ Mohammad Moazam ](https://fr.linkedin.com/in/mzmmoazam?trk=public_post_comment_actor-name)
LLM Tech Lead @ Stellantis | NLP | Computer Vision | Technomancer
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Love the illustration [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_comment-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 3 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 4 Reactions 
[ ](https://au.linkedin.com/in/johnnycosgrove?trk=public_post_comment_actor-image)
[ John (JC) Cosgrove ](https://au.linkedin.com/in/johnnycosgrove?trk=public_post_comment_actor-name)
Partner @ Cloudwerx || Founder and former CEO Lightfold || Advisor, Speaker, Strategist and Practitioner for Applied Generative and Agentic AI + Data || Total Lunatic
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


I like your four classifications and they are now my canon :-) I will cite you wherever I use it [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_comment-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 3 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 4 Reactions 
[ ](https://uk.linkedin.com/in/tarunsonania?trk=public_post_comment_actor-image)
[ Tarun S. ](https://uk.linkedin.com/in/tarunsonania?trk=public_post_comment_actor-name)
Data Architect | Data Management | Data Strategy | Data Product
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


As always, like the visualization to ease learnings (the concepts). Will come back with few questions.
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 3 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 4 Reactions 
[ ](https://lk.linkedin.com/in/lahiru-fernando-6262a429?trk=public_post_comment_actor-image)
[ Lahiru Fernando ](https://lk.linkedin.com/in/lahiru-fernando-6262a429?trk=public_post_comment_actor-name)
Country Director (Sri Lanka), APAC RPA Lead, & Practice Head - Artificial Intelligence at Boundaryless/ Author/ AI Ambassador/ 6x UiPath MVP - Document Understanding and Artificial Intelligence/ Mentor/ Public Speaker
2mo 
  * [ Report this comment ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=COMMENT&_f=guest-reporting)


Very well explained.. Thanks for sharing this... [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_comment-text)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_like) [ Reply  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reply) [ 4 Reactions ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_comment_reactions) 5 Reactions 
[ See more comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_see-more-comments)
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_feed-cta-banner-cta)
##  More Relevant Posts 
  * [](https://www.linkedin.com/posts/harveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX)
[ ](https://ph.linkedin.com/in/harveyjaysison?trk=public_post_feed-actor-image)
[ Harvey Jay Sison ](https://ph.linkedin.com/in/harveyjaysison?trk=public_post_feed-actor-name)
AI Engineer â€¢ Gen AI & Automation @ P&G â€¢ Ex-Spenmo (YC S21) â€¢ Co-Lead, GDG Cloud Manila â€¢ BS Management Engineering â€˜21, ADMU 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
ğŸš€ AI Agent Memory Simplified AI agents use memory to plan and act based on past interactions or data, structured into: 1ï¸âƒ£ Episodic: Stores past actions/interactions (e.g., vector databases). 2ï¸âƒ£ Semantic: External/self-knowledge, grounding context (e.g., RAG). 3ï¸âƒ£ Procedural: Prompts, tools, guardrails (stored in Git/registries). 4ï¸âƒ£ Short-Term: Compiled memory for immediate tasks. Iâ€™ve primarily worked with vector databases and data dictionaries so farâ€”excited to explore more memory setups! ğŸ’¡ How do you approach memory in AI agents? ğŸ‘‡ Visual explanation below!
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 12  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fharveyjaysison_ai-agent-memory-simplified-ai-agents-activity-7286530576881172481-S8fX&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/anastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT)
[ ](https://id.linkedin.com/in/anastasia-a-27335219b?trk=public_post_feed-actor-image)
[ Anastasia A. ](https://id.linkedin.com/in/anastasia-a-27335219b?trk=public_post_feed-actor-name)
I Simplify Systems to Scale Businesses ğŸš€ | IT System Analyst 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
AI with a structured brain: â€¢ LLMs are the reasoning cortex. â€¢ Memories (episodic, semantic, procedural) act as the long-term storage, strategy hub, and rulebook. â€¢ Short-term memory acts as the working memory for immediate context. â€¢ Tools and APIs are the hands and eyes, enabling real-world interaction. This layered architecture makes the system dynamic, capable, and collaborative without the "magic" of a super robot, just intelligent design.
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 8  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_social-actions-reactions) [ 2 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fanastasia-a-27335219b_ai-with-a-structured-brain-llms-are-the-activity-7284766847529336832-8BnT&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/francknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx)
[ ](https://ee.linkedin.com/in/francknouyrigat?trk=public_post_feed-actor-image)
[ Franck Nouyrigat ](https://ee.linkedin.com/in/francknouyrigat?trk=public_post_feed-actor-name)
Vibe Founder@ Stealth / Electis / StartupWeekend / startup next / Up Global / recorp.co / Massive / I focus on ambitious tech projects with high impact 
2mo  Edited 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
2025 will be an amazing year! here are my thoughts / updates Regarding the ai revolution powered by agents, let me start with a technical note related to the shared article: Memory management will def be key to solid architectures, Iâ€™m convinced what I called agent-oriented programming last year will also be about how to break down LLMsâ€™ requests to stable output at a task level. Eg you want to deeply understand the business to break down jobs to stable tasks (thatâ€™s the hard part) that can complement and later replace / scale existing jobs made of hundreds of tasks. The smaller the task / the more stable it will be. Hugging Face has a cool approach to do that it seems (programmatic), and Lang graph is also interesting. Microsoft seems to push the idea of general standard agents on top of memory management with context windows expanding crazy this year, it means stable tasksâ€™ output will be more and more complex aligned with Eric Schmidt vision â€”- back to 2025 for me, you will see me between estonia / silicon valley! Canâ€™t wait to see some of my lost ğŸ‡ºğŸ‡¸ friends :) gonna have a lot of fun building [muhu.ai](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fmuhu%2Eai&urlhash=-_Kr&trk=public_post-text) with [Teodos Pejoski](https://www.linkedin.com/in/teodos?trk=public_post-text) this year and expanding our messy middle podcast about post exit founders with [Gabriel Schillinger](https://www.linkedin.com/in/gabrielschillinger?trk=public_post-text) and teddy. we will also ramp up [electis.com](https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Felectis%2Ecom&urlhash=Jwdm&trk=public_post-text) growth using AI / agents to streamline our operation and scale fast with [Gilles MentrÃ©](https://fr.linkedin.com/in/gilles-mentr%C3%A9-88b9856?trk=public_post-text) / planning to launch our first ğŸ‡ºğŸ‡¸ product for HOA voting 2025 is just the beginning. Between crypto, AI, mixed reality, robotics, and all its outcomes (health, material scienceâ€¦), the next decade will be a time where those who missed it will just be forgotten. Of course letâ€™s not forget about defense! especially in Europe, ping me if you are raising for scaling existing startups (working with the amazing [Adrien Ramesan](https://fr.linkedin.com/in/adrienramesan?trk=public_post-text) and [AllStrat](https://fr.linkedin.com/company/allstrat?trk=public_post-text) as a tech advisor ) also ping me if dropping by estonia! We re running ai salon there with [David Clark](https://ee.linkedin.com/in/dcestuk?trk=public_post-text) and of course [Massive](https://www.linkedin.com/company/joinmassive?trk=public_post-text) with [Brian Kennish](https://www.linkedin.com/in/oldestlivingboy?trk=public_post-text) and [Jason Grad](https://www.linkedin.com/in/jasongrad?trk=public_post-text) are in the center of those revolutions! wishing all of you a lot of Ai fun â¤ï¸
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 18  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_social-actions-reactions) [ 4 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Ffrancknouyrigat_2025-will-be-an-amazing-year-here-are-my-activity-7286297912815329280-tfmx&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/aymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX)
[ ](https://fr.linkedin.com/in/aymenmouelhi/en?trk=public_post_feed-actor-image)
[ aymen mouelhi ](https://fr.linkedin.com/in/aymenmouelhi/en?trk=public_post_feed-actor-name)
Director of Engineering - Data & AI at Chance 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Insightful breakdown of how AI agent memory functions! A great read for anyone curious about the mechanics behind context retention and intelligent interactions.
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 5  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_social-actions-reactions) [ 2 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Faymenmouelhi_insightful-breakdown-of-how-ai-agent-memory-activity-7287038512418230272-9TTX&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/baskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45)
[ ](https://www.linkedin.com/in/baskarv?trk=public_post_feed-actor-image)
[ Baskar Velusamy ](https://www.linkedin.com/in/baskarv?trk=public_post_feed-actor-name)
Tech Architect & GenAI Specialist | Digital Transformation Leader in Agentic AI, LLMs, Cloud & HPC | Passionate coder 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
AI agent memory is essential for creating systems that can understand and respond effectively. Long-term memory helps the agent recall past interactions, store relevant knowledge, and follow defined rules. Short-term memory focuses on pulling together the information needed to handle current tasks. Tools like vector databases and clear instructions make this process smooth. When both memory types work well together, the agent becomes smarter and more adaptable. Long/short term memory unlocks Gen AIâ€™s potential
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 3  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_social-actions-reactions) [ 2 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fbaskarv_ai-agent-memory-is-essential-for-creating-activity-7287448966131064832-_V45&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/patriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM)
[ ](https://ar.linkedin.com/in/patriciopagani?trk=public_post_feed-actor-image)
[ Patricio Pagani ](https://ar.linkedin.com/in/patriciopagani?trk=public_post_feed-actor-name)
Founder & Lead Puma @TheBlackPuma | Growth Hacker | VC | Data & Tech Angel Investor & Advisor | Futurist | Exponential Thinker | Musician 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
How AI Agent memory works, including a short explanation of the different memory types that you can find (Eg. episodic, semantic, short and long term). Great post by [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post-text) ğŸ‘ğŸ¼ 
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 45  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_social-actions-reactions) [ 3 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fpatriciopagani_how-ai-agent-memory-works-including-a-short-activity-7286732302586384384--BBM&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/inmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY)
[ ](https://www.linkedin.com/in/inmankevin?trk=public_post_feed-actor-image)
[ Kevin Inman ](https://www.linkedin.com/in/inmankevin?trk=public_post_feed-actor-name)
ğŸš€ Technology Executive | AI & Cloud Transformation | SVP, VP, CTO | Crisis Leadership & Digital Innovation | Keynote Speaker & Thought Leader on AI, Leadership & Digital Transformation 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Finmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
This is a very well written explanation on AI agents and the memory they leverage, and why. As we continue to improve upon this throughout the year, I believe youâ€™ll once again see major advancements in how folks use AI and the value these agents deliver on. I see 2025 to be the year of the agents, followed up by 2026 being the year robots exploded into mainstream - ushering us then into 2027 and likely AGI. What a ride we are on!
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 5  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Finmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Finmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Finmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Finmankevin_this-is-a-very-well-written-explanation-on-activity-7287448225995702272-tQVY&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/ganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N)
[ ](https://in.linkedin.com/in/ganeshjagadeesan?trk=public_post_feed-actor-image)
[ Ganesh Jagadeesan ](https://in.linkedin.com/in/ganeshjagadeesan?trk=public_post_feed-actor-name)
Enterprise Data Science Specialist @Mastech Digital | NLP | NER | Deep Learning | Gen AI | MLops 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
This is such a fantastic explanation of AI Agent Memoryâ€”thank you for breaking it down so clearly! ğŸŒŸ The way youâ€™ve categorized memory into episodic, semantic, procedural, and short-term/working memory provides a comprehensive framework that aligns beautifully with how intelligent agents manage context and improve over time. ğŸš€ 1ï¸âƒ£ Episodic Memory: I love how youâ€™ve highlighted its role in capturing past interactions and storing them in a vector database. This approach ensures agents can retrieve historical context efficiently, making interactions more personalized and adaptive. Perfect for applications like customer support or long-term conversational AI. ğŸ§ ğŸ” 2ï¸âƒ£ Semantic Memory: This type of memory acting as the agent's knowledge base is so crucial. By grounding responses with domain-specific or internal knowledge, agents become far more accurate and reliable, especially in dynamic environments like RAG applications. ğŸŒğŸ“š 3ï¸âƒ£ Procedural Memory: Your point about defining systemic structures like prompts, tools, and guardrails is spot on. Keeping these elements stored in registries or Git ensures that agents operate consistently while allowing for easy scalability and updatesâ€”a must-have for production systems. âš™ï¸ğŸ“‚ 4ï¸âƒ£ Short-Term/Working Memory: Pulling together relevant long-term memories into context-rich prompts is the cornerstone of enabling agents to respond intelligently. This synthesis ensures agents are not only reactive but also proactive in delivering meaningful actions. ğŸ’¡âœ¨ The distinction between long-term (episodic, semantic, procedural) and short-term/working memory mirrors human-like cognition beautifully. It highlights how AI agents can mimic natural decision-making processes with the right architecture. Thank you for such an insightful post! This framework makes it easier to design robust, context-aware Agentic AI systems. Excited to see more of your thoughts on implementing these ideas in real-world scenarios! ğŸ™Œ [#AgenticAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fagenticai&trk=public_post-text) [#AIAgents](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiagents&trk=public_post-text) [#MemoryInAI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmemoryinai&trk=public_post-text) [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post-text) [#AIInnovation](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Faiinnovation&trk=public_post-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post-text)
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 15  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_social-actions-reactions) [ 1 Comment ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fganeshjagadeesan_agenticai-aiagents-memoryinai-activity-7285149439311130624-T98N&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/johnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5)
[ ](https://www.linkedin.com/in/johnlayers?trk=public_post_feed-actor-image)
[ John Ayers ](https://www.linkedin.com/in/johnlayers?trk=public_post_feed-actor-name)
Digital Disruption | Agentic AI | Business Transformation | Marketing Strategy | Partner Solutions | Guest Speaker 
2mo  Edited 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
AGENT MEMORY This post is a helpful breakdown of AI Agent Memory from [Aurimas GriciÅ«nas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post-text) It highlights how episodic, semantic, and procedural memory work together to create a foundation for short-term, task-specific responses. Building on this, I find it fascinating (and perhaps a bit concerning) how an agentâ€™s memory can enable a logical progression in influencing user actions or decisions over time. For example, if a human prompt includes personal details like â€œI donâ€™t like exerciseâ€ or â€œIâ€™m stressed at work,â€ the agent can recall these interactions to guide responses that subtly nudge behaviorâ€”tailoring advice to be more actionable and relevant to the userâ€™s preferences and patterns. However, this raises an interesting point about the potential for AI agents to not only assist but influence users in how they think, act, or behave. Over time, as memory grows, (correct me if Iâ€™m wrong) these interactions could evolve into a highly personalized feedback loop, encouraging specific actions aligned with the userâ€™s stated goals. Ethical design and user autonomy will play a crucial role in ensuring these agents act as supportive guides rather than directive forces. Again - Great postâ€”and a framework that invaluable for understanding the interplay between memory and behavior in AI systems!
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 15  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_social-actions-reactions) [ 2 Comments ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_social-actions-comments)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fjohnlayers_agent-memory-this-post-is-a-helpful-breakdown-activity-7286639096268050432-rsp5&trk=public_post_feed-cta-banner-cta)
  * [](https://www.linkedin.com/posts/davidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4)
[ ](https://es.linkedin.com/in/davidpalomo?trk=public_post_feed-actor-image)
[ David P. ](https://es.linkedin.com/in/davidpalomo?trk=public_post_feed-actor-name)
Engineering manager 
2mo 
    * [ Report this post ](https://www.linkedin.com/uas/login?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdavidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4&trk=public_post_ellipsis-menu-semaphore-sign-in-redirect&guestReportContentType=POST&_f=guest-reporting)
Really useful post to understand how the agents work. We should understand this clearly when we design our own agents
[ ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-image)
[ Aurimas GriciÅ«nas ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare_feed-actor-name) Aurimas GriciÅ«nas is an Influencer
Founder @ SwirlAI â€¢ AI Engineer â€¢ Follow me to Learn about AI Systems â€¢ Author of SwirlAI Newsletter â€¢ Public Speaker 
2mo 
A simple way to explain ğ—”ğ—œ ğ—”ğ—´ğ—²ğ—»ğ˜ ğ— ğ—²ğ—ºğ—¼ğ—¿ğ˜†. In general, the memory for an agent is something that we provide via context in the prompt passed to LLM that helps the agent to better plan and react given past interactions or data not immediately available. It is useful to group the memory into four types: ğŸ­. Episodic - This type of memory contains past interactions and actions performed by the agent. After an action is taken, the application controlling the agent would store the action in some kind of persistent storage so that it can be retrieved later if needed. A good example would be using a vector Database to store semantic meaning of the interactions. ğŸ®. Semantic - Any external information that is available to the agent and any knowledge the agent should have about itself. You can think of this as a context similar to one used in RAG applications. It can be internal knowledge only available to the agent or a grounding context to isolate part of the internet scale data for more accurate answers. ğŸ¯. Procedural - This is systemic information like the structure of the System Prompt, available tools, guardrails etc. It will usually be stored in Git, Prompt and Tool Registries. ğŸ°. Occasionally, the agent application would pull information from long-term memory and store it locally if it is needed for the task at hand. ğŸ±. All of the information pulled together from the long-term or stored in local memory is called short-term or working memory. Compiling all of it into a prompt will produce the prompt to be passed to the LLM and it will provide further actions to be taken by the system. We usually label 1. - 3. as Long-Term memory and 5. as Short-Term memory. A visual explanation of potential implementation details ğŸ‘‡ And that is it! The rest is all about how you architect the flow of your Agentic systems. What do you think about memory in AI Agents? [#LLM](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fllm&trk=public_post_reshare-text) [#AI](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fai&trk=public_post_reshare-text) [#MachineLearning](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Ffeed%2Fhashtag%2Fmachinelearning&trk=public_post_reshare-text) ---------- Be sure to â™»ï¸ repost if you found the article useful and follow [Aurimas](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_reshare-text) if you want to get a daily dose of useful AI related content in your feed!
[ 3  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdavidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4&trk=public_post_social-actions-reactions)
[ Like  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdavidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4&trk=public_post_like-cta) [ Comment  ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdavidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4&trk=public_post_comment-cta)
Share 
    * Copy
    * LinkedIn
    * Facebook
    * Twitter
To view or add a comment, [sign in](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww.linkedin.com%2Fposts%2Fdavidpalomo_really-useful-post-to-understand-how-the-activity-7286661182940139521-_zo4&trk=public_post_feed-cta-banner-cta)


![](https://media.licdn.com/dms/image/v2/D4D16AQFuRQIEnPn1Jg/profile-displaybackgroundimage-shrink_200_800/profile-displaybackgroundimage-shrink_200_800/0/1734371745230?e=2147483647&v=beta&t=7sts8SKLv7EPydLH-2Cl-MC2iCldgkwoh6x5T7ng_TE)
138,413 followers 
  * [ 694 Posts ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fin%2Faurimas-griciunas%2Frecent-activity%2F&trk=public_post_follow-posts)


[ View Profile ](https://lt.linkedin.com/in/aurimas-griciunas?trk=public_post_follow-view-profile) [ Connect ](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Ffeed%2Fupdate%2Furn%3Ali%3Aactivity%3A7284520203705610240&trk=public_post_follow)
##  Explore topics 
  * [ Sales ](https://www.linkedin.com/pulse/topics/sales-s5/)
  * [ Marketing ](https://www.linkedin.com/pulse/topics/marketing-s2461/)
  * [ IT Services ](https://www.linkedin.com/pulse/topics/it-services-s57547/)
  * [ Business Administration ](https://www.linkedin.com/pulse/topics/business-administration-s50111/)
  * [ HR Management ](https://www.linkedin.com/pulse/topics/hr-management-s50359/)
  * [ Engineering ](https://www.linkedin.com/pulse/topics/engineering-s166/)
  * [ Soft Skills ](https://www.linkedin.com/pulse/topics/soft-skills-s2976/)
  * [ See All ](https://www.linkedin.com/pulse/topics/home/)


  * LinkedIn Â© 2025
  * [ About ](https://about.linkedin.com?trk=d_public_post_footer-about)
  * [ Accessibility ](https://www.linkedin.com/accessibility?trk=d_public_post_footer-accessibility)
  * [ User Agreement ](https://www.linkedin.com/legal/user-agreement?trk=d_public_post_footer-user-agreement)
  * [ Privacy Policy ](https://www.linkedin.com/legal/privacy-policy?trk=d_public_post_footer-privacy-policy)
  * [ Your California Privacy Choices ](https://www.linkedin.com/legal/california-privacy-disclosure?trk=d_public_post_footer-california-privacy-rights-act)
  * [ Cookie Policy ](https://www.linkedin.com/legal/cookie-policy?trk=d_public_post_footer-cookie-policy)
  * [ Copyright Policy ](https://www.linkedin.com/legal/copyright-policy?trk=d_public_post_footer-copyright-policy)
  * [ Brand Policy ](https://brand.linkedin.com/policies?trk=d_public_post_footer-brand-policy)
  * [ Guest Controls ](https://www.linkedin.com/psettings/guest-controls?trk=d_public_post_footer-guest-controls)
  * [ Community Guidelines ](https://www.linkedin.com/legal/professional-community-policies?trk=d_public_post_footer-community-guide)
  *     * Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic) 
    * à¦¬à¦¾à¦‚à¦²à¦¾ (Bangla) 
    * ÄŒeÅ¡tina (Czech) 
    * Dansk (Danish) 
    * Deutsch (German) 
    * Î•Î»Î»Î·Î½Î¹ÎºÎ¬ (Greek) 
    * **English (English)**
    * EspaÃ±ol (Spanish) 
    * ÙØ§Ø±Ø³ÛŒ (Persian) 
    * Suomi (Finnish) 
    * FranÃ§ais (French) 
    * à¤¹à¤¿à¤‚à¤¦à¥€ (Hindi) 
    * Magyar (Hungarian) 
    * Bahasa Indonesia (Indonesian) 
    * Italiano (Italian) 
    * ×¢×‘×¨×™×ª (Hebrew) 
    * æ—¥æœ¬èª (Japanese) 
    * í•œêµ­ì–´ (Korean) 
    * à¤®à¤°à¤¾à¤ à¥€ (Marathi) 
    * Bahasa Malaysia (Malay) 
    * Nederlands (Dutch) 
    * Norsk (Norwegian) 
    * à¨ªà©°à¨œà¨¾à¨¬à©€ (Punjabi) 
    * Polski (Polish) 
    * PortuguÃªs (Portuguese) 
    * RomÃ¢nÄƒ (Romanian) 
    * Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian) 
    * Svenska (Swedish) 
    * à°¤à±†à°²à±à°—à± (Telugu) 
    * à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ (Thai) 
    * Tagalog (Tagalog) 
    * TÃ¼rkÃ§e (Turkish) 
    * Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° (Ukrainian) 
    * Tiáº¿ng Viá»‡t (Vietnamese) 
    * ç®€ä½“ä¸­æ–‡ (Chinese (Simplified)) 
    * æ­£é«”ä¸­æ–‡ (Chinese (Traditional)) 
Language 


##  Sign in to view more content 
Create your free account or sign in to continue your search 
Sign in 
##  Welcome back 
Email or phone 
Password 
Show
[Forgot password?](https://www.linkedin.com/uas/request-password-reset?trk=public_post_contextual-sign-in-modal_sign-in-modal_forgot_password) Sign in 
or 
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=public_post_contextual-sign-in-modal_sign-in-modal_auth-button_cookie-policy). 
New to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_contextual-sign-in-modal_sign-in-modal_join-link)
or 
New to LinkedIn? [Join now](https://www.linkedin.com/signup/cold-join?session_redirect=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fposts%2Faurimas-griciunas_llm-ai-machinelearning-activity-7284520203705610240-gkSj&trk=public_post_contextual-sign-in-modal_join-link)
By clicking Continue to join or sign in, you agree to LinkedInâ€™s [User Agreement](https://www.linkedin.com/legal/user-agreement?trk=linkedin-tc_auth-button_user-agreement), [Privacy Policy](https://www.linkedin.com/legal/privacy-policy?trk=linkedin-tc_auth-button_privacy-policy), and [Cookie Policy](https://www.linkedin.com/legal/cookie-policy?trk=linkedin-tc_auth-button_cookie-policy). 
