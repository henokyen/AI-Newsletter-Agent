{
    "id": "802c0bef20fb5eff3d31b71b8ce70cbb",
    "metadata": {
        "id": "802c0bef20fb5eff3d31b71b8ce70cbb",
        "url": "https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/",
        "title": "Build, train, deploy, and monitor a machine learning model with Amazon SageMaker Studio",
        "properties": {
            "description": "Learn how to build, train, deploy, and monitor a machine learning model with Amazon SageMaker Studio in 1 hour.",
            "keywords": null,
            "author": null,
            "og:title": "Build, train, deploy, and monitor a machine learning model with Amazon SageMaker Studio",
            "og:type": "company",
            "og:url": "https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/",
            "og:image": "https://a0.awsstatic.com/libra-css/images/logos/aws_logo_smile_1200x630.png",
            "og:site_name": "Amazon Web Services, Inc."
        }
    },
    "parent_metadata": {
        "id": "fdc2bb3cc00c4da2d7864e39ae5ccdc2",
        "url": "https://www.notion.so/SageMaker-fdc2bb3cc00c4da2d7864e39ae5ccdc2",
        "title": "SageMaker",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "## Select your cookie preferences\nWe use essential cookies and similar tools that are necessary to provide our site and services. We use performance cookies to collect anonymous statistics, so we can understand how customers use our site and make improvements. Essential cookies cannot be deactivated, but you can choose “Customize” or “Decline” to decline performance cookies. If you agree, AWS and approved third parties will also use cookies to provide useful site features, remember your preferences, and display relevant content, including relevant advertising. To accept or decline all non-essential cookies, choose “Accept” or “Decline.” To make more detailed choices, choose “Customize.”\nAcceptDeclineCustomize\n## Customize cookie preferences\nWe use cookies and similar tools (collectively, \"cookies\") for the following purposes.\n### Essential\nEssential cookies are necessary to provide our site and services and cannot be deactivated. They are usually set in response to your actions on the site, such as setting your privacy preferences, signing in, or filling in forms. \n### Performance\nPerformance cookies provide anonymous statistics about how customers navigate our site so we can improve site experience and performance. Approved third parties may perform analytics on our behalf, but they cannot use the data for their own purposes.\nAllow performance category\nAllowed\n### Functional\nFunctional cookies help us provide useful site features, remember your preferences, and display relevant content. Approved third parties may set these cookies to provide certain site features. If you do not allow these cookies, then some or all of these services may not function properly.\nAllow functional category\nAllowed\n### Advertising\nAdvertising cookies may be set through our site by us or our advertising partners and help us deliver relevant marketing content. If you do not allow these cookies, you will experience less relevant advertising.\nAllow advertising category\nAllowed\nBlocking some types of cookies may impact your experience of our sites. You may review and change your choices at any time by selecting Cookie preferences in the footer of this site. We and selected third-parties use cookies or similar technologies as specified in the [AWS Cookie Notice](https://aws.amazon.com/legal/cookies/).\nCancelSave preferences\n## Your privacy choices\nWe display ads relevant to your interests on AWS sites and on other properties, including cross-context behavioral advertising. Cross-context behavioral advertising uses data from one site or app to advertise to you on a different company’s site or app.\nTo not allow AWS cross-context behavioral advertising based on cookies or similar technologies, select “Don't allow” and “Save privacy choices” below, or visit an AWS site with a legally-recognized decline signal enabled, such as the Global Privacy Control. If you delete your cookies or visit this site from a different browser or device, you will need to make your selection again. For more information about cookies and how we use them, please read our [AWS Cookie Notice](https://aws.amazon.com/legal/cookies/).\nCross-context behavioral ads\nAllowDon't allow\nTo not allow all other AWS cross-context behavioral advertising, [complete this form by email](https://pulse.aws/application/ZRPLWLL6?p=0).\nFor more information about how AWS handles your information, please read the [AWS Privacy Notice](https://aws.amazon.com/privacy/).\nCancelSave privacy choices\n## Unable to save cookie preferences\nWe will only store essential cookies at this time, because we were unable to save your cookie preferences.If you want to change your cookie preferences, try again later using the link in the AWS console footer, or contact support if the problem persists.\nDismiss\n[ Skip to main content](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/#aws-page-content-main)\n[Click here to return to Amazon Web Services homepage](https://aws.amazon.com/?nc2=h_lg)\n[About AWS](https://aws.amazon.com/about-aws/?nc2=h_header) [Contact Us](https://aws.amazon.com/contact-us/?nc2=h_header) [ Support ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/) [ English ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/) [ My Account ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ Sign In](https://console.aws.amazon.com/console/home?nc2=h_ct&src=header-signin)\n[ Create an AWS Account ](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct&src=header_signup)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\nClose\nProfile \nYour profile helps improve your interactions with select AWS experiences. \n[ Login](https://auth.aws.amazon.com/sign-in)\nClose\nProfile \nYour profile helps improve your interactions with select AWS experiences. \n[ View profile](https://aws.amazon.com/profile)\n[ Log out](https://auth.aws.amazon.com/sign-out)\n  * [Amazon Q](https://aws.amazon.com/q/?nc2=h_ql_prod_l1_q)\n  * [Products](https://aws.amazon.com/products/?nc2=h_ql_prod)\n  * [Solutions](https://aws.amazon.com/solutions/?nc2=h_ql_sol)\n  * [Pricing](https://aws.amazon.com/pricing/?nc2=h_ql_pr)\n  * [Documentation](https://aws.amazon.com/documentation-overview/?nc2=h_ql_doc_do)\n  * [Learn](https://aws.amazon.com/getting-started/?nc2=h_ql_le)\n  * [Partner Network](https://aws.amazon.com/partners/?nc2=h_ql_pn)\n  * [AWS Marketplace](https://aws.amazon.com/marketplace/?nc2=h_ql_mp)\n  * [Customer Enablement](https://aws.amazon.com/customer-enablement/?nc2=h_ql_ce)\n  * [Events](https://aws.amazon.com/events/?nc2=h_ql_ev)\n  * [Explore More ](https://aws.amazon.com/contact-us/?nc2=h_ql_exm)\n\n\nClose\n  * [عربي](https://aws.amazon.com/ar/?nc1=h_ls)\n  * [Bahasa Indonesia](https://aws.amazon.com/id/?nc1=h_ls)\n  * [Deutsch](https://aws.amazon.com/de/?nc1=h_ls)\n  * [English](https://aws.amazon.com/?nc1=h_ls)\n  * [Español](https://aws.amazon.com/es/?nc1=h_ls)\n  * [Français](https://aws.amazon.com/fr/?nc1=h_ls)\n  * [Italiano](https://aws.amazon.com/it/?nc1=h_ls)\n  * [Português](https://aws.amazon.com/pt/?nc1=h_ls)\n\n\n  * [Tiếng Việt](https://aws.amazon.com/vi/?nc1=f_ls)\n  * [Türkçe](https://aws.amazon.com/tr/?nc1=h_ls)\n  * [Ρусский](https://aws.amazon.com/ru/?nc1=h_ls)\n  * [ไทย](https://aws.amazon.com/th/?nc1=f_ls)\n  * [日本語](https://aws.amazon.com/jp/?nc1=h_ls)\n  * [한국어](https://aws.amazon.com/ko/?nc1=h_ls)\n  * [中文 (简体)](https://aws.amazon.com/cn/?nc1=h_ls)\n  * [中文 (繁體)](https://aws.amazon.com/tw/?nc1=h_ls)\n\n\nClose\n  * [My Profile](https://aws.amazon.com/profile/?nc2=h_m_mc)\n  * [Sign out of AWS Builder ID](https://auth.aws.amazon.com/sign-out/?nc2=h_m_mc)\n  * [AWS Management Console](https://console.aws.amazon.com/?nc2=h_m_mc)\n  * [Account Settings](https://console.aws.amazon.com/billing/home#/account?nc2=h_m_ma)\n  * [Billing & Cost Management](https://console.aws.amazon.com/billing/home?nc2=h_m_bc)\n  * [Security Credentials](https://console.aws.amazon.com/iam/home?nc2=h_m_sc#security_credential)\n  * [AWS Personal Health Dashboard](https://phd.aws.amazon.com/?nc2=h_m_sc)\n\n\nClose\n  * [Support Center](https://console.aws.amazon.com/support/home/?nc2=h_ql_cu)\n  * [Expert Help](https://iq.aws.amazon.com/?utm=mkt.nav)\n  * [Knowledge Center](https://repost.aws/knowledge-center/?nc2=h_m_ma)\n  * [AWS Support Overview](https://aws.amazon.com/premiumsupport/?nc2=h_m_bc)\n  * [AWS re:Post](https://repost.aws/)\n\n\n[Click here to return to Amazon Web Services homepage](https://aws.amazon.com/?nc2=h_lg)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\nClose\nProfile \nYour profile helps improve your interactions with select AWS experiences. \n[ Login](https://auth.aws.amazon.com/sign-in)\nClose\nProfile \nYour profile helps improve your interactions with select AWS experiences. \n[ View profile](https://aws.amazon.com/profile)\n[ Log out](https://auth.aws.amazon.com/sign-out)\nClose\nProfile \nYour profile helps improve your interactions with select AWS experiences. \n[ View profile](https://aws.amazon.com/profile)\n[ Log out](https://auth.aws.amazon.com/sign-out)\n[ Get Started for Free ](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_mobile)\n[ Contact Us ](https://aws.amazon.com/contact-us/?nc2=h_mobile)\n  * [ Products ](https://aws.amazon.com/products/?nc2=h_mo)\n  * [ Solutions ](https://aws.amazon.com/solutions/?nc2=h_mo)\n  * [ Pricing ](https://aws.amazon.com/pricing/?nc2=h_mo)\n  * [ Introduction to AWS ](https://aws.amazon.com/what-is-aws/?nc2=h_mo)\n  * [ Getting Started ](https://aws.amazon.com/getting-started/?nc2=h_mo)\n  * [ Documentation ](https://aws.amazon.com/documentation-overview/?nc2=h_mo)\n  * [ Training and Certification ](https://aws.amazon.com/training/?nc2=h_mo)\n  * [ Developer Center ](https://aws.amazon.com/developer/?nc2=h_mo)\n  * [ Customer Success ](https://aws.amazon.com/solutions/case-studies/?nc2=h_mo)\n  * [ Partner Network ](https://aws.amazon.com/partners/?nc2=h_mo)\n  * [ AWS Marketplace ](https://aws.amazon.com/marketplace/?nc2=h_mo)\n  * [ Support ](https://console.aws.amazon.com/support/home?nc2=h_ql_cu)\n  * [ AWS re:Post ](https://repost.aws/)\n  * [ Log into Console ](https://console.aws.amazon.com/console/home)\n  * [ Download the Mobile App ](https://aws.amazon.com/console/mobile/)\n\n\n[ AWS Tutorials Directory](https://aws.amazon.com/tutorials/?ref=tutorials_navbar)\n[ Getting Started Resource Center](https://aws.amazon.com/getting-started/?ref=tutorials_navbar) [ Developer Center](https://aws.amazon.com/developer/?ref=tutorials_navbar) [ IT Pro Center](https://aws.amazon.com/it-pro/?ref=tutorials_navbar) [ Architecture Center](https://aws.amazon.com/architecture/?ref=tutorials_navbar) [ Tools & SDKs](https://aws.amazon.com/developer/tools/?ref=tutorials_navbar) [ More Resources ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\nClose [ Ask an Expert on AWS re:Post](https://repost.aws/?trk=859f3c3f-c0fa-4b16-9fd5-8f05cf9273de) [ Builders Library](https://aws.amazon.com/builders-library/?ref=tutorials_navbar) [ Documentation](https://docs.aws.amazon.com/?ref=tutorials_navbar)\n#  Build, train, deploy, and monitor a machine learning model\n##  with Amazon SageMaker Studio\n[Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html) is the first fully integrated development environment (IDE) for machine learning that provides a single, web-based visual interface to perform all the steps for ML development.\nIn this tutorial, you use Amazon SageMaker Studio to build, train, deploy, and monitor an [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) model. You cover the entire machine learning (ML) workflow from feature engineering and model training to batch and live deployments for [ML models](https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/). \nIn this tutorial, you learn how to:\n  1. Set up the Amazon SageMaker Studio Control Panel\n  2. Download a public dataset using an Amazon SageMaker Studio Notebook and upload it to Amazon S3\n  3. Create an Amazon SageMaker Experiment to track and manage training and processing jobs\n  4. Run an Amazon SageMaker Processing job to generate features from raw data\n  5. Train a model using the built-in XGBoost algorithm\n  6. Test the model performance on the test dataset using Amazon SageMaker Batch Transform\n  7. Deploy the model as an endpoint, and set up a Monitoring job to monitor the model endpoint in production for data drift.\n  8. Visualize results and monitor the model using SageMaker Model Monitor to determine any differences between the training dataset and the deployed model.\n\n\nThe model will be trained on the [UCI Credit Card Default](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients) dataset that contains information on customer demographics, payment history, and billing history.\n**About this Tutorial**  \n---  \n**Time** | 1 hour   \n**Cost** | Less than $10  \n**Use Case** | Machine Learning  \n**Products** | [Amazon SageMaker](https://aws.amazon.com/sagemaker/)  \n**Audience** | Developer, Data Scientist  \n**Level** | Intermediate  \n**Last Updated** | February 25, 2021  \n###  Step 1. Create an AWS Account\nThe resources created and used in this tutorial are [AWS Free Tier](https://aws.amazon.com/free/) eligible. The cost of this workshop is less than $10. \n[ Sign-up for AWS ](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?client=lightsail&fid=3BE5EA8FA64943AD-0284EED1954F5F15)\nAlready have an account? [Sign-in](https://lightsail.aws.amazon.com/ls/)\n###  Step 2. Create your Amazon SageMaker Studio Control Panel\nComplete the following steps to onboard to Amazon SageMaker Studio and set up your Amazon SageMaker Studio Control Panel.\n**Note:** For more information, see [Get Started with Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio.html) in the Amazon SageMaker documentation. \na. Sign in to the [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/). \nNote: In the top right corner, make sure to select an AWS Region where SageMaker Studio is available. For a list of Regions, see [Onboard to Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html).\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-region-selection.8d03ac86c93954a3f9feedd3316dd7c67261af18.png)\nb. In the **Amazon SageMaker** navigation pane, choose **Amazon SageMaker Studio**. \n**Note:** If you are using Amazon SageMaker Studio for the first time, you must complete the [Studio onboarding process](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html). When onboarding, you can choose to use either AWS Single Sign-On (AWS SSO) or AWS Identity and Access Management (IAM) for authentication methods. When you use IAM authentication, you can choose either the Quick start or the Standard setup procedure. If you are unsure of which option to choose, see [Onboard to Amazon SageMaker Studio](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html) and ask your IT administrator for assistance. For simplicity, this tutorial uses the **Quick start** procedure. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-studio-selection.95603b17fb12513f282a9b2efd6bbeee8ec548bb.png)\nc. In the **Get started** box, choose **Quick start** and specify a user name. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-quickstart.0d81f24ac6a2d84d274fa5859942edcaf5f06815.png)\nd. For **Execution role** , choose **Create an IAM role**. In the dialog box that appears, choose **Any S3 bucket** and choose **Create role**. \nAmazon SageMaker creates a role with the required permissions and assigns it to your instance. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-create-iam-role.8ef3ad4ffeab2feb692e76dc838993e7dcfc01cd.png)\ne. Click **Submit**. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-execution-role.4d28d46ee847169231967a7983fc02341e463394.png)\n###  Step 3. Download the dataset\nAmazon SageMaker Studio notebooks are one-click Jupyter notebooks that contain everything you need to build and test your training scripts. SageMaker Studio also includes experiment tracking and visualization so that it’s easy to manage your entire machine learning workflow in one place.\nComplete the following steps to create a SageMaker Notebook, download the dataset, and then upload the dataset to Amazon S3.\n**Note:** For more information, see [Use Amazon SageMaker Studio Notebooks](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html) in the Amazon SageMaker documentation. \na. In the **Amazon SageMaker Studio Control Panel** , choose **Open Studio**. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-open-studio.779522ed5a6e213544a7533b9d7642cf175df6e5.png)\nb. In **JupyterLab** , on the **File** menu, choose **New** , then **Notebook**. In the **Select Kernel** box, choose **Python 3 (Data Science)**. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/autopilot-select-kernel.b8683aa1b83df9d2bba63f794318bcb27599d2f3.png)\nc. First, verify your version of the [Amazon SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/). Copy and paste the following code block into the code cell and select **Run**. \n**Note:** While the code runs, an * appears between the square brackets. After a few seconds, the code execution completes and the * is replaced with a number. \n```\nimport boto3\nimport sagemaker\nfrom sagemaker import get_execution_role\nimport sys\nimport IPython\nif int(sagemaker.__version__.split('.')[0]) == 2:\n  print(\"Installing previous SageMaker Version and restarting the kernel\")\n  !{sys.executable} -m pip install sagemaker==1.72.0\n  IPython.Application.instance().kernel.do_shutdown(True)\nelse:\n  print(\"Version is good\")\n\nrole = get_execution_role()\nsess = sagemaker.Session()\nregion = boto3.session.Session().region_name\nprint(\"Region = {}\".format(region))\nsm = boto3.Session().client('sagemaker')\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-import-libraries.446f3b0434e7a5b49edfc095d5b75053b6e1bd4c.png)\nNext, import libraries. Copy and paste the following code into the code cell and select **Run**. \n```\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom time import sleep, gmtime, strftime\nimport json\nimport time\n\n```\n\nCode snippet copied\nCopy\nFinally, import the experiments. Copy and paste the following code into the code cell and select **Run**. \n```\n!pip install sagemaker-experiments \nfrom sagemaker.analytics import ExperimentAnalytics\nfrom smexperiments.experiment import Experiment\nfrom smexperiments.trial import Trial\nfrom smexperiments.trial_component import TrialComponent\nfrom smexperiments.tracker import Tracker\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-import-libraries-experiments.c2ac30bea7afced4a181768c00e685352a17dd50.png)\nd. Define the Amazon S3 buckets and folders for the project. Copy and paste the following code into the code cell and select **Run**. \n```\nrawbucket= sess.default_bucket() # Alternatively you can use our custom bucket here. \nprefix = 'sagemaker-modelmonitor' # use this prefix to store all files pertaining to this workshop.\ndataprefix = prefix + '/data'\ntraindataprefix = prefix + '/train_data'\ntestdataprefix = prefix + '/test_data'\ntestdatanolabelprefix = prefix + '/test_data_no_label'\ntrainheaderprefix = prefix + '/train_headers'\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-s3-bucket.5af937a58471f3dad23ac1aa696fae009ef71998.png)\ne. Download the dataset and import it using the pandas library. Copy and paste the following code into a new code cell and choose **Run**.\n```\n! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\ndata = pd.read_excel('default of credit card clients.xls', header=1)\ndata = data.drop(columns = ['ID'])\ndata.head()\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-dataset.84eb9011450307b0c1417122cbe53dcdeef67b1f.png)\nf. Rename the last column as **Label** and extract the label column separately. For the Amazon SageMaker built-in [XGBoost algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html), the label column must be the first column in the dataframe. To make that change, copy and paste the following code into a new code cell and choose **Run**. \n```\ndata.rename(columns={\"default payment next month\": \"Label\"}, inplace=True)\nlbl = data.Label\ndata = pd.concat([lbl, data.drop(columns=['Label'])], axis = 1)\ndata.head()\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-dataset-columns.0d2617872331e776ce8de8887e489c331e1cb52e.png)\ng. Upload the CSV dataset into an [Amazon S3](https://aws.amazon.com/s3/) bucket. Copy and paste the following code into a new code cell and choose **Run**.\n```\nif not os.path.exists('rawdata/rawdata.csv'):\n  !mkdir rawdata\n  data.to_csv('rawdata/rawdata.csv', index=None)\nelse:\n  pass\n# Upload the raw dataset\nraw_data_location = sess.upload_data('rawdata', bucket=rawbucket, key_prefix=dataprefix)\nprint(raw_data_location)\n```\n\nCode snippet copied\nCopy\nYou're done! The code output displays the S3 bucket URI like the following example:\n```\ns3://sagemaker-us-east-2-ACCOUNT_NUMBER/sagemaker-modelmonitor/data\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-upload-data.5a4e18b23cf127a751f7b60667a485c4a22d390c.png)\n##  Step 4: Process the data using Amazon SageMaker Processing\nIn this step, you use Amazon SageMaker Processing to pre-process the dataset, including scaling the columns and splitting the dataset into train and test data. Amazon SageMaker Processing lets you run your preprocessing, postprocessing, and model evaluation workloads on fully managed infrastructure.\nComplete the following steps to processs the data and generate features using Amazon SageMaker Processing. \n**Note:** Amazon SageMaker Processing runs on separate compute instances from your notebook. This means you can continue to experiment and run code in your notebook while the processing job is under way. This will incur additional charges for the cost of the instance which is up and running for the duration of the processing job. The instances are automatically terminated by SageMaker once the processing job completes. For pricing details, see [Amazon SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/).\n**Note:** For more information, see [Process Data and Evaluate Models](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html) in the Amazon SageMaker documentation.\na. Import the [scikit-learn processing](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation) container. Copy and paste the following code into a new code cell and choose **Run**.\n**Note:** Amazon SageMaker provides a managed container for scikit-learn. For more information, see [Process Data and Evaluate Models with scikit-learn](https://docs.aws.amazon.com/sagemaker/latest/dg/use-scikit-learn-processing-container.html).\n```\nfrom sagemaker.sklearn.processing import SKLearnProcessor\nsklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n                   role=role,\n                   instance_type='ml.c4.xlarge',\n                   instance_count=1)\n```\n\nCode snippet copied\nCopy\n[ ![Import scikit-learn container](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-sklearn.ec336d7c7e2bf8bed959ebf9a7060241b2470758.png)](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\nb. Copy and paste the following pre-processing script into a new cell and choose **Run**. \n```\n%%writefile preprocessing.py\nimport argparse\nimport os\nimport warnings\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.compose import make_column_transformer\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\nif __name__=='__main__':\n  parser = argparse.ArgumentParser()\n  parser.add_argument('--train-test-split-ratio', type=float, default=0.3)\n  parser.add_argument('--random-split', type=int, default=0)\n  args, _ = parser.parse_known_args()\n  \n  print('Received arguments {}'.format(args))\n  input_data_path = os.path.join('/opt/ml/processing/input', 'rawdata.csv')\n  \n  print('Reading input data from {}'.format(input_data_path))\n  df = pd.read_csv(input_data_path)\n  df.sample(frac=1)\n  \n  COLS = df.columns\n  newcolorder = ['PAY_AMT1','BILL_AMT1'] + list(COLS[1:])[:11] + list(COLS[1:])[12:17] + list(COLS[1:])[18:]\n  \n  split_ratio = args.train_test_split_ratio\n  random_state=args.random_split\n  \n  X_train, X_test, y_train, y_test = train_test_split(df.drop('Label', axis=1), df['Label'], \n                            test_size=split_ratio, random_state=random_state)\n  \n  preprocess = make_column_transformer(\n    (['PAY_AMT1'], StandardScaler()),\n    (['BILL_AMT1'], MinMaxScaler()),\n  remainder='passthrough')\n  \n  print('Running preprocessing and feature engineering transformations')\n  train_features = pd.DataFrame(preprocess.fit_transform(X_train), columns = newcolorder)\n  test_features = pd.DataFrame(preprocess.transform(X_test), columns = newcolorder)\n  \n  # concat to ensure Label column is the first column in dataframe\n  train_full = pd.concat([pd.DataFrame(y_train.values, columns=['Label']), train_features], axis=1)\n  test_full = pd.concat([pd.DataFrame(y_test.values, columns=['Label']), test_features], axis=1)\n  \n  print('Train data shape after preprocessing: {}'.format(train_features.shape))\n  print('Test data shape after preprocessing: {}'.format(test_features.shape))\n  \n  train_features_headers_output_path = os.path.join('/opt/ml/processing/train_headers', 'train_data_with_headers.csv')\n  \n  train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_data.csv')\n  \n  test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_data.csv')\n  \n  print('Saving training features to {}'.format(train_features_output_path))\n  train_full.to_csv(train_features_output_path, header=False, index=False)\n  print(\"Complete\")\n  \n  print(\"Save training data with headers to {}\".format(train_features_headers_output_path))\n  train_full.to_csv(train_features_headers_output_path, index=False)\n         \n  print('Saving test features to {}'.format(test_features_output_path))\n  test_full.to_csv(test_features_output_path, header=False, index=False)\n  print(\"Complete\")\n```\n\nCode snippet copied\nCopy\nc. Copy the preprocessing code over to the Amazon S3 bucket using the following code, then choose **Run**.\n```\n# Copy the preprocessing code over to the s3 bucket\ncodeprefix = prefix + '/code'\ncodeupload = sess.upload_data('preprocessing.py', bucket=rawbucket, key_prefix=codeprefix)\nprint(codeupload)\n\n```\n\nCode snippet copied\nCopy\n[ ![Copy code and specify S3 bucket](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-parsed-dataset.b049c144237ed3eba2ee9f843d6487034f6e1cc6.png)](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\nd. Specify where you want to store your training and test data after the SageMaker Processing job completes. Amazon SageMaker Processing automatically stores the data in the specified location. \n```\ntrain_data_location = rawbucket + '/' + traindataprefix\ntest_data_location = rawbucket+'/'+testdataprefix\nprint(\"Training data location = {}\".format(train_data_location))\nprint(\"Test data location = {}\".format(test_data_location))\n\n```\n\nCode snippet copied\nCopy\n[ ![Copy code and specify S3 bucket](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-parsed-dataset.b049c144237ed3eba2ee9f843d6487034f6e1cc6.png)](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\ne. Copy and paste the following code to start the Processing job. This code starts the job by calling _sklearn_processor.run_ and extracts some optional metadata about the processing job, such as where the training and test outputs were stored. \n```\nfrom sagemaker.processing import ProcessingInput, ProcessingOutput\nsklearn_processor.run(code=codeupload,\n           inputs=[ProcessingInput(\n            source=raw_data_location,\n            destination='/opt/ml/processing/input')],\n           outputs=[ProcessingOutput(output_name='train_data',\n                        source='/opt/ml/processing/train',\n                destination='s3://' + train_data_location),\n                ProcessingOutput(output_name='test_data',\n                        source='/opt/ml/processing/test',\n                        destination=\"s3://\"+test_data_location),\n                ProcessingOutput(output_name='train_data_headers',\n                        source='/opt/ml/processing/train_headers',\n                        destination=\"s3://\" + rawbucket + '/' + prefix + '/train_headers')],\n           arguments=['--train-test-split-ratio', '0.2']\n           )\npreprocessing_job_description = sklearn_processor.jobs[-1].describe()\noutput_config = preprocessing_job_description['ProcessingOutputConfig']\nfor output in output_config['Outputs']:\n  if output['OutputName'] == 'train_data':\n    preprocessed_training_data = output['S3Output']['S3Uri']\n  if output['OutputName'] == 'test_data':\n    preprocessed_test_data = output['S3Output']['S3Uri']\n\n\n```\n\nCode snippet copied\nCopy\nNote the locations of the code, train and test data in the outputs provided to the processor. Also, note the arguments provided to the processing scripts. \n[ ![Start processing job](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-processor.cd7cba4b42a5bccb909283f6f0d18753b4828cf7.png)](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n##  Step 5: Create an Amazon SageMaker Experiment\nNow that you have downloaded and staged your dataset in Amazon S3, you can create an Amazon SageMaker Experiment. An experiment is a collection of processing and training jobs related to the same machine learning project. Amazon SageMaker Experiments automatically manages and tracks your training runs for you. \nComplete the following steps to create a new experiment.\n**Note:** For more information, see [Experiments](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) in the Amazon SageMaker documentation. \na. Copy and paste the following code to create an experiment named _Build-train-deploy-_. \n```\n# Create a SageMaker Experiment\ncc_experiment = Experiment.create(\n  experiment_name=f\"Build-train-deploy-{int(time.time())}\", \n  description=\"Predict credit card default from payments data\", \n  sagemaker_boto_client=sm)\nprint(cc_experiment)\n\n```\n\nCode snippet copied\nCopy\nEvery training job is logged as a _trial_. Each trial is an iteration of your end-to-end training job. In addition to the training job, it can also track pre-processing and post-processing jobs as well as datasets and other metadata. A single experiment can include multiple trials which makes it easy for you to track multiple iterations over time within the Amazon SageMaker Studio Experiments pane.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-create-experiment.5dc4402f2042c47cbc266aeb544bc9e3b9bd9a1c.png)\nb. Copy and paste the following code to track your pre-processing job under Experiments as well as a step in the training pipeline.\n```\n# Start Tracking parameters used in the Pre-processing pipeline.\nwith Tracker.create(display_name=\"Preprocessing\", sagemaker_boto_client=sm) as tracker:\n  tracker.log_parameters({\n    \"train_test_split_ratio\": 0.2,\n    \"random_state\":0\n  })\n  # we can log the s3 uri to the dataset we just uploaded\n  tracker.log_input(name=\"ccdefault-raw-dataset\", media_type=\"s3/uri\", value=raw_data_location)\n  tracker.log_input(name=\"ccdefault-train-dataset\", media_type=\"s3/uri\", value=train_data_location)\n  tracker.log_input(name=\"ccdefault-test-dataset\", media_type=\"s3/uri\", value=test_data_location)\n\n```\n\nCode snippet copied\nCopy\nc. View the details of the experiment: In the **Experiments** pane, right-click the experiment named **Build-train-deploy-** and choose **Open in trial components list**.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-trial-components.a29bc386558de92b10e5681c9f17ab6f58578495.png)\nd. Copy and paste the following code and choose **Run**. Then, take a closer look at the code:\nTo train an XGBoost classifier, you first import the [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) container maintained by Amazon SageMaker. Then, you log the training run under a **Trial** so SageMaker Experiments can track it under a **Trial** name. The pre-processing job is included under the same trial name since it is part of the pipeline. Next, create a SageMaker Estimator object, which automatically provisions the underlying instance type of your choosing, copies over the training data from the specified output location from the processing job, trains the model, and outputs the model artifacts.\n```\nfrom sagemaker.amazon.amazon_estimator import get_image_uri\ncontainer = get_image_uri(boto3.Session().region_name, 'xgboost', '1.0-1')\ns3_input_train = sagemaker.s3_input(s3_data='s3://' + train_data_location, content_type='csv')\npreprocessing_trial_component = tracker.trial_component\ntrial_name = f\"cc-default-training-job-{int(time.time())}\"\ncc_trial = Trial.create(\n    trial_name=trial_name, \n      experiment_name=cc_experiment.experiment_name,\n    sagemaker_boto_client=sm\n  )\ncc_trial.add_trial_component(preprocessing_trial_component)\ncc_training_job_name = \"cc-training-job-{}\".format(int(time.time()))\nxgb = sagemaker.estimator.Estimator(container,\n                  role, \n                  train_instance_count=1, \n                  train_instance_type='ml.m4.xlarge',\n                  train_max_run=86400,\n                  output_path='s3://{}/{}/models'.format(rawbucket, prefix),\n                  sagemaker_session=sess) # set to true for distributed training\nxgb.set_hyperparameters(max_depth=5,\n            eta=0.2,\n            gamma=4,\n            min_child_weight=6,\n            subsample=0.8,\n            verbosity=0,\n            objective='binary:logistic',\n            num_round=100)\nxgb.fit(inputs = {'train':s3_input_train},\n    job_name=cc_training_job_name,\n    experiment_config={\n      \"TrialName\": cc_trial.trial_name, #log training job in Trials for lineage\n      \"TrialComponentDisplayName\": \"Training\",\n    },\n    wait=True,\n  )\ntime.sleep(2)\n\n```\n\nCode snippet copied\nCopy\nThe training job will take about 70 seconds to complete. You should see the following output.\n```\nCompleted - Training job completed\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-get-image.20072e3101167eb9b0dc9b9186788b40cc24e5fd.png)\ne. In the left toolbar, choose **Experiment**. Right-click the **Build-train-deploy-** experiment and choose **Open in trial components list**. Amazon SageMaker Experiments captures all the runs including any failed training runs. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-job-list.f741f928cbf3c41cfb829696e624a30cbad11d9f.png)\nf. Right-click one of the completed **Training jobs** and choose **Open in Trial Details** to explore the associated metadata with the training job. \n**Note:** You may need to refresh the page to see the latest results. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-training-metadata.57bcdc852f9f9f450dbb3a1d2a675ee9a27dae90.png)\n##  Step 6: Deploy the model for offline inference\nIn your preprocessing step, you generated some test data. In this step, you generate offline or batch inference from the trained model to evaluate the model performance on unseen test data. \nComplete the following steps to deploy the model for offline inference.\n**Note:** For more information, see [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) in the Amazon SageMaker documentation. \na. Copy and paste the following code and choose **Run**.\nThis step copies the test dataset over from the Amazon S3 location into your local folder. \n```\ntest_data_path = 's3://' + test_data_location + '/test_data.csv'\n! aws s3 cp $test_data_path .\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-copy-dataset.cba162066d4319117deb98a5d9358eda159ca83b.png)\nb. Copy and paste the following code and choose **Run**.\n```\ntest_full = pd.read_csv('test_data.csv', names = [str(x) for x in range(len(data.columns))])\ntest_full.head()\n\n```\n\nCode snippet copied\nCopy\nc. Copy and paste the following code and choose **Run**. This step extracts the label column. \n```\nlabel = test_full['0'] \n```\n\nCode snippet copied\nCopy\nd. Copy and paste the following code and choose **Run** to create the Batch Transform job. Then, take a closer look at the code:\nLike the training job, SageMaker provisions all the underlying resources, copies over the trained model artifacts, sets up a Batch endpoint locally, copies over the data, and runs inferences on the data and pushes the outputs to Amazon S3. Note that by setting the **input_filter** , you are letting Batch Transform know to neglect the first column in the test data which is the label column. \n```\n%%time\nsm_transformer = xgb.transformer(1, 'ml.m5.xlarge', accept = 'text/csv')\n# start a transform job\nsm_transformer.transform(test_data_path, split_type='Line', input_filter='$[1:]', content_type='text/csv')\nsm_transformer.wait()\n\n```\n\nCode snippet copied\nCopy\nThe Batch Transform job will take about 4 minutes to complete after which you can evaluate the model results. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-input-filter.36e2fc6554ce24555355d3c3e0d6bfa429010e92.png)\ne. Copy and run the following code to evaluate the model metrics. Then, take a closer look at the code:\nFirst, you define a function that pulls the output of the Batch Transform job, which is contained in a file with a **.out** extension from the Amazon S3 bucket. Then, you extract the predicted labels into a dataframe and append the true labels to this dataframe. \n```\nimport json\nimport io\nfrom urllib.parse import urlparse\ndef get_csv_output_from_s3(s3uri, file_name):\n  parsed_url = urlparse(s3uri)\n  bucket_name = parsed_url.netloc\n  prefix = parsed_url.path[1:]\n  s3 = boto3.resource('s3')\n  obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n  return obj.get()[\"Body\"].read().decode('utf-8')\noutput = get_csv_output_from_s3(sm_transformer.output_path, 'test_data.csv.out')\noutput_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\noutput_df.head(8)\noutput_df['Predicted']=np.round(output_df.values)\noutput_df['Label'] = label\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nconfusion_matrix = pd.crosstab(output_df['Predicted'], output_df['Label'], rownames=['Actual'], colnames=['Predicted'], margins = True)\nconfusion_matrix\n\n```\n\nCode snippet copied\nCopy\nYou should see an output similar to the image, which shows the total number of **Predicted** True and False values compared to the **Actual** values. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-output-predicted-actual.07c3626191859ac332d35a22fbfe0ce6fdd0dadd.png)\nf. Use the following code to extract both the baseline model accuracy and the model accuracy. \n**Note:** A helpful model for the baseline accuracy can be the fraction of non-default cases. A model that always predicts that a user will not default has that accuracy. \n```\nprint(\"Baseline Accuracy = {}\".format(1- np.unique(data['Label'], return_counts=True)[1][1]/(len(data['Label']))))\nprint(\"Accuracy Score = {}\".format(accuracy_score(label, output_df['Predicted'])))\n\n```\n\nCode snippet copied\nCopy\nThe results show that a simple model can already beat the baseline accuracy. In order to improve the results, you can tune the hyperparameters. You can use hyperparameter optimization (HPO) on SageMaker for automatic model tuning. To learn more, see [How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html). \n**Note:** Although it is not included in this tutorial, you also have the option of including Batch Transform as part of your trial. When you call the .transform function, simply pass in the experiment_config as you did for the Training job. Amazon SageMaker automatically associates the Batch Transform as a trial component.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-accuracy.06e79010a31766ea2511406de7618f2f1f3c1960.png)\n##  Step 7: Deploy the model as an endpoint and set up data capture\nIn this step, you deploy the model as a RESTful HTTPS endpoint to serve live inferences. Amazon SageMaker automatically handles the model hosting and creation of the endpoint for you. \nComplete the following steps to deploy the model as an endpoint and set up data capture.\n**Note:** For more information, see [Deploy Models for Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html) in the Amazon SageMaker documentation. \na. Copy and paste the following code and choose **Run**.\n```\nfrom sagemaker.model_monitor import DataCaptureConfig\nfrom sagemaker import RealTimePredictor\nfrom sagemaker.predictor import csv_serializer\nsm_client = boto3.client('sagemaker')\nlatest_training_job = sm_client.list_training_jobs(MaxResults=1,\n                        SortBy='CreationTime',\n                        SortOrder='Descending')\ntraining_job_name=TrainingJobName=latest_training_job['TrainingJobSummaries'][0]['TrainingJobName']\ntraining_job_description = sm_client.describe_training_job(TrainingJobName=training_job_name)\nmodel_data = training_job_description['ModelArtifacts']['S3ModelArtifacts']\ncontainer_uri = training_job_description['AlgorithmSpecification']['TrainingImage']\n# create a model.\ndef create_model(role, model_name, container_uri, model_data):\n  return sm_client.create_model(\n    ModelName=model_name,\n    PrimaryContainer={\n    'Image': container_uri,\n    'ModelDataUrl': model_data,\n    },\n    ExecutionRoleArn=role)\n  \ntry:\n  model = create_model(role, training_job_name, container_uri, model_data)\nexcept Exception as e:\n    sm_client.delete_model(ModelName=training_job_name)\n    model = create_model(role, training_job_name, container_uri, model_data)\n    \nprint('Model created: '+model['ModelArn'])\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-create-model-created.bbeba188f4609843e78c7430f1f499eddcc1b30d.png)\nb. To specify the data configuration settings, copy and paste the following code and choose **Run**.\nThis code tells SageMaker to capture 100% of the inference payloads received by the endpoint, capture both inputs and outputs, and also note the input content type as csv.\n```\ns3_capture_upload_path = 's3://{}/{}/monitoring/datacapture'.format(rawbucket, prefix)\ndata_capture_configuration = {\n  \"EnableCapture\": True,\n  \"InitialSamplingPercentage\": 100,\n  \"DestinationS3Uri\": s3_capture_upload_path,\n  \"CaptureOptions\": [\n    { \"CaptureMode\": \"Output\" },\n    { \"CaptureMode\": \"Input\" }\n  ],\n  \"CaptureContentTypeHeader\": {\n    \"CsvContentTypes\": [\"text/csv\"],\n    \"JsonContentTypes\": [\"application/json\"]}}\n\n```\n\nCode snippet copied\nCopy\nc. Copy and paste the following code and choose **Run**. This step creates an endpoint configuration and deploys the endpoint. In the code, you can specify instance type and whether you want to send all the traffic to this endpoint, etc. \n```\ndef create_endpoint_config(model_config, data_capture_config): \n  return sm_client.create_endpoint_config(\n                        EndpointConfigName=model_config,\n                        ProductionVariants=[\n                            {\n                              'VariantName': 'AllTraffic',\n                              'ModelName': model_config,\n                              'InitialInstanceCount': 1,\n                              'InstanceType': 'ml.m4.xlarge',\n                              'InitialVariantWeight': 1.0,\n                        },\n                          \n                          ],\n                        DataCaptureConfig=data_capture_config\n                        )\n\n\ntry:\n  endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\nexcept Exception as e:\n  sm_client.delete_endpoint_config(EndpointConfigName=endpoint)\n  endpoint_config = create_endpoint_config(training_job_name, data_capture_configuration)\nprint('Endpoint configuration created: '+ endpoint_config['EndpointConfigArn'])\n\n```\n\nCode snippet copied\nCopy\nd. Copy and paste the following code and choose **Run** to create the endpoint. \n```\n# Enable data capture, sampling 100% of the data for now. Next we deploy the endpoint in the correct VPC.\nendpoint_name = training_job_name\ndef create_endpoint(endpoint_name, config_name):\n  return sm_client.create_endpoint(\n                  EndpointName=endpoint_name,\n                  EndpointConfigName=training_job_name\n                )\n\ntry:\n  endpoint = create_endpoint(endpoint_name, endpoint_config)\nexcept Exception as e:\n  sm_client.delete_endpoint(EndpointName=endpoint_name)\n  endpoint = create_endpoint(endpoint_name, endpoint_config)\nprint('Endpoint created: '+ endpoint['EndpointArn'])\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-endpoint-created.462d228b19d0aa86c03bb1a72d1af56a71bb34f5.png)\ne. In the left toolbar, choose **Endpoints**. The **Endpoints** list displays all of the endpoints in service.\nNotice the _build-train-deploy_ endpoint shows a status of _Creating_. To deploy the model, Amazon SageMaker must first copy your model artifacts and inference image onto the instance and set up a HTTPS endpoint to inferface with client applications or RESTful APIs. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-endpoint-status.52db936293c7da09a14e87bb0323ff66cd07c721.png)\nOnce the endpoint is created, the status changes to _InService_. (Note that creating an endpoint may take about 5-10 minutes.) \n**Note:** You may need to click Refresh to get the updated status.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-endpoints-inservice.e905d3fa36dd3a238515588c6fd57cfe1928e6d3.png)\nf. In the **JupyterLab Notebook** , copy and run the following code to take a sample of the test dataset. This code takes the first 10 rows. \n```\n!head -10 test_data.csv > test_sample.csv\n```\n\nCode snippet copied\nCopy\ng. Run the following code to send some inference requests to this endpoint.\n**Note:** If you specified a different endpoint name, you will need to replace _endpoint_ below with your endpoint name. \n```\nfrom sagemaker import RealTimePredictor\nfrom sagemaker.predictor import csv_serializer\npredictor = RealTimePredictor(endpoint=endpoint_name, content_type = 'text/csv')\nwith open('test_sample.csv', 'r') as f:\n  for row in f:\n    payload = row.rstrip('\\n')\n    response = predictor.predict(data=payload[2:])\n    sleep(0.5)\nprint('done!')\n\n```\n\nCode snippet copied\nCopy\nh. Run the following code to verify that Model Monitor is correctly capturing the incoming data.\nIn the code, the _current_endpoint_capture_prefix_ captures the directory path where your ModelMonitor outputs are stored. Navigate to your Amazon S3 bucket, to see if the prediction requests are being captured. Note that this location should match the _s3_capture_upload_path_ in the code above.\n```\n# Extract the captured json files.\ndata_capture_prefix = '{}/monitoring'.format(prefix)\ns3_client = boto3.Session().client('s3')\ncurrent_endpoint_capture_prefix = '{}/datacapture/{}/AllTraffic'.format(data_capture_prefix, endpoint_name)\nprint(current_endpoint_capture_prefix)\nresult = s3_client.list_objects(Bucket=rawbucket, Prefix=current_endpoint_capture_prefix)\ncapture_files = [capture_file.get(\"Key\") for capture_file in result.get('Contents')]\nprint(\"Found Capture Files:\")\nprint(\"\\n \".join(capture_files))\n\ncapture_files[0]\n\n```\n\nCode snippet copied\nCopy\nThe captured output indicates that data capture is configured and saving the incoming requests. \n**Note:** If you initially see a Null response, the data may not have been synchronously loaded onto the Amazon S3 path when you first initialized the data capture. Wait about a minute and try again.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-extract-json.b8d96a4ad7f35a372350477cd0d44732d817dd35.png)\ni. Run the following code to extract the content of one of the json files and view the captured outputs. \n```\n# View contents of the captured file.\ndef get_obj_body(bucket, obj_key):\n  return s3_client.get_object(Bucket=rawbucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\ncapture_file = get_obj_body(rawbucket, capture_files[0])\nprint(json.dumps(json.loads(capture_file.split('\\n')[5]), indent = 2, sort_keys =True))\n\n```\n\nCode snippet copied\nCopy\nThe output indicates that data capture is capturing both the input payload and the output of the model. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-data-capture.ce3385bec24cc4418bbd5619bfacbda0b9172362.png)\n##  Step 8: Monitor the endpoint with SageMaker Model Monitor\nIn this step, you enable SageMaker Model Monitor to monitor the deployed endpoint for data drift. To do so, you compare the payload and outputs sent to the model against a baseline and determine whether there is any drift in the input data, or the label. \nComplete the following steps to enable model monitoring.\n**Note:** For more information, see [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) in the Amazon SageMaker documentation. \na. Run the following code to create a folder in your Amazon S3 bucket to store the outputs of the Model Monitor. \nThis code creates two folders: one folder stores the baseline data which you used for training your model; the second folder stores any violations from that baseline.\n```\nmodel_prefix = prefix + \"/\" + endpoint_name\nbaseline_prefix = model_prefix + '/baselining'\nbaseline_data_prefix = baseline_prefix + '/data'\nbaseline_results_prefix = baseline_prefix + '/results'\nbaseline_data_uri = 's3://{}/{}'.format(rawbucket,baseline_data_prefix)\nbaseline_results_uri = 's3://{}/{}'.format(rawbucket, baseline_results_prefix)\ntrain_data_header_location = \"s3://\" + rawbucket + '/' + prefix + '/train_headers'\nprint('Baseline data uri: {}'.format(baseline_data_uri))\nprint('Baseline results uri: {}'.format(baseline_results_uri))\nprint(train_data_header_location)\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-monitor-baseline.abcd340eba0425223dc460d618c529d5afc42ef7.png)\nb. Run the following code to set up a baseline job for Model Monitor to capture the statistics of the training data. To do this, Model Monitor uses the [deequ](https://github.com/awslabs/deequ) library built on top of Apache Spark for conducting unit tests on data. \n```\nfrom sagemaker.model_monitor import DefaultModelMonitor\nfrom sagemaker.model_monitor.dataset_format import DatasetFormat\nmy_default_monitor = DefaultModelMonitor(\n  role=role,\n  instance_count=1,\n  instance_type='ml.m5.xlarge',\n  volume_size_in_gb=20,\n  max_runtime_in_seconds=3600)\nmy_default_monitor.suggest_baseline(\n  baseline_dataset=os.path.join(train_data_header_location, 'train_data_with_headers.csv'),\n  dataset_format=DatasetFormat.csv(header=True),\n  output_s3_uri=baseline_results_uri,\n  wait=True\n)\n\n```\n\nCode snippet copied\nCopy\nModel Monitor sets up a separate instance, copies over the training data, and generates some statistics. The service generates a lot of Apache Spark logs, which you can ignore. Once the job is completed, you will see a _Spark job completed_ output. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-baseline-suggestion-job.94077d3556b0cec3439b0fae3cdd90e02ba6308d.png)\nc. Run the following code to look at the outputs generated by the baseline job. \n```\ns3_client = boto3.Session().client('s3')\nresult = s3_client.list_objects(Bucket=rawbucket, Prefix=baseline_results_prefix)\nreport_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\nprint(\"Found Files:\")\nprint(\"\\n \".join(report_files))\nbaseline_job = my_default_monitor.latest_baselining_job\nschema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\nschema_df\n\n```\n\nCode snippet copied\nCopy\nYou will see two files: **constraints.json** and **statistics.json**. Next, dive deeper into their contents.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-found-files.140817729d769be046cdcce8e9d077fd90cbb094.png)\nThe code above converts the json output in /**statistics.json** into a pandas dataframe. Note how the deequ library infers the data type of the column, the presence or absence of Null or missing values, and statistical parameters such as the mean, min, max, sum, standard deviation, and sketch parameters for an input data stream.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-pandas-dataframe.05626b92265719c2560ca0fea5cd8b764e82c033.png)\nLikewise, the **constraints.json** file consists of a number of constraints the training dataset obeys such as non-negativity of values, and the data type of the feature field.\n```\nconstraints_df = pd.io.json.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\nconstraints_df\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-constraints.f6ff33dcef9c1683e56876735748e2239936e443.png)\nd. Run the following code to set up the frequency for endpoint monitoring.\nYou can specify daily or hourly. This code specifies an hourly frequency, but you may want to change this for production applications as hourly frequency will generate a lot of data. Model Monitor will produce a report consisting of all the violations it finds. \n```\nreports_prefix = '{}/reports'.format(prefix)\ns3_report_path = 's3://{}/{}'.format(rawbucket,reports_prefix)\nprint(s3_report_path)\nfrom sagemaker.model_monitor import CronExpressionGenerator\nfrom time import gmtime, strftime\nmon_schedule_name = 'Built-train-deploy-model-monitor-schedule-' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\nmy_default_monitor.create_monitoring_schedule(\n  monitor_schedule_name=mon_schedule_name,\n  endpoint_input=predictor.endpoint,\n  output_s3_uri=s3_report_path,\n  statistics=my_default_monitor.baseline_statistics(),\n  constraints=my_default_monitor.suggested_constraints(),\n  schedule_cron_expression=CronExpressionGenerator.hourly(),\n  enable_cloudwatch_metrics=True,\n)\n\n```\n\nCode snippet copied\nCopy\nNote that this code enables Amazon CloudWatch Metrics, which instructs Model Monitor to send outputs to CloudWatch. You can use this approach to trigger alarms using CloudWatch Alarms to let engineers or admins know when data drift has been detected. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-monitoring-schedule.18c63636ce89f1afef2d023f7661170c17de0694.png)\n##  Step 9: Test SageMaker Model Monitor performance\nIn this step, you evaluate Model Monitor against some sample data. Instead of sending the test payload as is, you modify the distribution of several features in the test payload to test that Model Monitor can detect the change. \nComplete the following steps to test the Model Monitor performance.\n**Note:** For more information, see [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) in the Amazon SageMaker documentation. \na. Run the following code to import the test data and generate some modified sample data.\n```\nCOLS = data.columns\ntest_full = pd.read_csv('test_data.csv', names = ['Label'] +['PAY_AMT1','BILL_AMT1'] + list(COLS[1:])[:11] + list(COLS[1:])[12:17] + list(COLS[1:])[18:]\n)\ntest_full.head()\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-test-model-monitor.6e99408ff7c5f40815eae5f7da1a76fc1e876085.png)\nb. Run the following code to change a few columns. Note the differences marked in red in the image here from the previous step. Drop the label column and save the modified sample test data. \n```\nfaketestdata = test_full\nfaketestdata['EDUCATION'] = -faketestdata['EDUCATION'].astype(float)\nfaketestdata['BILL_AMT2']= (faketestdata['BILL_AMT2']//10).astype(float)\nfaketestdata['AGE']= (faketestdata['AGE']-10).astype(float)\nfaketestdata.head()\nfaketestdata.drop(columns=['Label']).to_csv('test-data-input-cols.csv', index = None, header=None)\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-changed-data.9f7dd607cda6a7ab60a657e1b7aec16370ace339.png)\nc. Run the following code to repeatedly invoke the endpoint with this modified dataset.\n```\nfrom threading import Thread\nruntime_client = boto3.client('runtime.sagemaker')\n# (just repeating code from above for convenience/ able to run this section independently)\ndef invoke_endpoint(ep_name, file_name, runtime_client):\n  with open(file_name, 'r') as f:\n    for row in f:\n      payload = row.rstrip('\\n')\n      response = runtime_client.invoke_endpoint(EndpointName=ep_name,\n                     ContentType='text/csv', \n                     Body=payload)\n      time.sleep(1)\n      \ndef invoke_endpoint_forever():\n  while True:\n    invoke_endpoint(endpoint, 'test-data-input-cols.csv', runtime_client)\n    \nthread = Thread(target = invoke_endpoint_forever)\nthread.start()\n# Note that you need to stop the kernel to stop the invocations\n\n```\n\nCode snippet copied\nCopy\nd. Run the following code to check the status of the Model Monitor job.\n```\ndesc_schedule_result = my_default_monitor.describe_schedule()\nprint('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))\n\n```\n\nCode snippet copied\nCopy\nYou should see an output of _Schedule status: Scheduled_\ne. Run the following code to check every 10 minutes if any monitoring outputs have been generated. Note that the first job may run with a buffer of about 20 minutes. \n```\nmon_executions = my_default_monitor.list_executions()\nprint(\"We created ahourly schedule above and it will kick off executions ON the hour (plus 0 - 20 min buffer.\\nWe will have to wait till we hit the hour...\")\nwhile len(mon_executions) == 0:\n  print(\"Waiting for the 1st execution to happen...\")\n  time.sleep(600)\n  mon_executions = my_default_monitor.list_executions()\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-check-outputs.ff1fd4f19f425b4c550173751822b43d1d88c224.png)\nf. In the left toolbar of **Amazon SageMaker Studio** , choose **Endpoints**. Right-click the **build-train-deploy** endpoint and choose **Describe Endpoint**.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-describe-endpoint.9fce4a1fc1edf1d313f047fcf3d7a08c3436342a.png)\ng. Choose **Monitoring job history**. Notice that the **Monitoring status** shows **In progress**.\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-job-in-progress.71f53f2b4495a140a46185926cec91d755081e84.png)\nOnce the job is complete, the **Monitoring status** displays **Issue found** (for any issues found). \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-job-complete.b737bd9c81ebba5e7965cfdcb503383e1f39eff2.png)\nh. Double-click the issue to view details. You can see that Model Monitor detected large baseline drifts in the **EDUCATION** and **BILL_AMT2** fields that you previously modified.\nModel Monitor also detected some differences in data types in two other fields. The training data consists of integer labels, but the XGBoost model predicts a probability score. Therefore, Model Monitor reported a mismatch. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-monitoring-details.b7ec04489c35ab8e250881100cb8783d084fe1b4.png)\ni. In your **JupyterLab Notebook** , run the following cells to see the output from Model Monitor.\n```\nlatest_execution = mon_executions[-1] # latest execution's index is -1, second to last is -2 and so on..\ntime.sleep(60)\nlatest_execution.wait(logs=False)\nprint(\"Latest execution status: {}\".format(latest_execution.describe()['ProcessingJobStatus']))\nprint(\"Latest execution result: {}\".format(latest_execution.describe()['ExitMessage']))\nlatest_job = latest_execution.describe()\nif (latest_job['ProcessingJobStatus'] != 'Completed'):\n    print(\"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\")\n\n```\n\nCode snippet copied\nCopy\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-job-complete-in-notebook.02e6e572fc344c036e6eb17bf5f89544474d04e6.png)\nj. Run the following code to view the reports generated by Model Monitor. \n```\nreport_uri=latest_execution.output.destination\nprint('Report Uri: {}'.format(report_uri))\nfrom urllib.parse import urlparse\ns3uri = urlparse(report_uri)\nreport_bucket = s3uri.netloc\nreport_key = s3uri.path.lstrip('/')\nprint('Report bucket: {}'.format(report_bucket))\nprint('Report key: {}'.format(report_key))\ns3_client = boto3.Session().client('s3')\nresult = s3_client.list_objects(Bucket=rawbucket, Prefix=report_key)\nreport_files = [report_file.get(\"Key\") for report_file in result.get('Contents')]\nprint(\"Found Report Files:\")\nprint(\"\\n \".join(report_files))\n\n```\n\nCode snippet copied\nCopy\nYou can see that in addition to **statistics.json** and **constraints.json** , there is a new file generated named **constraint_violations.json**. The contents of this file were displayed above in Amazon SageMaker Studio (Step g).\n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-constraints-violation.bb9c8bfcfc663443b50f70ba6445c25bdd728c59.png)\n**Note:** Once you set up data capture, Amazon SageMaker Studio automatically creates a notebook for you that contains the code above to run monitoring jobs. To access the notebook, right-click the endpoint and choose **Describe Endpoint**. On the **Monitoring results** tab, choose **Enable Monitoring**. This step automatically opens a Jupyter notebook containing the code you authored above. \n![](https://d1.awsstatic.com/Getting%20Started/tutorials/tutorial-sagemaker-studio-model-monitor.3d2d7aa2dbe60180cffe0fb4ba2dedb6a79c5273.png)\n###  Step 10. Clean up\nIn this step, you terminate the resources you used in this lab. \n**Important:** Terminating resources that are not actively being used reduces costs and is a best practice. Not terminating your resources will result in charges to your account.\na. **Delete monitoring schedules:** In your Jupyter notebook, copy and paste the following code and choose **Run**.\n**Note:** You cannot delete the Model Monitor endpoint until all of the monitoring jobs associated with the endpoint are deleted.\n```\nmy_default_monitor.delete_monitoring_schedule()\ntime.sleep(10) # actually wait for the deletion\n\n```\n\nCode snippet copied\nCopy\nb. **Delete your endpoint:** In your Jupyter notebook, copy and paste the following code and choose **Run**.\n**Note:** Make sure you have first deleted all monitoring jobs associated with the endpoint.\n```\nsm.delete_endpoint(EndpointName = endpoint_name)\n```\n\nCode snippet copied\nCopy\nIf you want to clean up all training artifacts (models, preprocessed data sets, etc.), copy and paste the following code into your code cell and choose **Run**.\n**Note:** Make sure to replace ACCOUNT_NUMBER with your account number. \n```\n%%sh\naws s3 rm --recursive s3://sagemaker-us-east-2-ACCOUNT_NUMBER/sagemaker-modelmonitor/data\n\n```\n\nCode snippet copied\nCopy\n##  Conclusion\nCongratulations! You created, trained, deployed, and monitored a machine learning model with Amazon SageMaker Studio. \nYou can continue your machine learning journey with SageMaker by following the next steps section below. \n###  Was this page helpful?\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ Feedback ](https://docs-feedback.aws.amazon.com/feedback.jsp?feedback_destination_id=29e3b6b0-4a70-4d70-a6ec-6459755d2383&topic_url=https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n[ ](https://docs-feedback.aws.amazon.com/feedback.jsp?feedback_destination_id=29e3b6b0-4a70-4d70-a6ec-6459755d2383&topic_url=https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio \"Feedback\")\nClose\nThank you for your feedback \nFeedback helps us improve our experience. If you would like to share more details on the feedback, please click the feedback button below. \n[ Feedback ](https://docs-feedback.aws.amazon.com/feedback.jsp?feedback_destination_id=29e3b6b0-4a70-4d70-a6ec-6459755d2383&topic_url=https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio)\n[ Explore example ML notebooks  Explore example notebooks that show how to apply machine learning, deep learning and reinforcement learning in Amazon SageMaker.  ](https://github.com/awslabs/amazon-sagemaker-examples)\n[ **Take a tour of Amazon SageMaker Studio** See the Amazon SageMaker UI overview.  ](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html)\n[ Learn how to build, train, and deploy ML models automatically with Amazon SageMaker Autopilot  Complete the 10-minute tutorial to create a machine learning model automatically with Amazon SageMaker Autopilot.  ](https://aws.amazon.com/getting-started/hands-on/create-machine-learning-model-automatically-sagemaker-autopilot/)\n[ Sign In to the Console ](https://console.aws.amazon.com/console/home?nc1=f_ct&src=footer-signin-mobile)\n###  Learn About AWS\n  * [What Is AWS?](https://aws.amazon.com/what-is-aws/?nc1=f_cc)\n  * [What Is Cloud Computing?](https://aws.amazon.com/what-is-cloud-computing/?nc1=f_cc)\n  * [AWS Accessibility](https://aws.amazon.com/accessibility/?nc1=f_cc)\n  * [What Is DevOps?](https://aws.amazon.com/devops/what-is-devops/?nc1=f_cc)\n  * [What Is a Container?](https://aws.amazon.com/containers/?nc1=f_cc)\n  * [What Is a Data Lake?](https://aws.amazon.com/what-is/data-lake/?nc1=f_cc)\n  * [What is Artificial Intelligence (AI)?](https://aws.amazon.com/what-is/artificial-intelligence/?nc1=f_cc)\n  * [What is Generative AI?](https://aws.amazon.com/what-is/generative-ai/?nc1=f_cc)\n  * [What is Machine Learning (ML)?](https://aws.amazon.com/what-is/machine-learning/?nc1=f_cc)\n  * [AWS Cloud Security](https://aws.amazon.com/security/?nc1=f_cc)\n  * [What's New](https://aws.amazon.com/new/?nc1=f_cc)\n  * [Blogs](https://aws.amazon.com/blogs/?nc1=f_cc)\n  * [Press Releases](https://press.aboutamazon.com/press-releases/aws \"Press Releases\")\n\n\n###  Resources for AWS\n  * [Getting Started](https://aws.amazon.com/getting-started/?nc1=f_cc)\n  * [Training and Certification](https://aws.amazon.com/training/?nc1=f_cc)\n  * [AWS Trust Center](https://aws.amazon.com/trust-center/?nc1=f_cc)\n  * [AWS Solutions Library](https://aws.amazon.com/solutions/?nc1=f_cc)\n  * [Architecture Center](https://aws.amazon.com/architecture/?nc1=f_cc)\n  * [Product and Technical FAQs](https://aws.amazon.com/faqs/?nc1=f_dr)\n  * [Analyst Reports](https://aws.amazon.com/resources/analyst-reports/?nc1=f_cc)\n  * [AWS Partners](https://aws.amazon.com/partners/work-with-partners/?nc1=f_dr)\n\n\n###  Developers on AWS\n  * [Developer Center](https://aws.amazon.com/developer/?nc1=f_dr)\n  * [SDKs & Tools](https://aws.amazon.com/developer/tools/?nc1=f_dr)\n  * [.NET on AWS](https://aws.amazon.com/developer/language/net/?nc1=f_dr)\n  * [Python on AWS](https://aws.amazon.com/developer/language/python/?nc1=f_dr)\n  * [Java on AWS](https://aws.amazon.com/developer/language/java/?nc1=f_dr)\n  * [PHP on AWS](https://aws.amazon.com/developer/language/php/?nc1=f_cc)\n  * [JavaScript on AWS](https://aws.amazon.com/developer/language/javascript/?nc1=f_dr)\n\n\n###  Help\n  * [Contact Us](https://aws.amazon.com/contact-us/?nc1=f_m)\n  * [Get Expert Help](https://iq.aws.amazon.com/?utm=mkt.foot/?nc1=f_m)\n  * [File a Support Ticket](https://console.aws.amazon.com/support/home/?nc1=f_dr)\n  * [AWS re:Post](https://repost.aws/?nc1=f_dr)\n  * [Knowledge Center](https://repost.aws/knowledge-center/?nc1=f_dr)\n  * [AWS Support Overview](https://aws.amazon.com/premiumsupport/?nc1=f_dr)\n  * [Legal](https://aws.amazon.com/legal/?nc1=f_cc)\n  * [AWS Careers](https://aws.amazon.com/careers/)\n\n\n[ Create an AWS Account ](https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc1=f_ct&src=default)\n[ ](https://twitter.com/awscloud \"Twitter\")\n[ ](https://www.facebook.com/amazonwebservices \"Facebook\")\n[ ](https://www.linkedin.com/company/amazon-web-services/ \"Linkedin\")\n[ ](https://www.instagram.com/amazonwebservices/ \"Instagram\")\n[ ](https://www.twitch.tv/aws \"Twitch\")\n[ ](https://www.youtube.com/user/AmazonWebServices/Cloud/ \"YouTube\")\n[ ](https://aws.amazon.com/podcasts/ \"Podcast\")\n[ ](https://pages.awscloud.com/communication-preferences?trk=homepage \"Email\")\nAmazon is an Equal Opportunity Employer: _Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age._\n  * Language\n  * [عربي](https://aws.amazon.com/ar/?nc1=h_ls)\n  * [Bahasa Indonesia](https://aws.amazon.com/id/?nc1=h_ls)\n  * [Deutsch](https://aws.amazon.com/de/?nc1=h_ls)\n  * [English](https://aws.amazon.com/?nc1=h_ls)\n  * [Español](https://aws.amazon.com/es/?nc1=h_ls)\n  * [Français](https://aws.amazon.com/fr/?nc1=h_ls)\n  * [Italiano](https://aws.amazon.com/it/?nc1=h_ls)\n  * [Português](https://aws.amazon.com/pt/?nc1=h_ls)\n  * [Tiếng Việt](https://aws.amazon.com/vi/?nc1=f_ls)\n  * [Türkçe](https://aws.amazon.com/tr/?nc1=h_ls)\n  * [Ρусский](https://aws.amazon.com/ru/?nc1=h_ls)\n  * [ไทย](https://aws.amazon.com/th/?nc1=f_ls)\n  * [日本語](https://aws.amazon.com/jp/?nc1=h_ls)\n  * [한국어](https://aws.amazon.com/ko/?nc1=h_ls)\n  * [中文 (简体)](https://aws.amazon.com/cn/?nc1=h_ls)\n  * [中文 (繁體)](https://aws.amazon.com/tw/?nc1=h_ls)\n\n\n  * [Privacy](https://aws.amazon.com/privacy/?nc1=f_pr)\n  * |\n  * [Accessibility](https://aws.amazon.com/accessibility/?nc1=f_acc)\n  * |\n  * [Site Terms](https://aws.amazon.com/terms/?nc1=f_pr)\n  * |\n  * [ Cookie Preferences ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/)\n  * |\n  * © 2025, Amazon Web Services, Inc. or its affiliates. All rights reserved.\n\n\n####  Ending Support for Internet Explorer\n[ Got it ](https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/ \"Close\")\nAWS support for Internet Explorer ends on 07/31/2022. Supported browsers are Chrome, Firefox, Edge, and Safari. [Learn more »](https://aws.amazon.com/blogs/aws/heads-up-aws-support-for-internet-explorer-11-is-ending/)\nGot it\n",
    "content_quality_score": 0.8,
    "summary": null,
    "child_urls": [
        "https://aws.amazon.com/legal/cookies/",
        "https://aws.amazon.com/privacy/",
        "https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/#aws-page-content-main",
        "https://aws.amazon.com/?nc2=h_lg",
        "https://aws.amazon.com/about-aws/?nc2=h_header",
        "https://aws.amazon.com/contact-us/?nc2=h_header",
        "https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio/?trk=ha_a134p000004f0SDAAY~ha_awssm-5821_all-users/",
        "https://console.aws.amazon.com/console/home?nc2=h_ct&src=header-signin",
        "https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct&src=header_signup",
        "https://auth.aws.amazon.com/sign-in",
        "https://aws.amazon.com/profile",
        "https://auth.aws.amazon.com/sign-out",
        "https://aws.amazon.com/q/?nc2=h_ql_prod_l1_q",
        "https://aws.amazon.com/products/?nc2=h_ql_prod",
        "https://aws.amazon.com/solutions/?nc2=h_ql_sol",
        "https://aws.amazon.com/pricing/?nc2=h_ql_pr",
        "https://aws.amazon.com/documentation-overview/?nc2=h_ql_doc_do",
        "https://aws.amazon.com/getting-started/?nc2=h_ql_le",
        "https://aws.amazon.com/partners/?nc2=h_ql_pn",
        "https://aws.amazon.com/marketplace/?nc2=h_ql_mp",
        "https://aws.amazon.com/customer-enablement/?nc2=h_ql_ce",
        "https://aws.amazon.com/events/?nc2=h_ql_ev",
        "https://aws.amazon.com/contact-us/?nc2=h_ql_exm",
        "https://aws.amazon.com/ar/?nc1=h_ls",
        "https://aws.amazon.com/id/?nc1=h_ls",
        "https://aws.amazon.com/de/?nc1=h_ls",
        "https://aws.amazon.com/?nc1=h_ls",
        "https://aws.amazon.com/es/?nc1=h_ls",
        "https://aws.amazon.com/fr/?nc1=h_ls",
        "https://aws.amazon.com/it/?nc1=h_ls",
        "https://aws.amazon.com/pt/?nc1=h_ls",
        "https://aws.amazon.com/vi/?nc1=f_ls",
        "https://aws.amazon.com/tr/?nc1=h_ls",
        "https://aws.amazon.com/ru/?nc1=h_ls",
        "https://aws.amazon.com/th/?nc1=f_ls",
        "https://aws.amazon.com/jp/?nc1=h_ls",
        "https://aws.amazon.com/ko/?nc1=h_ls",
        "https://aws.amazon.com/cn/?nc1=h_ls",
        "https://aws.amazon.com/tw/?nc1=h_ls",
        "https://aws.amazon.com/profile/?nc2=h_m_mc",
        "https://auth.aws.amazon.com/sign-out/?nc2=h_m_mc",
        "https://console.aws.amazon.com/?nc2=h_m_mc",
        "https://console.aws.amazon.com/billing/home#/account?nc2=h_m_ma",
        "https://console.aws.amazon.com/billing/home?nc2=h_m_bc",
        "https://console.aws.amazon.com/iam/home?nc2=h_m_sc#security_credential",
        "https://phd.aws.amazon.com/?nc2=h_m_sc",
        "https://console.aws.amazon.com/support/home/?nc2=h_ql_cu",
        "https://iq.aws.amazon.com/?utm=mkt.nav",
        "https://aws.amazon.com/premiumsupport/?nc2=h_m_bc",
        "https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_mobile",
        "https://aws.amazon.com/contact-us/?nc2=h_mobile",
        "https://aws.amazon.com/products/?nc2=h_mo",
        "https://aws.amazon.com/solutions/?nc2=h_mo",
        "https://aws.amazon.com/pricing/?nc2=h_mo",
        "https://aws.amazon.com/what-is-aws/?nc2=h_mo",
        "https://aws.amazon.com/getting-started/?nc2=h_mo",
        "https://aws.amazon.com/documentation-overview/?nc2=h_mo",
        "https://aws.amazon.com/training/?nc2=h_mo",
        "https://aws.amazon.com/developer/?nc2=h_mo",
        "https://aws.amazon.com/solutions/case-studies/?nc2=h_mo",
        "https://aws.amazon.com/partners/?nc2=h_mo",
        "https://aws.amazon.com/marketplace/?nc2=h_mo",
        "https://console.aws.amazon.com/support/home?nc2=h_ql_cu",
        "https://console.aws.amazon.com/console/home",
        "https://aws.amazon.com/console/mobile/",
        "https://aws.amazon.com/tutorials/?ref=tutorials_navbar",
        "https://aws.amazon.com/getting-started/?ref=tutorials_navbar",
        "https://aws.amazon.com/developer/?ref=tutorials_navbar",
        "https://aws.amazon.com/it-pro/?ref=tutorials_navbar",
        "https://aws.amazon.com/architecture/?ref=tutorials_navbar",
        "https://aws.amazon.com/developer/tools/?ref=tutorials_navbar",
        "https://aws.amazon.com/builders-library/?ref=tutorials_navbar",
        "https://docs.aws.amazon.com/?ref=tutorials_navbar",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html",
        "https://aws.amazon.com/getting-started/hands-on/build-train-deploy-machine-learning-model-sagemaker/",
        "https://aws.amazon.com/sagemaker/",
        "https://aws.amazon.com/free/",
        "https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?client=lightsail&fid=3BE5EA8FA64943AD-0284EED1954F5F15",
        "https://lightsail.aws.amazon.com/ls/",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio.html",
        "https://console.aws.amazon.com/sagemaker/",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html",
        "https://aws.amazon.com/s3/",
        "https://aws.amazon.com/sagemaker/pricing/",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/use-scikit-learn-processing-container.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html",
        "https://docs-feedback.aws.amazon.com/feedback.jsp?feedback_destination_id=29e3b6b0-4a70-4d70-a6ec-6459755d2383&topic_url=https://aws.amazon.com/tutorials/build-train-deploy-monitor-machine-learning-model-sagemaker-studio",
        "https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html",
        "https://aws.amazon.com/getting-started/hands-on/create-machine-learning-model-automatically-sagemaker-autopilot/",
        "https://console.aws.amazon.com/console/home?nc1=f_ct&src=footer-signin-mobile",
        "https://aws.amazon.com/what-is-aws/?nc1=f_cc",
        "https://aws.amazon.com/what-is-cloud-computing/?nc1=f_cc",
        "https://aws.amazon.com/accessibility/?nc1=f_cc",
        "https://aws.amazon.com/devops/what-is-devops/?nc1=f_cc",
        "https://aws.amazon.com/containers/?nc1=f_cc",
        "https://aws.amazon.com/what-is/data-lake/?nc1=f_cc",
        "https://aws.amazon.com/what-is/artificial-intelligence/?nc1=f_cc",
        "https://aws.amazon.com/what-is/generative-ai/?nc1=f_cc",
        "https://aws.amazon.com/what-is/machine-learning/?nc1=f_cc",
        "https://aws.amazon.com/security/?nc1=f_cc",
        "https://aws.amazon.com/new/?nc1=f_cc",
        "https://aws.amazon.com/blogs/?nc1=f_cc",
        "https://press.aboutamazon.com/press-releases/aws",
        "https://aws.amazon.com/getting-started/?nc1=f_cc",
        "https://aws.amazon.com/training/?nc1=f_cc",
        "https://aws.amazon.com/trust-center/?nc1=f_cc",
        "https://aws.amazon.com/solutions/?nc1=f_cc",
        "https://aws.amazon.com/architecture/?nc1=f_cc",
        "https://aws.amazon.com/faqs/?nc1=f_dr",
        "https://aws.amazon.com/resources/analyst-reports/?nc1=f_cc",
        "https://aws.amazon.com/partners/work-with-partners/?nc1=f_dr",
        "https://aws.amazon.com/developer/?nc1=f_dr",
        "https://aws.amazon.com/developer/tools/?nc1=f_dr",
        "https://aws.amazon.com/developer/language/net/?nc1=f_dr",
        "https://aws.amazon.com/developer/language/python/?nc1=f_dr",
        "https://aws.amazon.com/developer/language/java/?nc1=f_dr",
        "https://aws.amazon.com/developer/language/php/?nc1=f_cc",
        "https://aws.amazon.com/developer/language/javascript/?nc1=f_dr",
        "https://aws.amazon.com/contact-us/?nc1=f_m",
        "https://iq.aws.amazon.com/?utm=mkt.foot/?nc1=f_m",
        "https://console.aws.amazon.com/support/home/?nc1=f_dr",
        "https://aws.amazon.com/premiumsupport/?nc1=f_dr",
        "https://aws.amazon.com/legal/?nc1=f_cc",
        "https://aws.amazon.com/careers/",
        "https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc1=f_ct&src=default",
        "https://aws.amazon.com/podcasts/",
        "https://aws.amazon.com/privacy/?nc1=f_pr",
        "https://aws.amazon.com/accessibility/?nc1=f_acc",
        "https://aws.amazon.com/terms/?nc1=f_pr",
        "https://aws.amazon.com/blogs/aws/heads-up-aws-support-for-internet-explorer-11-is-ending/",
        "https://pulse.aws/application/ZRPLWLL6?p=0",
        "https://repost.aws/knowledge-center/?nc2=h_m_ma",
        "https://repost.aws/",
        "https://repost.aws/?trk=859f3c3f-c0fa-4b16-9fd5-8f05cf9273de",
        "https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients",
        "https://sagemaker.readthedocs.io/en/stable/",
        "https://github.com/awslabs/amazon-sagemaker-examples/tree/master/sagemaker_processing/scikit_learn_data_processing_and_model_evaluation",
        "https://github.com/awslabs/deequ",
        "https://github.com/awslabs/amazon-sagemaker-examples",
        "https://repost.aws/?nc1=f_dr",
        "https://repost.aws/knowledge-center/?nc1=f_dr",
        "https://twitter.com/awscloud",
        "https://www.facebook.com/amazonwebservices",
        "https://www.linkedin.com/company/amazon-web-services/",
        "https://www.instagram.com/amazonwebservices/",
        "https://www.twitch.tv/aws",
        "https://www.youtube.com/user/AmazonWebServices/Cloud/",
        "https://pages.awscloud.com/communication-preferences?trk=homepage"
    ]
}