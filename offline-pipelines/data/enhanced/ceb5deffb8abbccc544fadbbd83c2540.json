{
    "id": "ceb5deffb8abbccc544fadbbd83c2540",
    "metadata": {
        "id": "ceb5deffb8abbccc544fadbbd83c2540",
        "url": "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/",
        "title": "The Taxonomy for Data Transformations in AI Systems  - Hopsworks",
        "properties": {
            "description": "The data transformation taxonomy is important to understand for any AI application that wants to reuse feature data in more than one model.",
            "keywords": null,
            "author": null,
            "og:title": "The Taxonomy for Data Transformations in AI Systems  - Hopsworks",
            "og:description": "The data transformation taxonomy is important to understand for any AI application that wants to reuse feature data in more than one model.",
            "og:image": "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/668d97122ea716ed1633a7f7_PR%20Blog%202_Taxonomy.png",
            "og:type": "website",
            "twitter:card": "summary_large_image"
        }
    },
    "parent_metadata": {
        "id": "2af82b33c08a88f2a491a9a15f282ab2",
        "url": "https://www.notion.so/Components-Architecture-and-System-Design-2af82b33c08a88f2a491a9a15f282ab2",
        "title": "Components, Architecture, and System Design",
        "properties": {
            "Type": "Leaf"
        }
    },
    "content": "![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61f958575ff62d320d46701e_closeicon.png)\nScheduled upgrade from November 26, 07:00 UTC to November 26, 17:00 UTC\nKindly note that during the maintenance window, app.hopsworks.ai will not be accessible.\n5\n[View the Changes](https://www.hopsworks.ai/news/hopsworks-4-0-breaking-changes)\n![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61f958575ff62d320d46701e_closeicon.png)\nScheduled upgrade from November 26, 07:00 UTC to November 26, 17:00 UTC\nKindly note that during the maintenance window, app.hopsworks.ai will not be accessible.\n5\n[View the Changes](https://www.hopsworks.ai/news/hopsworks-4-0-breaking-changes)\nScheduled upgrade from November 26, 07:00 UTC to November 26, 17:00 UTC\n[Contact](https://www.hopsworks.ai/contact/main)[Login](https://app.hopsworks.ai)[![Github Mark](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/6418216a570b0da3d471661a_icons8-slack-new.svg)](https://join.slack.com/t/public-hopsworks/shared_invite/zt-1uf21vitz-rhHKNdIf8GEiOf1EJ6Wzsw)[![Github Mark](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/62261cde4669f63d3880938d_github.svg)](https://github.com/logicalclocks/hopsworks)[![linkedin logo](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.linkedin.com/company/hopsworks/)[![Twitter icon](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/66a346ea27ec6d7c0e354747_icons8-twitter%20\\(1\\).svg)](https://twitter.com/hopsworks)\n[![Untitled UI logotext](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/6202a13e7cafec5553703f6b_logo.svg)![Logo](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/666c3cc1cfc4741e6b2d9fe6_untitled-ui-logo.png)](https://www.hopsworks.ai/)\nProduct\n[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/5fad49f715203ed9d66fc1b0_Hops%20Icon%20Green.png)Hopsworks EnterpriseFull edition of Hopsworks, high levels of SLAs and support.](https://www.hopsworks.ai/try)[IntegrationsLeverage your existing data sources and tools.](https://www.hopsworks.ai/integrations)[ExamplesGet up and running on new features and techniques.](https://www.hopsworks.ai/hopsworks-examples)[FAQAll you need to know about Hopsworks.](https://www.hopsworks.ai/frequently-asked-questions)\n[Hopsworks On-PremisesManage everything securely within your data center.](https://www.hopsworks.ai/product-capabilities/feature-store-on-premises)[Performance & High AvailabilityHighest performance requirements in the industry.](https://www.hopsworks.ai/product-capabilities/operational-performance-and-high-availability)[Feature Engineering in PythonPython-first collaborative environment.](https://www.hopsworks.ai/product-capabilities/feature-engineering-in-python)[Other capabilitiesRead about our extended platform capabilities.](https://www.hopsworks.ai/product-capabilities)\nSolutions\nFor your Team\n[Technical Stakeholders](https://www.hopsworks.ai/solutions/teams)[Machine Learning Engineers](https://www.hopsworks.ai/solutions/teams?tab=ml-engineers)[Data Engineers](https://www.hopsworks.ai/solutions/teams?tab=data-engineers)[Data Scientists](https://www.hopsworks.ai/solutions/teams?tab=data-scientists)[DevOps](https://www.hopsworks.ai/solutions/teams?tab=devops)[Architects](https://www.hopsworks.ai/solutions/teams?tab=architects)[Non-Technical Stakeholders](https://www.hopsworks.ai/solutions/teams?tab=non-technical)[Project Managers ](https://www.hopsworks.ai/solutions/teams?tab=non-technical)\nFor your Industry\n[Defense and Law Enforcement](https://www.hopsworks.ai/solutions/industry/defense-and-law-enforcement)\n[FSI](https://www.hopsworks.ai/solutions/industry/fsi)\n[Online Retail & E-commerce](https://www.hopsworks.ai/solutions/industry/online-retail-and-e-commerce)\n[Public Sector](https://www.hopsworks.ai/solutions/industry/public-sector)\n[Research and Healthcare](https://www.hopsworks.ai/solutions/industry/research-and-healthcare)\n[iGaming](https://www.hopsworks.ai/solutions/industry/i-gaming)\n[All Solutions](https://www.hopsworks.ai/solutions/all)\nUse Cases\n[Generative AI](https://www.hopsworks.ai/use-case/fine-tuning-llms-rag-for-genai)[Real-time Fraud Detection](https://www.hopsworks.ai/use-case/realtime-fraud-detection)[Hopsworks Medical Copilot](https://www.hopscopilot.com/)\n[CustomersExplore how our customers leverage Hopsworks.](https://www.hopsworks.ai/customers)\n[Pricing](https://www.hopsworks.ai/pricing)[Blog](https://www.hopsworks.ai/blog)[Pricing](https://www.hopsworks.ai/pricing)[Blog](https://www.hopsworks.ai/blog)\nResources\n[MLOps DictionaryComprehensive terminology guide for ML solutions.](https://www.hopsworks.ai/mlops-dictionary)[DocumentationDetailed information to help you effectively utilize Hopsworks.](https://docs.hopsworks.ai/latest/)[Research PapersDiscover how our research is driving innovation.](https://www.hopsworks.ai/research-papers)[CommunityJoin our community and get all your questions answered. ](https://community.hopsworks.ai/)\n[EventsOnline & Offline sessions and workshops. ](https://www.hopsworks.ai/events)[AcademyEverything about ML Systems, and the Hopsworks platform.](https://www.hopsworks.ai/academy)[Feature Store ComparisonIn-depth comparisons of feature stores highlighting key features.](https://www.hopsworks.ai/product-comparison/sagemaker)[FAQ: EU AI ActA complete guide to The EU AI Act.](https://www.hopsworks.ai/faq-eu-ai-act)\nCompany\n[About usLearn more about our team. ](https://www.hopsworks.ai/about-us)[NewsThe latest industry news, updates and info.](https://www.hopsworks.ai/news)[Security & ComplianceRobust security and compliance with industry standards.](https://www.hopsworks.ai/security-compliance)\n[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/66a0b13c473a71304470c35a_oreilly_logo_mark_red.svg)Book](https://www.hopsworks.ai/lp/oreilly-book-building-ml-systems-with-a-feature-store)[Benchmarks](https://www.hopsworks.ai/index#performance)\n[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/63e4e90bd6c2ad05ecd89669_icons8-great-britain-96.png)EN](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/63e4e90b88b00c69a52f92cc_icons8-germany-96.png)DE](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)\n[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/63e4e90bd6c2ad05ecd89669_icons8-great-britain-96.png)EN](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)[![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/63e4e90b88b00c69a52f92cc_icons8-germany-96.png)DE](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)\n[![arrow back](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/6183f249d69379869e0b3524_icons8-chevron-left-30.png)Back to Blog](https://www.hopsworks.ai/blog)\n[![arrow back](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/6183f249d69379869e0b3524_icons8-chevron-left-30.png)Back to Blog](https://www.hopsworks.ai/blog)\nManu Joseph\n[![link to linkedin](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)\nData Scientist\nJim Dowling\n[![link to linkedin](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.linkedin.com/in/jim-dowling-206a98/)\nCEO and Co-Founder\n**Let's keep in touch!**\n**Subscribe to our newsletter and receive the latest product updates, upcoming events, and industry news.**\n**More Blogs**\n[ Migrating from AWS to a European Cloud - How We Cut Costs by 62%](https://www.hopsworks.ai/post/migrating-from-aws-to-a-european-cloud-how-we-cut-costs-by-62)\n[The 10 Fallacies of MLOps](https://www.hopsworks.ai/post/the-10-fallacies-of-mlops)\n[Hopsworks AI Lakehouse: The Power of Integrated MLOps Components](https://www.hopsworks.ai/post/hopsworks-ai-lakehouse-the-power-of-integrated-mlops-components)\n[Unlocking the Power of AI in Government](https://www.hopsworks.ai/post/the-power-of-ai-in-government)\n[Optimizing AI Costs](https://www.hopsworks.ai/post/optimizing-ai-costs)\nArticle updated on\n# The Taxonomy for Data Transformations in AI Systems\nIf you plan to reuse features, you need to understand the Taxonomy\n[![link to github](https://cdn.prod.website-files.com/5e6f7cd3ee7f51d539a4da0b/605b3c459e87eff3298d0e25_github%20\\(1\\).svg)](https://github.com/logicalclocks/hopsworks)\n[![Share on Twitter](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61b0ae07358bb3d1224410c1_Twitter%20icon.svg)](https://twitter.com/share?url=https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems)\n[![share on linkedin](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.linkedin.com/shareArticle?mini=true&url=https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems&title=The Taxonomy for Data Transformations in AI Systems - Hopsworks)\nJuly 1, 2024\n30 min\nRead\nManu Joseph\n[Manu Joseph](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)[![link to linkedin](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/)\nData Scientist\nHopsworks\nJim Dowling\n[Jim Dowling](https://www.linkedin.com/in/jim-dowling-206a98/)[![link to linkedin](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/61926637aaba4d3968d7956d_linkedin.svg)](https://www.linkedin.com/in/jim-dowling-206a98/)\nCEO and Co-Founder\nHopsworks\n[MLOps](https://www.hopsworks.ai/blog-categories/mlops)\n[Data Engineering](https://www.hopsworks.ai/blog-categories/data-engineering)\n[SIGMOD 2024](https://www.hopsworks.ai/blog-categories/sigmod-2024)\n## TL;DR\nThis article introduces a taxonomy for data transformations in AI applications that is fundamental for any AI system that wants to reuse feature data in more than one model. The taxonomy consists of model-independent data transformations that produce reusable features (for example, total customer spend in the last week), model-dependent transformations that produce features that are specific to one model (for example, normalizing that customer spend value using the mean and standard deviation of all customer spends in the model’s training dataset), and on-demand transformations, found in real-time AI systems, that require data only available at request-time (for example, transforming longitude/latitude to a zipcode). The data transformation taxonomy shows you what data transformations to apply in which AI pipelines, and potential sources of offline-online skew. We finish the article comparing how existing feature stores fare in addressing the taxonomy, and the event-sourcing pattern requires full support for the taxonomy. \n[Introduction](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#introduction)  \n---  \n[1 - Data Transformation Taxonomy for AI](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#data-transformation)  \n[a. Model-Dependent Transformations](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#dependent-transformations)  \n[b. Model-Independent Transformations](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#independent-transformations)  \n[c. On-Demand Transformations](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#ondemand-transformations)  \n[i. On-Demand Transformations without a Feature Store](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#with-feature)  \n[ii. On-Demand Transformations as Functions, not Microservices](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#as-functions)  \n[2 - Existing Feature Store support for the Data Transformation Taxonomy](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#existing-support)  \n[a. Preprocessing Pipelines and Model-Dependent Transformations](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#pre-processed)  \n[3 - Hopsworks and the Data Transformation Taxonomy](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#hops-taxonomy)  \n[4 - Summary](https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#summary)  \nThis article is part 2 in a 7 part series describing in lay terms concepts and results from a [SIGMOD 2024 research paper on the Hopsworks Feature Store](https://www.hopsworks.ai/research-papers/the-hopsworks-feature-store-for-machine-learning). \nOther Parts: 1 ([Modularity and Composability for AI Systems](https://www.hopsworks.ai/post/modularity-and-composability-for-ai-systems-with-ai-pipelines-and-shared-storage)), 3 ([Use all features: Snowflake Schema)](https://www.hopsworks.ai/post/the-journey-from-star-schema-to-snowflake-schema-in-the-feature-store), 4 [(Lakehouse for AI)](https://www.hopsworks.ai/post/the-feature-store-makes-your-data-warehouse-easy-to-use-for-ai), 5 ([From Lakehouse to AI Lakehouse](https://www.hopsworks.ai/post/from-lakehouse-to-ai-lakehouse-with-a-python-native-query-engine)), 6 [(Real-Time AI Database)](https://www.hopsworks.ai/post/rondb-a-real-time-database-for-real-time-ai-systems), 7 ([Reproducible Data](http://www.hopsworks.ai/post/reproducible-data-for-the-ai-lakehouse)). \n## Introduction\nMany [machine learning](https://www.hopsworks.ai/dictionary/ml) models require \"encoded feature data\". That is, a categorical variable transformed into a numerical representation or a numerical variable transformed or scaled to improve model performance. Many data scientists ask an obvious question - should I store encoded [feature data](https://www.hopsworks.ai/dictionary/feature-data) in a feature store?\nMost existing feature stores do not answer this question in their documentation. ChatGPT confidently gives you the wrong answer. It says you should store encoded feature data in a feature store, hallucinating a number of imagined benefits. One of the few answers you will find on Google is [an answer to this Stack Overflow question](https://stackoverflow.com/questions/75079929/storing-encoded-features-in-the-feature-store):\n> “A consultant from one of the big cloud providers opted for storing encoded [features](https://www.hopsworks.ai/dictionary/feature) in the store which I find strange because different models will use the same type of feature but will need different encoding procedures and storing encoded value complicates [model monitoring](https://www.hopsworks.ai/dictionary/ml) and debugging in production.”\nI answered that question as I have been [teaching about model-independent vs model-dependent transformations since 2022](https://www.youtube.com/watch?v=BD1UOJs1Bvo&t=2426s), and given the continued confusion on this topic, I felt compelled to write something more accessible than our research paper linked above.\nData reuse is fundamental to operational, analytical and AI data processing systems. Operational databases organize their data in normalized (2nd/3rd normal form) data models, removing redundant data and reusing tables in views. In [data warehousing](https://www.hopsworks.ai/dictionary/data-warehouse), the medallion architecture organizes data into bronze, silver, and gold tables, where silver tables reuse bronze tables, gold tables reuse silver tables, and dashboards and AI systems reuse gold tables. Data reuse is less well understood for AI systems, but is still practiced by all hyperscalers. For example, [Meta reported](https://dl.acm.org/doi/10.1145/3534678.3539059) that “most features are used by many models”. They specifically said that the most popular 100 features are reused in over 100 different models. They claim [feature reuse](https://www.hopsworks.ai/dictionary/feature-reuse) results in higher quality features through increased usage, reduced storage costs, reduced feature development and operational costs. Like other Enterprises, Meta reuses feature data using [a feature store](https://www.hopsworks.ai/dictionary/feature-store).\nAlthough Meta showed the benefit of feature stores in enabling features to be computed once and then reused in many different models, it is important to note that not all necessary [data transformations](https://www.hopsworks.ai/dictionary/data-transformation) in an AI system can happen before the feature store. If you store an encoded feature in the feature store, it will prevent a model from reusing that feature if it wants to encode the feature differently. For example, gradient-descent models often work better when numerical features have been normalized, but decision trees do not require normalized numerical features. But, if you do not encode feature data before the feature store, this means that not all data transformations can be performed in your [feature pipelines](https://www.hopsworks.ai/dictionary/feature-pipeline) (the [data pipelines](https://www.hopsworks.ai/dictionary/data-pipelines) that transform raw data to features before they are stored in the feature store). Where should you perform the model-specific data transformations for [feature encoding](https://www.hopsworks.ai/dictionary/encoding-for-features)? The answer is that they should be performed consistently in training/inference pipelines - without introducing training/inference skew. As we will see later with Hopsworks, a feature store can add support for model-specific data transformations to ensure there is no skew between the training and inference pipelines.\nThe data transformations familiar to data engineers, such as data cleaning/[filtering](https://www.hopsworks.ai/dictionary/filtering)/aggregations/binning, produce reusable feature data that can be stored in a feature store and used by many models. This feature data is sample-independent - there is no relationship between the feature data and any training datasets created from it.\nIn contrast, many of the data transformations performed by data scientists transform input data into a numerical format to improve [model performance](http://www.hopsworks.ai/dictionary/model-performance). These [model-dependent transformations](https://www.hopsworks.ai/dictionary/model-dependent-transformations) are typically sample dependent, as they are parameterized by the model’s training dataset. That is, the output of these model-dependent transformations is [feature data](https://www.hopsworks.ai/dictionary/feature-data) that is specific to one model - it cannot be reused by other models. Another class of data transformation for AI systems are on-demand transformations that need request-time parameters to be computed. On-demand transformations cannot be precomputed for online inference as they require request-time parameters and functions to compute them can be combined with precomputed data from the feature store.\n[ ![image \\(15\\)](https://no-cache.hubspot.com/cta/default/5524414/interactive-176024224097.png) ](https://cta-service-cms2.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLL8aIV1Q%2B5ZSUfYLKLxVSlUlPku38D2BJ0CuYkCy8h9lgh0Gpu2ooFCOgz6zRefuhkCC2mLJaJwbuiEs%2FTQ9njgFDF%2BXLvsMd8DRQ2UekbP5wohn10%2FrMWjt8DWViwIwazinBqy%2BcAZ0lv%2BfqgKTFoSbOJh4rMKpeEhYyeL%2Bjb%2BuZMeqcWmPtJIy0raFSsndm1lSEE%3D&webInteractiveContentId=176024224097&portalId=5524414)\n## Data Transformation Taxonomy for AI\nData transformations in AI systems are not equivalent, when it comes to feature reuse, as shown in figure 1. Different types of data transformations produce features that can be classified according to a taxonomy.\n[![Data transformations in AI systems are not equivalent, when it comes to feature reuse](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b21b_6682a338ded3a8e40a72b19b_1_data%2520transformation%2520taxonomy_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b21b_6682a338ded3a8e40a72b19b_1_data%2520transformation%2520taxonomy_lightbox.png)\n**_Figure 1:_**_When you want to apply a_[ _data transformation_](https://www.hopsworks.ai/dictionary/transformation) _in an AI system, you need to consider the type of feature created, according to this taxonomy. Reusable features are stored in a feature store, but model-specific features are typically not (they are applied consistently in training and inference pipelines). Real-time AI systems may have on-demand features._\nThe data [transformation](https://www.hopsworks.ai/dictionary/transformation) taxonomy for AI is based on the following observations:\n  * There are **data transformations** that produce **feature data that is reusable across many models**. These transformations produce feature data that is _model independent_. \n  * There are **data transformations** that produce feature data **specific to one model** (and not usable by other models). These can be data transformations that are parameterized a training dataset (a training dataset is typically specific to a single model) or a transformation specific to a model (such as encoding text for a [LLM](https://www.hopsworks.ai/dictionary/llms-large-language-models) using its encoder). \n  * There are **data transformations** that create features for inference in real-time AI systems that **have input parameter(s) only available at request time**. On-demand transformations can also be applied on historical data to produce model-independent feature data for training models.\n\n\n[![Data Transformation comparison](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1df_6682a394decfc5b65e08b199_Table%25201_transformation%2520comparison_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1df_6682a394decfc5b65e08b199_Table%25201_transformation%2520comparison_lightbox.png)\n**_Table 1:_**_A comparison of the different types of Data Transformation based on whether they produce reusable feature data or not, whether they can be precomputed for predictions by AI applications or not, and whether they need request-time data for online inference._\nA taxonomy is a (often hierarchical) classification, where things are organized into groups or types. From the above observations, we can see that data transformations can be classified as model-independent, model-dependent, or on-demand, see figure 2.\n[![Transformations grouped in hierarchical classification](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1fc_6682a382967f6efdcc6da5e9_2_3%2520groups%2520of%2520data%2520transformations_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1fc_6682a382967f6efdcc6da5e9_2_3%2520groups%2520of%2520data%2520transformations_lightbox.png)\n**_Figure 2:_**_Data transformations in AI systems can be classified into one of three groups: model-independent transformations that are performed on raw data to create reusable feature data. Model-dependent transformations are performed on the_[ _training data_](https://www.hopsworks.ai/dictionary/training-data) _for a model as well as on feature data at inference time. On-demand transformations require data that is only available at request time and can either output reusable feature data (model-independent) or be chained with model-dependent transformations to produce model-specific feature data._\nThis data transformation taxonomy for AI systems generalizes to any AI system architecture that has separate training and inference programs - which is pretty much all existing AI systems - and reuses features, which is all AI systems that use a feature store. \nFigure 3 includes our three different types of data transformations and the AI artifacts created by them. The data that arrives over time in the diagram is typically stored in a feature store, but could be any AI system that manages newly arriving data, where the data is used both for [model training](http://www.hopsworks.ai/dictionary/model-training) and inference.\n[![three different types of data transformations and the AI artifacts created by them](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f0_6682a5285f675e07f640d48b_3_3%2520types%2520of%2520transformations_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f0_6682a5285f675e07f640d48b_3_3%2520types%2520of%2520transformations_lightbox.png)\n**_Figure 3:_**_Model-independent transformations are performed on new input data and create reusable feature data for training and inference. Model-dependent transformations are performed in training and inference on feature data and need to be consistent across both training/inference to prevent skew. On-Demand transformations are performed on request data (possibly combined with precomputed feature data) and the output can have further model-dependent transformations applied to it. On-demand transformations can also be performed on historical data (backfilling feature data), creating reusable feature data._\nWe note here that [model-independent transformations](https://www.hopsworks.ai/dictionary/model-independent-transformations) are only found at one place in the diagram, where new and historical data arrives. In contrast, model-dependent transformations and on-demand transformations can be found in two places. Model-dependent transformations need to be applied when creating training data, in training pipelines, but also in inference pipelines, before making predictions. These training and inference pipelines are typically separate programs, which introduces the possibility of skew between the implementations (see [online-offline skew](https://www.hopsworks.ai/dictionary/skew)). Similarly, on-demand transformations are found in [online inference pipelines](https://www.hopsworks.ai/dictionary/online-inference-pipeline), but may also be applied to backfill feature data from historical data in a feature pipeline. Again, online inference programs and feature pipelines are typically separate programs, meaning there is potential for skew between the two on-demand transformations (for example, if there are two different implementations of the on-demand transformation). Online-offline skew is a general challenge for AI systems, and the data transformation taxonomy helps provide an understanding of its cause and alerts you where it can occur, so you can prevent it occurring. In general, the taxonomy also applies to any AI system that aims to create [reusable feature data](https://www.hopsworks.ai/dictionary/feature-reuse), where solutions to online-offline skew will always need to be provided.\n### Model-Dependent Transformations\nModel-dependent transformations produce feature data that is specific to one model. When data scientists talk about transformations, they typically refer to model-dependent transformations, such as transforming a categorical variable into a numerical format or scaling/normalizing/standardizing a numerical variable to improve the performance of your gradient-based ML model. Feature encoding is the most common example of model-dependent transformations in AI systems. Feature encoding transformations are parameterized by the model’s training dataset (they are sample dependent), and as most models typically have their own training dataset, the output data from feature encoding is specific to only that one model. Similarly, transformations that impute missing data are typically parameterized by the training dataset, and are, therefore, model-dependent transformations.\nA well known example of a model-dependent transformation for LLMs, is text tokenization. Each LLM typically has their own tokenizer, and, therefore, tokenization is a model-dependent transformation. For example, if you were to tokenize text when creating [instruction datasets for LLM fine-tuning](https://www.hopsworks.ai/dictionary/instruction-datasets-for-fine-tuning-llms), the tokenized text would not be reusable for [fine-tuning a different LLM.](http://www.hopsworks.ai/dictionary/fine-tuning-llms) This means you should not tokenize text in feature pipelines, where model-independent transformations are performed. Instead, your feature pipeline should create clear-text instruction datasets for fine-tuning, and tokenization should be performed in both the training and inference pipelines, where model-dependent transformations are performed, see figure 4.\n[![Model-dependent transformations are applied in both training and inference pipelines ](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e9_6682a59661617e47e531a5ff_4_on-demand%2520transformations_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e9_6682a59661617e47e531a5ff_4_on-demand%2520transformations_lightbox.png)\n**_Figure 4_** _: Model-dependent transformations are applied in both training and inference pipelines and the transformations need to be consistent to prevent skew. For example, normalizing a numerical feature should use the same values for the mean and standard deviation in both training and inference pipelines._\n### Model-Independent Transformations\nModel-independent transformations produce features that can be reused in many models. They cover the types of transformations that data engineers are very familiar with that are widely used in [feature engineering](https://www.hopsworks.ai/dictionary/feature-engineering), such as:\n  * grouped aggregations (such as the avg/max/min of some numerical variable),\n  * windowed counts (for example, number of clicks per day), \n  * transformations that create RFM (recency, frequency, monetary) features,\n  * binning _to create categorical variables that_ are easier for models to identify signals in sparse data,\n  * stream processing windowed features that are computed in sliding/tumbling/session windows in frameworks like Flink/Beam/Spark-Streaming,\n  * joining data from different sources together using a common join key,\n  * time series transformations that aggregate/extract data over time to produce features that identify trends, patterns, or anomalies.\n\n\nModel-independent transformations are applied once in batch or [streaming feature pipelines](https://www.hopsworks.ai/dictionary/streaming-feature-pipeline), see figure 5. \n[![Model-independent transformations are applied once in batch or streaming feature pipelines](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1ec_6683b87de8bcaaf0a96dc544_v2_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1ec_6683b87de8bcaaf0a96dc544_v2_lightbox.png)\n** _Figure 5:_**_Model-independent transformations are performed in feature pipelines and produce reusable feature data stored in a feature store._\nThe reusable feature data output by feature pipelines is stored in a feature store, to be later used by [downstream](https://www.hopsworks.ai/dictionary/downstream) training and inference pipelines.\n### On-Demand Transformations\nOn-demand transformations are found in real-time AI systems, see figure 6. In an online inference pipeline, an on-demand transformation requires input data that is only available at prediction request time. If an on-demand transformation is implemented as a function, that function has at least one parameter that originates from the prediction request. The function may also include (precomputed feature) parameters that originate from a feature store. \n[![On-demand transformations are found in real-time AI systems](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f3_6682a64bf17f7395ff901934_6_real%2520time%2520ai%2520systems_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f3_6682a64bf17f7395ff901934_6_real%2520time%2520ai%2520systems_lightbox.png)\n** _Figure 6:_**_On-demand transformations are found in online inference pipelines, where they compute features using prediction request data, and they can be combined with “other” precomputed features. On-demand transformations can also be used to compute reusable feature data from backfill data sources._\nWhen historical data used to compute [on-demand features](https://www.hopsworks.ai/dictionary/on-demand-features) is available, you can use the on-demand [feature function](https://www.hopsworks.ai/dictionary/feature-function) to [backfill feature data](https://www.hopsworks.ai/dictionary/backfill-training-data) to a feature store. For example, in figure 7, you can see an event-sourcing pattern, where event data in Kafka is stored in a S3 data lake. You can use that historical data to create on-demand features by applying the same [on-demand transformation](https://www.hopsworks.ai/dictionary/on-demand-transformation) function on the event data in a feature pipeline. \n[![An event-sourcing pattern, where event data in Kafka is stored in a S3 data lake](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e3_6682a6838dd9a33c10e159c3_7_event%2520sourcing%2520pattern_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e3_6682a6838dd9a33c10e159c3_7_event%2520sourcing%2520pattern_lightbox.png)\n** _Figure 7:_**_On-demand transformations can be used in batch feature pipelines to backfill event-sourced feature data from data lakes, like S3._\nThe features created can then be used as [training data](https://www.hopsworks.ai/dictionary/training-data) for models. The feature data created should be model-independent as the transformation should not have model-specific output. If the transformation is model-specific, it should be performed in a model-dependent transformation that can be performed consistently after reading the feature data from the feature store (for historical data) and after any on-demand transformations functions in an online inference pipeline. Note that the model-independent requirement for on-demand transformations means just that the transformation should create sample-independent feature data - it is not parameterized by the training dataset or model itself. An on-demand feature may ultimately only be used by one model, but if its transformations are model-independent, it does not need to be performed in a model-dependent transformation. The benefit of computing on-demand feature data in a feature pipeline over model-dependent transformations in a [training pipeline](https://www.hopsworks.ai/dictionary/training-pipeline) is that you only need to compute them once, not every time you create a training dataset. \nSo, you should factor out those parts of the online transformation that are model-specific (such as feature encoding) from those that are model-independent. The parts that are model-independent go in the on-demand transformation logic, while model-specific transformations still happen in model-dependent transformations. In online inference, the output of an on-demand transformation function is passed through model-dependent transformations before it is received by the model.\n[ ![The AI Lakehouse](https://no-cache.hubspot.com/cta/default/5524414/interactive-177758961194.png) ](https://cta-service-cms2.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLKqezz9RftCB8ctXyqqlNDjMtJOTRyq%2Fp99txGDgWWoYNFsozaC3wZyD4Oo%2B5cjVs9eqtTCAi%2FnFOL4iBrm3V%2BJEmBKxoIKlHSZ%2B%2FImF1ZMW615qSSuiagfvpQHMmN22urTwQreKeJCnmc7aA5vmtWs37EceSIAudMZH3l%2FwlbReFkxxwl5urF4MsgbQwpOoLY%3D&webInteractiveContentId=177758961194&portalId=5524414)\n#### On-Demand Transformations without a Feature Store\nIn Figure 8, you can see an architecture diagram from an unnamed payments company that did not include a feature store to store the output of their on-demand transformation functions on historical data. The result is massively decreased productivity for data scientists, as any changes to training datasets require many hours of massive PySpark jobs to recompute the training data. A feature store that supports model-independent on-demand transformation functions (like Hopsworks) would have enabled them to compute the feature data incrementally as new events arrive, and create new training datasets in seconds (for EDA) or minutes (for full training). Feature stores that treat on-demand transformation functions as model-dependent transformations (Databricks, Tecton) have the same problem as the payments company below - they have to recompute all on-demand features every time they want to create new training data with them.\n[![Architectural diagram without a feature store to store the output of their on-demand transformation functions on historical data. ](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b203_6682a73911329cf4cf20a985_8_architecture%2520without%2520feature%2520store_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b203_6682a73911329cf4cf20a985_8_architecture%2520without%2520feature%2520store_lightbox.png)\n**_Figure 8:_**_In this event-sourcing pattern, event data from Kafka is stored to S3 as historical data used to create training data. The on-demand transformation functions in Python in the ingestion, projection,and features packages are applied to TBs of event data using two PySpark jobs that take many hours to create training data. This makes iterating on training data very slow for data scientists - every time you want to change something in the training data, you have to recompute all the training data. If, instead, they stored the features in a feature store, Data Scientists could iterate faster on data and improve their time-to-value._\n#### On-Demand Transformations as Functions, not Microservices\nOn-demand transformations are typically implemented as functions in online inference pipelines. A previous generation of feature stores implemented on-demand transformations as microservices (or serverless functions) that are invoked from online inference pipelines. The problem with this approach, however, is that for every new on-demand feature you add to your online model, you get large increases in latency due to straggler effects and the tail-at-scale from network calls. They are also massively inefficient in batch pipelines for backfilling with historical data. On-demand features as functions, in contrast, use the same programming language as the model was trained in (typically Python). In Python-based feature pipelines and online inference pipelines, you can implement the on-demand transformations as Python UDFs (although they do not scale for backfilling) or [Pandas UDFs](https://www.hopsworks.ai/dictionary/pandas-udf) (that scale for backfilling, but add some latency to online inference).\n## Existing Feature Store support for the Data Transformation Taxonomy\nThe data transformation taxonomy for AI systems is most relevant for feature stores that all support the computation of features once, and their subsequent reuse in many models. Table 2 summarizes the current support of well-known feature stores for the taxonomy.\n[![Summary of the current support of well-known feature stores for the taxonomy.](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f9_6682a7c1b7dbdd45e3c42fea_table%25202_support%2520for%2520on-demand%2520features_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f9_6682a7c1b7dbdd45e3c42fea_table%25202_support%2520for%2520on-demand%2520features_lightbox.png)\n**_Table 2:_**_Support for the Data Transformation Taxonomy in leading Feature Stores. Only three feature stores support on-demand features. Only one feature supports the full taxonomy._\nFirstly, Hopsworks is the only feature store to support the full taxonomy, with open APIs for feature engineering, enabling support for a wide range of compute engines for model-independent transformations. Model-dependent transformations and on-demand transformations are supported as Pandas or Python user-defined functions (UDFs). \nIn Databricks, model-independent transformations are supported in PySpark and SQL, while Tecton provides a domain-specific language (DSL) for defining model-independent transformations that are transpiled into Spark, SQL, or Rift (their DuckDB engine) for execution. Both Databricks and Tecton support computing features using request-time parameters with Python UDFs. Tecton also supports Pandas UDFs.. These on-demand transformations are model-dependent transformations applied to request-time (and historical) parameters. Neither feature store supports model-independent on-demand transformations in feature pipelines to precompute feature data for the feature store. Model-dependent transformations are not explicitly supported, except as on-demand transformations. Neither of these feature stores has support for declarative model-dependent transformations for encoding a categorical/numerical feature (found in Hopsworks). \nThe other feature stores - AWS Sagemaker, GCP Vertex, and Snowflake - only support model-independent transformations, mostly with SQL and some Python support. This makes it challenging to build real-time AI systems that require on-demand transformations.\n### Preprocessing Pipelines and Model-Dependent Transformations\nIt is possible to implement your own model-dependent transformations by tightly coupling them with your model, for example, using Scikit-Learn pipelines ([as shown here in Hopsworks lending club tutorial](https://github.com/logicalclocks/hopsworks-tutorials/tree/master/loan_approval)). A Scikit-Learn pipeline can be designed to contain a series of model-dependent transformation steps before either model.fit() or model.predict() is invoked as part of the pipeline. If you save and package your Scikit-Learn pipeline along with your versioned model in your [model registry](https://www.hopsworks.ai/dictionary/model-registry) ([see example training pipeline](https://github.com/logicalclocks/hopsworks-tutorials/blob/master/loan_approval/2-loan-approval-training-pipeline.ipynb)), then in your [inference pipeline](https://github.com/logicalclocks/hopsworks-tutorials/blob/master/loan_approval/3-loan-approval-batch-inference.ipynb) when you download the versioned model, you get exactly the same pipeline object (and model-dependent transformations). Similarly, TensorFlow enables you to perform a limited number of model-dependent transformations in pre-processing layers for the model. In PyTorch, the [transforms API](https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html) is often used for model-dependent transformations.\nOne disadvantage of preprocessing pipelines is that they consume CPU cycles and may cause under utilization of GPUs in model training or inference. If your model-dependent transformations are too CPU-intensive, it may not be possible to run your GPUs at maximum capacity. An alternative is to introduce a training dataset creation pipeline that creates training data as files, after applying model-dependent transformation functions. This is possible in Hopsworks with [feature views](https://www.hopsworks.ai/dictionary/feature-view).\n## Hopsworks and the Data Transformation Taxonomy\nIn Hopsworks, an AI system is typically decomposed into different AI pipelines that fall into one of the following categories:\n  * feature pipelines that perform model-independent transformations (and on-demand transformations) to transform raw data into features and labels/observations,\n  * training pipelines that can perform model-dependent transformations on features (and labels) before they are used to train one or more ML models,\n  * Inference pipelines that can perform on-demand transformations using request-time parameters, read [precomputed features](http://www.hopsworks.ai/dictionary/precomputed-features) from the feature store and perform model-dependent transformations on them, and then output predictions using the encoded feature data and trained model.\n\n\nEach of these AI pipelines has a different role in transforming data so that it gets progressively closer to the input data used for model training and inference. Another sub-pipeline of the training pipeline is the training dataset pipeline that reads features (and labels) from the feature store, applies model-dependent transformations and outputs training data as files. Training dataset pipelines are important when training data is large, and needs to be streamed into workers, and when model-dependent transformations are expensive and can be applied before the model training pipeline.\nHopsworks stores feature data in [feature groups](https://www.hopsworks.ai/dictionary/feature-groups) (tables containing feature data in an [offline store](https://www.hopsworks.ai/dictionary/offline-store) and an [online store](https://www.hopsworks.ai/dictionary/online-store)). Feature data is read for both training and inference, however, using a [feature view](https://www.hopsworks.ai/dictionary/feature-view), not using feature groups directly. A feature view is a meta-data only selection of features (from potentially different feature groups) that include the input and output [schema](https://www.hopsworks.ai/dictionary/schema) for a model. That is, the feature view describes the input features, the output target(s) as well as any helper columns used for training or inference. But a feature view is not only a schema, it can also include model-dependent transformations. Transformations are included in feature views as their primary goal is to prevent skew between training and inference pipelines - whether that is the model schema or model-dependent transformations. \nFeature views are used to create consistent snapshots of data for both training and inference. The feature view also computes and saves statistics for the training datasets it creates, and these statistics are made available as parameters for many model-dependent transformations (like categorical encoding, normalization, scaling) in both training and inference, see Figure 9. \n[![Feature views are used to create consistent snapshots of data for both training and inference. ](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b20e_6682a8f6264c5acc4e566595_9_full%2520overview%2520transformations_lightbox.png)](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b20e_6682a8f6264c5acc4e566595_9_full%2520overview%2520transformations_lightbox.png)\n**_Figure 9:_**_In Hopsworks, feature pipelines execute model-independent transformations, and can execute on-demand transformations on backfill data. Training pipelines and inference pipelines execute model-dependent transformations, and they must be consistent, to avoid training-serving skew. Online inference pipelines execute on-demand transformations, and they should be consistent with on-demand transformations in feature pipelines. On-demand and model-dependent transformations can be registered with feature groups and feature views in the feature store, respectively, to ensure the same transformations are performed in both AI pipelines._\nIn Figure 9, we can also see that on-demand transformations may need to be kept consistent between online inference pipelines and feature pipelines. We use on-demand transformations in feature pipelines to [backfill feature](https://www.hopsworks.ai/dictionary/backfill-features) data for training using historical data. In Hopsworks, you can register those on-demand features with [feature groups](https://www.hopsworks.ai/dictionary/feature-groups) and, through lineage, use exactly the same on-demand transformation in online inference.\nYou can define model-dependent transformations and on-demand transformations in Hopsworks as either Pandas or Python user-defined functions (UDFs). [Pandas UDFs](https://www.hopsworks.ai/dictionary/pandas-udf) enable the vectorized execution of the transformation functions, providing orders of magnitude higher throughput compared to [Python UDFs](https://www.hopsworks.ai/dictionary/python-udf). Pandas UDFs can also be scaled out in workers in a Spark program, enabling scaling from GBs to TBs or more. Here is an example of declarative model-dependent transformation function - one-hot encoding is applied to the _city_ feature in the _my_fv_ feature view:\n```\n#### Training Pipeline ########################\none_hot_encoder = fs.get_transformation_function(name=\"one_hot_encoder\",\n                         version=1)\nfv = fs.create_feature_view(name=\"my_fv\",\n         version=1,\n         query=fg.select(\"id\", \"amount\", \"age\", \"city\"),\n         transformation_functions=[one_hot_encoder(\"city\")],\n         labels=[\"amount\"])\n# one_hot_encoder is applied creating training data \nX_train, X_test, y_train, y_test = fv.train_test_split(test_size=0.2)\n#### Batch Inference Pipeline #################\n# one_hot_encoder is applied on-reading batch inference data \ndf = fv.get_batch_data(start_time=\"2024-06-28 00:00\")\n#### Online Inference Pipeline ############\n\n# one_hot_encoder is applied on-reading online inference data \nrow = fv.get_feature_vector(entity={'id':1234})\n\n```\n\nFor on-demand features, you implement the same Pandas/Python UDF, one for each on-demand feature:\n```\n# Define on-demand transformation function\n@hopsworks.udf(return_type=float)\ndef on_demand_feature(feature, request_parameter):\n   import packages\n   ....\n   return df\n...\n##### Feature Pipeline ########################\nfg = fs.create_feature_group(name=\"my_fg\", \n            version=1,\n            primary_key=[\"id\"],\n            event_time=\"evt_ts\",\n            transformation_functions=[on_demand_feature],\n            online_enabled = True)\n# `on_demand_feature` is computed with columns in `df` before insertion \nfg.insert(df)\n\n##### Online Inference Pipeline ###############\ndef prediction_request(id, request_parameter):\n   # Get feature vector without any transformations\n   df = fv.get_feature_vector(entity={\"id\":id}, transform=False, return_type=\"pandas\")\n   # Apply on-demand transformation function \n   df['on_demand_feature'] = fv.on_demand_transformations[\"on_demand_feature\"](df['feature'], request_parameter)\n   # Apply model-dependent transformation functions\n   df_encoded = fv.transform(df\n   df['prediction'] = model.predict(df_encoded)\n   fv.log(df)\n   return df['prediction']\n\n```\n\n## Summary\nIf you intend to reuse feature data in many models, you need to first understand the data transformation taxonomy, so that you know what data transformations to put in your different AI pipelines. Feature stores can help by providing infrastructure support for the data transformation taxonomy, but currently only Hopsworks Feature Store supports the complete taxonomy.\n## References\n![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/663b8c6a964c76be96237444_written%20by%20human_hops.png)![](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/663b8ae5a0a33abc94baf561_written%20by%20ai_hops.png)\n### Interested for more?\n  * 🤖 Register for free on [Hopsworks Serverless](https://app.hopsworks.ai/app?utm_source=blog&utm_medium=list&utm_id=backlink)\n  * 🌐 Read about the open, disaggregated [AI Lakehouse stack](https://www.hopsworks.ai/post/the-ai-lakehouse)\n  * 📚 Get your early copy: O'Reilly's ['**Building Machine Learning Systems'**](https://www.hopsworks.ai/lp/oreilly-book-building-ml-systems-with-a-feature-store)book\n  * 🛠️ Explore all [Hopsworks Integrations](https://www.hopsworks.ai/integrations)\n  * 🧩 Get started with [codes and examples](https://www.hopsworks.ai/hopsworks-examples)\n  * ⚖️ [Compare other Feature Stores](https://www.hopsworks.ai/product-comparison/sagemaker) with Hopsworks\n\n\n### More blogs\n[![Hopsworks new feature service, ArrowFlight with DuckDB, introduces significant performance improvements for Python-clients working with feature data.](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/65113a725a93dc40f6d74c85_duckdb_thumbnail.png)](https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb)[Feature StoreAugust 9, 202313 minReadFaster reading from the Lakehouse to Python with DuckDB/ArrowFlightIn this article, we outline how we leveraged ArrowFlight with DuckDB to build a new service that massively improves the performance of Python clients reading from lakehouse data in the Feature Store](https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb)\nTill Döhmen\n[![ML and AI applications are becoming increasingly demanding in terms of performance, we compare Redis to RonDB in terms of Scalability, Throughput and H.A.](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/61eace23ecf46e36f195d5d1_REDIS.png)](https://www.hopsworks.ai/post/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it)[BenchmarkFebruary 26, 202112 minReadAI/ML needs a Key-Value store, and Redis is not up to itSeeing how Redis is a popular open-source feature store with features significantly similar to RonDB, we compared the innards of RonDB’s multithreading architecture to the commercial Redis products. ](https://www.hopsworks.ai/post/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it)\nMikael Ronström\n[![This article explores the limitations of existing feature stores that only support Star Schema data models and introduces the Snowflake Schema data model.](https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66869f1f4f75a7d91c67775f_PR%20Blog%203_snowflake%20schema.png)](https://www.hopsworks.ai/post/the-journey-from-star-schema-to-snowflake-schema-in-the-feature-store)[Feature StoreJuly 8, 202414 minReadThe Journey from Star Schema to Snowflake Schema in the Feature StoreIn this article we introduce the snowflake schema data model for feature stores, and show how it helps you include more features to make better predictions ](https://www.hopsworks.ai/post/the-journey-from-star-schema-to-snowflake-schema-in-the-feature-store)\nDavit Bzhalava\n[![Untitled UI logotext](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/630e3413d3fafa0f79c52da2_hopsworks-logo%202022_white.svg)![Logo](https://cdn.prod.website-files.com/5f6353590bb01cacbcecfbac/666c3cc1cfc4741e6b2d9fe6_untitled-ui-logo.png)The AI Lakehouse](https://www.hopsworks.ai/)\nProduct\n[Hopsworks Enterprise](https://www.hopsworks.ai/try)[Capabilities](https://www.hopsworks.ai/product-capabilities)[Integrations](https://www.hopsworks.ai/integrations)[Examples](https://www.hopsworks.ai/hopsworks-examples)[Pricing](https://www.hopsworks.ai/pricing)[App Status](https://hopsworks.statuspage.io/)[FAQ](https://www.hopsworks.ai/frequently-asked-questions)\nSolutions\n[Industry & Team Solutions](https://www.hopsworks.ai/solutions/all)[Generative AI](https://www.hopsworks.ai/use-case/fine-tuning-llms-rag-for-genai)[Real-time Fraud Detection ](https://www.hopsworks.ai/use-case/realtime-fraud-detection)[Hopsworks Medical Copilot](https://www.hopscopilot.com/)[Customers](https://www.hopsworks.ai/customers)\nResources\n[Blog](https://www.hopsworks.ai/blog)[MLOps Dictionary](https://www.hopsworks.ai/mlops-dictionary)[Events](https://www.hopsworks.ai/events)[Documentation](https://docs.hopsworks.ai/latest/)[Academy](https://www.hopsworks.ai/academy)[Research Papers](https://www.hopsworks.ai/research-papers)[Feature Store Comparison](https://www.hopsworks.ai/product-comparison/sagemaker)[Community](https://community.hopsworks.ai/)[FAQ: EU AI Act](https://www.hopsworks.ai/faq-eu-ai-act)\nCompany\n[About Us](https://www.hopsworks.ai/about-us)[News](https://www.hopsworks.ai/news)[Security & Compliance](https://www.hopsworks.ai/security-compliance)[Contact Us](https://www.hopsworks.ai/contact/main)\nJoin our newsletter\n**Receive the latest product updates, upcoming events, and industry news.**\n© Hopsworks 2025. All rights reserved. Various trademarks held by their respective owners.\n[](https://join.slack.com/t/public-hopsworks/shared_invite/zt-1uf21vitz-rhHKNdIf8GEiOf1EJ6Wzsw)[](https://github.com/logicalclocks/hopsworks)[](https://www.linkedin.com/company/hopsworks/)[](https://twitter.com/hopsworks)[](https://www.youtube.com/@hopsworks)\n[Privacy Policy](https://www.iubenda.com/privacy-policy/90800199 \"Privacy Policy \")\n[Cookie Policy](https://www.iubenda.com/privacy-policy/90800199/cookie-policy \"Cookie Policy \")\n[Terms and Conditions](https://www.iubenda.com/terms-and-conditions/90800199 \"Terms and Conditions \")\n",
    "content_quality_score": 0.5,
    "summary": null,
    "child_urls": [
        "https://www.hopsworks.ai/news/hopsworks-4-0-breaking-changes",
        "https://www.hopsworks.ai/contact/main",
        "https://app.hopsworks.ai",
        "https://www.hopsworks.ai/",
        "https://www.hopsworks.ai/try",
        "https://www.hopsworks.ai/integrations",
        "https://www.hopsworks.ai/hopsworks-examples",
        "https://www.hopsworks.ai/frequently-asked-questions",
        "https://www.hopsworks.ai/product-capabilities/feature-store-on-premises",
        "https://www.hopsworks.ai/product-capabilities/operational-performance-and-high-availability",
        "https://www.hopsworks.ai/product-capabilities/feature-engineering-in-python",
        "https://www.hopsworks.ai/product-capabilities",
        "https://www.hopsworks.ai/solutions/teams",
        "https://www.hopsworks.ai/solutions/teams?tab=ml-engineers",
        "https://www.hopsworks.ai/solutions/teams?tab=data-engineers",
        "https://www.hopsworks.ai/solutions/teams?tab=data-scientists",
        "https://www.hopsworks.ai/solutions/teams?tab=devops",
        "https://www.hopsworks.ai/solutions/teams?tab=architects",
        "https://www.hopsworks.ai/solutions/teams?tab=non-technical",
        "https://www.hopsworks.ai/solutions/industry/defense-and-law-enforcement",
        "https://www.hopsworks.ai/solutions/industry/fsi",
        "https://www.hopsworks.ai/solutions/industry/online-retail-and-e-commerce",
        "https://www.hopsworks.ai/solutions/industry/public-sector",
        "https://www.hopsworks.ai/solutions/industry/research-and-healthcare",
        "https://www.hopsworks.ai/solutions/industry/i-gaming",
        "https://www.hopsworks.ai/solutions/all",
        "https://www.hopsworks.ai/use-case/fine-tuning-llms-rag-for-genai",
        "https://www.hopsworks.ai/use-case/realtime-fraud-detection",
        "https://www.hopsworks.ai/customers",
        "https://www.hopsworks.ai/pricing",
        "https://www.hopsworks.ai/blog",
        "https://www.hopsworks.ai/mlops-dictionary",
        "https://docs.hopsworks.ai/latest/",
        "https://www.hopsworks.ai/research-papers",
        "https://community.hopsworks.ai/",
        "https://www.hopsworks.ai/events",
        "https://www.hopsworks.ai/academy",
        "https://www.hopsworks.ai/product-comparison/sagemaker",
        "https://www.hopsworks.ai/faq-eu-ai-act",
        "https://www.hopsworks.ai/about-us",
        "https://www.hopsworks.ai/news",
        "https://www.hopsworks.ai/security-compliance",
        "https://www.hopsworks.ai/lp/oreilly-book-building-ml-systems-with-a-feature-store",
        "https://www.hopsworks.ai/index#performance",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/",
        "https://www.hopsworks.ai/post/migrating-from-aws-to-a-european-cloud-how-we-cut-costs-by-62",
        "https://www.hopsworks.ai/post/the-10-fallacies-of-mlops",
        "https://www.hopsworks.ai/post/hopsworks-ai-lakehouse-the-power-of-integrated-mlops-components",
        "https://www.hopsworks.ai/post/the-power-of-ai-in-government",
        "https://www.hopsworks.ai/post/optimizing-ai-costs",
        "https://www.hopsworks.ai/blog-categories/mlops",
        "https://www.hopsworks.ai/blog-categories/data-engineering",
        "https://www.hopsworks.ai/blog-categories/sigmod-2024",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#introduction",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#data-transformation",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#dependent-transformations",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#independent-transformations",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#ondemand-transformations",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#with-feature",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#as-functions",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#existing-support",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#pre-processed",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#hops-taxonomy",
        "https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems/#summary",
        "https://www.hopsworks.ai/research-papers/the-hopsworks-feature-store-for-machine-learning",
        "https://www.hopsworks.ai/post/modularity-and-composability-for-ai-systems-with-ai-pipelines-and-shared-storage",
        "https://www.hopsworks.ai/post/the-journey-from-star-schema-to-snowflake-schema-in-the-feature-store",
        "https://www.hopsworks.ai/post/the-feature-store-makes-your-data-warehouse-easy-to-use-for-ai",
        "https://www.hopsworks.ai/post/from-lakehouse-to-ai-lakehouse-with-a-python-native-query-engine",
        "https://www.hopsworks.ai/post/rondb-a-real-time-database-for-real-time-ai-systems",
        "http://www.hopsworks.ai/post/reproducible-data-for-the-ai-lakehouse",
        "https://www.hopsworks.ai/dictionary/ml",
        "https://www.hopsworks.ai/dictionary/feature-data",
        "https://www.hopsworks.ai/dictionary/feature",
        "https://www.hopsworks.ai/dictionary/data-warehouse",
        "https://www.hopsworks.ai/dictionary/feature-reuse",
        "https://www.hopsworks.ai/dictionary/feature-store",
        "https://www.hopsworks.ai/dictionary/data-transformation",
        "https://www.hopsworks.ai/dictionary/feature-pipeline",
        "https://www.hopsworks.ai/dictionary/data-pipelines",
        "https://www.hopsworks.ai/dictionary/encoding-for-features",
        "https://www.hopsworks.ai/dictionary/filtering",
        "http://www.hopsworks.ai/dictionary/model-performance",
        "https://www.hopsworks.ai/dictionary/model-dependent-transformations",
        "https://www.hopsworks.ai/dictionary/transformation",
        "https://www.hopsworks.ai/dictionary/llms-large-language-models",
        "https://www.hopsworks.ai/dictionary/training-data",
        "http://www.hopsworks.ai/dictionary/model-training",
        "https://www.hopsworks.ai/dictionary/model-independent-transformations",
        "https://www.hopsworks.ai/dictionary/skew",
        "https://www.hopsworks.ai/dictionary/online-inference-pipeline",
        "https://www.hopsworks.ai/dictionary/instruction-datasets-for-fine-tuning-llms",
        "http://www.hopsworks.ai/dictionary/fine-tuning-llms",
        "https://www.hopsworks.ai/dictionary/feature-engineering",
        "https://www.hopsworks.ai/dictionary/streaming-feature-pipeline",
        "https://www.hopsworks.ai/dictionary/downstream",
        "https://www.hopsworks.ai/dictionary/on-demand-features",
        "https://www.hopsworks.ai/dictionary/feature-function",
        "https://www.hopsworks.ai/dictionary/backfill-training-data",
        "https://www.hopsworks.ai/dictionary/on-demand-transformation",
        "https://www.hopsworks.ai/dictionary/training-pipeline",
        "https://www.hopsworks.ai/dictionary/pandas-udf",
        "https://www.hopsworks.ai/dictionary/model-registry",
        "https://www.hopsworks.ai/dictionary/feature-view",
        "http://www.hopsworks.ai/dictionary/precomputed-features",
        "https://www.hopsworks.ai/dictionary/feature-groups",
        "https://www.hopsworks.ai/dictionary/offline-store",
        "https://www.hopsworks.ai/dictionary/online-store",
        "https://www.hopsworks.ai/dictionary/schema",
        "https://www.hopsworks.ai/dictionary/backfill-features",
        "https://www.hopsworks.ai/dictionary/python-udf",
        "https://app.hopsworks.ai/app?utm_source=blog&utm_medium=list&utm_id=backlink",
        "https://www.hopsworks.ai/post/the-ai-lakehouse",
        "https://www.hopsworks.ai/post/python-centric-feature-service-with-arrowflight-and-duckdb",
        "https://www.hopsworks.ai/post/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it",
        "https://join.slack.com/t/public-hopsworks/shared_invite/zt-1uf21vitz-rhHKNdIf8GEiOf1EJ6Wzsw",
        "https://github.com/logicalclocks/hopsworks",
        "https://www.linkedin.com/company/hopsworks/",
        "https://twitter.com/hopsworks",
        "https://www.hopscopilot.com/",
        "https://www.linkedin.com/in/jim-dowling-206a98/",
        "https://twitter.com/share?url=https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems",
        "https://www.linkedin.com/shareArticle?mini=true&url=https://www.hopsworks.ai/post/a-taxonomy-for-data-transformations-in-ai-systems&title=The Taxonomy for Data Transformations in AI Systems - Hopsworks",
        "https://stackoverflow.com/questions/75079929/storing-encoded-features-in-the-feature-store",
        "https://www.youtube.com/watch?v=BD1UOJs1Bvo&t=2426s",
        "https://dl.acm.org/doi/10.1145/3534678.3539059",
        "https://cta-service-cms2.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLL8aIV1Q%2B5ZSUfYLKLxVSlUlPku38D2BJ0CuYkCy8h9lgh0Gpu2ooFCOgz6zRefuhkCC2mLJaJwbuiEs%2FTQ9njgFDF%2BXLvsMd8DRQ2UekbP5wohn10%2FrMWjt8DWViwIwazinBqy%2BcAZ0lv%2BfqgKTFoSbOJh4rMKpeEhYyeL%2Bjb%2BuZMeqcWmPtJIy0raFSsndm1lSEE%3D&webInteractiveContentId=176024224097&portalId=5524414",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b21b_6682a338ded3a8e40a72b19b_1_data%2520transformation%2520taxonomy_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1df_6682a394decfc5b65e08b199_Table%25201_transformation%2520comparison_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1fc_6682a382967f6efdcc6da5e9_2_3%2520groups%2520of%2520data%2520transformations_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f0_6682a5285f675e07f640d48b_3_3%2520types%2520of%2520transformations_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e9_6682a59661617e47e531a5ff_4_on-demand%2520transformations_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1ec_6683b87de8bcaaf0a96dc544_v2_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f3_6682a64bf17f7395ff901934_6_real%2520time%2520ai%2520systems_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1e3_6682a6838dd9a33c10e159c3_7_event%2520sourcing%2520pattern_lightbox.png",
        "https://cta-service-cms2.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLKqezz9RftCB8ctXyqqlNDjMtJOTRyq%2Fp99txGDgWWoYNFsozaC3wZyD4Oo%2B5cjVs9eqtTCAi%2FnFOL4iBrm3V%2BJEmBKxoIKlHSZ%2B%2FImF1ZMW615qSSuiagfvpQHMmN22urTwQreKeJCnmc7aA5vmtWs37EceSIAudMZH3l%2FwlbReFkxxwl5urF4MsgbQwpOoLY%3D&webInteractiveContentId=177758961194&portalId=5524414",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b203_6682a73911329cf4cf20a985_8_architecture%2520without%2520feature%2520store_lightbox.png",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b1f9_6682a7c1b7dbdd45e3c42fea_table%25202_support%2520for%2520on-demand%2520features_lightbox.png",
        "https://github.com/logicalclocks/hopsworks-tutorials/tree/master/loan_approval",
        "https://github.com/logicalclocks/hopsworks-tutorials/blob/master/loan_approval/2-loan-approval-training-pipeline.ipynb",
        "https://github.com/logicalclocks/hopsworks-tutorials/blob/master/loan_approval/3-loan-approval-batch-inference.ipynb",
        "https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html",
        "https://cdn.prod.website-files.com/618399cd49d125734c8dec95/66b08da3ff1e129fac59b20e_6682a8f6264c5acc4e566595_9_full%2520overview%2520transformations_lightbox.png",
        "https://hopsworks.statuspage.io/",
        "https://www.youtube.com/@hopsworks",
        "https://www.iubenda.com/privacy-policy/90800199",
        "https://www.iubenda.com/privacy-policy/90800199/cookie-policy",
        "https://www.iubenda.com/terms-and-conditions/90800199"
    ]
}