{
    "id": "5aab3355f23450acc40ec5eefda076ba",
    "metadata": {
        "id": "5aab3355f23450acc40ec5eefda076ba",
        "url": "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/",
        "title": "Advanced Retrieval-Augmented Generation: From Theory to LlamaIndex Implementation | Towards Data Science",
        "properties": {
            "description": null,
            "keywords": null,
            "author": "Leonie Monigatti",
            "og:locale": "en_US",
            "og:type": "article",
            "og:title": "Advanced Retrieval-Augmented Generation: From Theory to LlamaIndex Implementation | Towards Data Science",
            "og:description": "How to address limitations of naive RAG pipelines by implementing targeted advanced RAG techniques in Python",
            "og:url": "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/",
            "og:site_name": "Towards Data Science",
            "og:image": "https://towardsdatascience.com/wp-content/uploads/2024/02/18z-QRadKewNmos0J_4TNAQ.png",
            "og:image:width": "3318",
            "og:image:height": "1866",
            "og:image:type": "image/png",
            "twitter:card": "summary_large_image",
            "twitter:creator": "@TDataScience",
            "twitter:site": "@TDataScience",
            "twitter:label1": "Written by",
            "twitter:data1": "Leonie Monigatti",
            "twitter:label2": "Est. reading time",
            "twitter:data2": "11 minutes"
        }
    },
    "parent_metadata": {
        "id": "3c656c86d22b6ceecae909b2aed5b80b",
        "url": "https://www.notion.so/RAG-3c656c86d22b6ceecae909b2aed5b80b",
        "title": "RAG",
        "properties": {
            "Type": [
                "Leaf"
            ]
        }
    },
    "content": "[Skip to content](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#wp--skip-link--target)\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\nThe world’s leading publication for data science, AI, and ML professionals.\nSign in\nSign out\n[Contributor Portal](https://contributor.insightmediagroup.io/)\n  * [Latest](https://towardsdatascience.com/latest/)\n  * [Editor’s Picks](https://towardsdatascience.com/tag/editors-pick/)\n  * [Deep Dives](https://towardsdatascience.com/tag/deep-dives/)\n  * [Contribute](https://towardsdatascience.com/questions-96667b06af5/)\n  * [Newsletter](https://newsletter.towardsdatascience.com/subscription-to-the-newsletter)\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\n\n\nToggle Mobile Navigation\n  * [LinkedIn](https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca)\n  * [X](https://x.com/TDataScience)\n\n\nToggle Search\nSearch\n[ Artificial Intelligence ](https://towardsdatascience.com/category/artificial-intelligence/)\n# Advanced Retrieval-Augmented Generation: From Theory to LlamaIndex Implementation\nHow to address limitations of naive RAG pipelines by implementing targeted advanced RAG techniques in Python \n[Leonie Monigatti](https://towardsdatascience.com/author/iamleonie/)\nFeb 19, 2024\n10 min read\nShare \n![Difference between Naive and Advanced RAG \\(Image by the author, inspired by \\[1\\]\\)](https://towardsdatascience.com/wp-content/uploads/2024/02/18z-QRadKewNmos0J_4TNAQ.png)Difference between Naive and Advanced RAG (Image by the author, inspired by [1])\nA recent survey on [Retrieval-Augmented Generation (RAG)](https://medium.com/towards-data-science/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2) [1] summarized three recently evolved paradigms:\n  * Naive RAG,\n  * advanced RAG, and\n  * modular RAG.\n\n\nThe advanced RAG paradigm comprises of a set of techniques targeted at addressing known limitations of naive RAG. This article first discusses these techniques, which can be categorized into _pre-retrieval, retrieval, and post-retrieval optimizations_.\nIn the second half, you will learn how to implement a naive RAG pipeline using [Llamaindex](https://www.llamaindex.ai/) in Python, which will then be enhanced to an advanced RAG pipeline with a selection of the following advanced RAG techniques:\n  * [Pre-retrieval optimization: Sentence window retrieval](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c968)\n  * [Retrieval optimization: Hybrid search](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#3275)\n  * [Post-retrieval optimization: Re-ranking](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c1e2)\n\n\nThis article focuses on the **advanced RAG paradigm** and its implementation. If you are unfamiliar with the fundamentals of RAG, you can catch up on it here:\n> [**Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation**](https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2)\n## What is Advanced RAG\nWith the recent advancements in the RAG domain, advanced RAG has evolved as a new paradigm with targeted enhancements to address some of the limitations of the naive RAG paradigm. As summarized in a recent survey [1], advanced RAG techniques can be categorized into pre-retrieval, retrieval, and post-retrieval optimizations.\n![Difference between Naive and Advanced RAG \\(Image by the author, inspired by \\[1\\]\\)](https://towardsdatascience.com/wp-content/uploads/2024/02/16bTQeYn9814yAgLor2EFrQ.png)Difference between Naive and Advanced RAG (Image by the author, inspired by [1])\n## Pre-retrieval optimization\nPre-retrieval optimizations focus on data indexing optimizations as well as query optimizations. Data indexing optimization techniques aim to store the data in a way that helps you improve retrieval efficiency, such as [1]:\n  * **Sliding window** uses an overlap between chunks and is one of the simplest techniques.\n  * **Enhancing data granularity** applies data cleaning techniques, such as removing irrelevant information, confirming factual accuracy, updating outdated information, etc.\n  * **Adding metadata** , such as dates, purposes, or chapters, for filtering purposes.\n  * **Optimizing index structures** involves different strategies to index data, such as adjusting the chunk sizes or using multi-indexing strategies. One technique we will implement in this article is sentence window retrieval, which embeds single sentences for retrieval and replaces them with a larger text window at inference time.\n\n![Sentence window retrieval](https://towardsdatascience.com/wp-content/uploads/2024/02/1pbU5KBqYWhx0GOeNRMiPoA.png)Sentence window retrieval\nAdditionally, pre-retrieval techniques aren’t limited to data indexing and can cover **techniques at inference time** , such as query routing, query rewriting, and query expansion.\n## Retrieval optimization\nThe retrieval stage aims to identify the most relevant context. Usually, the retrieval is based on vector search, which calculates the semantic similarity between the query and the indexed data. Thus, the majority of retrieval optimization techniques revolve around the embedding models [1]:\n  * **Fine-tuning embedding models** customizes embedding models to domain-specific contexts, especially for domains with evolving or rare terms. For example, `BAAI/bge-small-en` is a high-performance embedding model that can be fine-tuned (see[ Fine-tuning guide](https://betterprogramming.pub/fine-tuning-your-embedding-model-to-maximize-relevance-retrieval-in-rag-pipeline-2ea3fa231149))\n  * **Dynamic Embedding** adapts to the context in which words are used, unlike static embedding, which uses a single vector for each word. For example, OpenAI’s `embeddings-ada-02` is a sophisticated dynamic embedding model that captures contextual understanding. [1]\n\n\nThere are also other retrieval techniques besides vector search, such as hybrid search, which often refers to the concept of combining vector search with keyword-based search. This retrieval technique is beneficial if your retrieval requires exact keyword matches.\n> [**Improving Retrieval Performance in RAG Pipelines with Hybrid Search**](https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5)\n## Post-retrieval optimization\nAdditional processing of the retrieved context can help address issues such as exceeding the context window limit or introducing noise, thus hindering the focus on crucial information. Post-retrieval optimization techniques summarized in the RAG survey [1] are:\n  * **Prompt compression** reduces the overall prompt length by removing irrelevant and highlighting important context.\n  * **Re-ranking** uses [Machine Learning](https://towardsdatascience.com/tag/machine-learning/ \"Machine Learning\") models to recalculate the relevance scores of the retrieved contexts.\n\n![Re-ranking](https://towardsdatascience.com/wp-content/uploads/2024/02/1owudWLuoXhqeLjStCsnDiw.png)Re-ranking\nFor additional ideas on how to improve the performance of your RAG pipeline to make it production-ready, continue reading here:\n> [**A Guide on 12 Tuning Strategies for Production-Ready RAG Applications**](https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439)\n## Prerequisites\nThis section discusses the required packages and API keys to follow along in this article.\n### Required Packages\nThis article will guide you through implementing a naive and an advanced RAG pipeline using [LlamaIndex](https://www.llamaindex.ai/) in Python.\n```\npip install llama-index\n```\n\nIn this article, we will be using LlamaIndex `v0.10`. If you are upgrading from an older LlamaIndex version, you need to run the following commands to install and run LlamaIndex properly:\n```\npip uninstall llama-index\npip install llama-index --upgrade --no-cache-dir --force-reinstall\n```\n\nLlamaIndex offers an option to store vector embeddings locally in JSON files for persistent storage, which is great for quickly prototyping an idea. However, we will use a vector database for persistent storage since advanced RAG techniques aim for production-ready applications.\nSince we will need metadata storage and hybrid search capabilities in addition to storing the vector embeddings, we will use the open source vector database [Weaviate](http://weaviate.io) (`v3.26.2`), which supports these features.\n```\npip install weaviate-client llama-index-vector-stores-weaviate\n```\n\n### API Keys\nWe will be using Weaviate embedded, which you can use for free without registering for an API key. However, this tutorial uses an embedding model and LLM from [OpenAI](https://openai.com/), for which you will need an OpenAI API key. To obtain one, you need an OpenAI account and then \"Create new secret key\" under [API keys](https://platform.openai.com/account/api-keys).\nNext, create a local `.env` file in your root directory and define your API keys in it:\n```\nOPENAI_API_KEY=\"<YOUR_OPENAI_API_KEY>\"\n```\n\nAfterwards, you can load your API keys with the following code:\n```\n# !pip install python-dotenv\nimport os\nfrom dotenv import load_dotenv,find_dotenv\nload_dotenv(find_dotenv())\n```\n\n## Implementing Naive RAG with LlamaIndex\nThis section discusses how to implement a naive RAG pipeline using LlamaIndex. You can find the entire naive RAG pipeline in this [Jupyter Notebook](https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/naive_rag.ipynb). For the implementation using LangChain, you can continue in [this article (naive RAG pipeline using LangChain](https://medium.com/towards-data-science/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2)).\n### Step 1: Define the embedding model and LLM\nFirst, you can define an embedding model and LLM in a global settings object. Doing this means you don’t have to specify the models explicitly in the code again.\n  * Embedding model: used to generate vector embeddings for the document chunks and the query.\n  * LLM: used to generate an answer based on the user query and the relevant context.\n\n```\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core.settings import Settings\nSettings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\nSettings.embed_model = OpenAIEmbedding()\n```\n\n### Step 2: Load data\nNext, you will create a local directory named `data` in your root directory and download some example data from the [LlamaIndex GitHub repository](https://github.com/run-llama/llama_index) (MIT license).\n```\n!mkdir -p 'data'\n!wget '<https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt>' -O 'data/paul_graham_essay.txt'\n```\n\nAfterward, you can load the data for further processing:\n```\nfrom llama_index.core import SimpleDirectoryReader\n# Load data\ndocuments = SimpleDirectoryReader(\n    input_files=[\"./data/paul_graham_essay.txt\"]\n).load_data()\n```\n\n### Step 3: Chunk documents into nodes\nAs the entire document is too large to fit into the context window of the LLM, you will need to partition it into smaller text chunks, which are called `Nodes` in LlamaIndex. You can parse the loaded documents into nodes using the `SimpleNodeParser` with a defined chunk size of 1024.\n```\nfrom llama_index.core.node_parser import SimpleNodeParser\nnode_parser = SimpleNodeParser.from_defaults(chunk_size=1024)\n# Extract nodes from documents\nnodes = node_parser.get_nodes_from_documents(documents)\n```\n\n### Step 4: Build index\nNext, you will build the index that stores all the external knowledge in [Weaviate](https://weaviate.io/), an open source vector database.\nFirst, you will need to connect to a Weaviate instance. In this case, we’re using [Weaviate Embedded](https://weaviate.io/developers/weaviate/installation/embedded), which allows you to experiment in Notebooks for free without an API key. For a production-ready solution, deploying Weaviate yourself, e.g., [via Docker](https://weaviate.io/developers/weaviate/installation/docker-compose) or utilizing a [managed service](https://weaviate.io/developers/weaviate/installation/weaviate-cloud-services), is recommended.\n```\nimport weaviate\n# Connect to your Weaviate instance\nclient = weaviate.Client(\n  embedded_options=weaviate.embedded.EmbeddedOptions(), \n)\n```\n\nNext, you will build a `VectorStoreIndex` from the Weaviate client to store your data in and interact with.\n```\nfrom llama_index.core import VectorStoreIndex, StorageContext\nfrom llama_index.vector_stores.weaviate import WeaviateVectorStore\nindex_name = \"MyExternalContext\"\n# Construct vector store\nvector_store = WeaviateVectorStore(\n  weaviate_client = client, \n  index_name = index_name\n)\n# Set up the storage for the embeddings\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n# Setup the index\n# build VectorStoreIndex that takes care of chunking documents\n# and encoding chunks to embeddings for future retrieval\nindex = VectorStoreIndex(\n  nodes,\n  storage_context = storage_context,\n)\n```\n\n### Step 5: Setup query engine\nLastly, you will set up the index as the query engine.\n```\n# The QueryEngine class is equipped with the generator\n# and facilitates the retrieval and generation steps\nquery_engine = index.as_query_engine()\n```\n\n### Step 6: Run a naive RAG query on your data\nNow, you can run a naive RAG query on your data, as shown below:\n```\n# Run your naive RAG query\nresponse = query_engine.query(\n  \"What happened at Interleaf?\"\n)\n```\n\n## Implementing Advanced RAG with LlamaIndex\nIn this section, we will cover some simple adjustments you can make to turn the above naive RAG pipeline into an advanced one. This walkthrough will cover the following selection of advanced RAG techniques:\n  * [Pre-retrieval optimization: Sentence window retrieval](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c968)\n  * [Retrieval optimization: Hybrid search](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#3275)\n  * [Post-retrieval optimization: Re-ranking](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c1e2)\n\n\nAs we will only cover the modifications here, you can find the [full end-to-end advanced RAG pipeline in this Jupyter Notebook](https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/advanced_rag.ipynb).\n## Indexing optimization example: Sentence window retrieval\nFor the [sentence window retrieval technique](https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo.html), you need to make two adjustments: First, you must adjust how you store and post-process your data. Instead of the `SimpleNodeParser`, we will use the `SentenceWindowNodeParser`.\n```\nfrom llama_index.core.node_parser import SentenceWindowNodeParser\n# create the sentence window node parser w/ default settings\nnode_parser = SentenceWindowNodeParser.from_defaults(\n  window_size=3,\n  window_metadata_key=\"window\",\n  original_text_metadata_key=\"original_text\",\n)\n```\n\nThe `SentenceWindowNodeParser` does two things:\n  1. It separates the document into single sentences, which will be embedded.\n  2. For each sentence, it creates a context window. If you specify a `window_size = 3`, the resulting window will be three sentences long, starting at the previous sentence of the embedded sentence and spanning the sentence after. The window will be stored as metadata.\n\n\nDuring retrieval, the sentence that most closely matches the query is returned. After retrieval, you need to replace the sentence with the entire window from the metadata by defining a `MetadataReplacementPostProcessor` and using it in the list of `node_postprocessors`.\n```\nfrom llama_index.core.postprocessor import MetadataReplacementPostProcessor\n# The target key defaults to `window` to match the node_parser's default\npostproc = MetadataReplacementPostProcessor(\n  target_metadata_key=\"window\"\n)\n...\nquery_engine = index.as_query_engine( \n  node_postprocessors = [postproc],\n)\n```\n\n## Retrieval optimization example: Hybrid search\nImplementing a hybrid search in LlamaIndex is as easy as two parameter changes to the `query_engine` if the underlying vector database supports hybrid search queries. The `alpha` parameter specifies the weighting between vector search and keyword-based search, where `alpha=0` means keyword-based search and `alpha=1` means pure vector search.\n```\nquery_engine = index.as_query_engine(\n  ...,\n  vector_store_query_mode=\"hybrid\", \n  alpha=0.5,\n  ...\n)\n```\n\n## Post-retrieval optimization example: Re-ranking\nAdding a reranker to your advanced RAG pipeline only takes three simple steps:\n  1. First, define a reranker model. Here, we are using the `BAAI/bge-reranker-base`from Hugging Face.\n  2. In the query engine, add the reranker model to the list of `node_postprocessors`.\n  3. Increase the `similarity_top_k` in the query engine to retrieve more context passages, which can be reduced to `top_n` after reranking.\n\n```\n# !pip install torch sentence-transformers\nfrom llama_index.core.postprocessor import SentenceTransformerRerank\n# Define reranker model\nrerank = SentenceTransformerRerank(\n  top_n = 2, \n  model = \"BAAI/bge-reranker-base\"\n)\n...\n# Add reranker to query engine\nquery_engine = index.as_query_engine(\n    similarity_top_k = 6,\n    ...,\n        node_postprocessors = [rerank],\n    ...,\n)\n```\n\nThere are many more different techniques within the advanced RAG paradigm. If you are interested in further implementations, I recommend the following two resources:\n> [**Building and Evaluating Advanced RAG Applications**](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/)\n> [**Advanced RAG 01: Small-to-Big Retrieval**](https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4)\n## Summary\nThis article covered the concept of advanced RAG, which covers a set of techniques to address the limitations of the naive RAG paradigm. After an overview of advanced RAG techniques, which can be categorized into pre-retrieval, retrieval, and post-retrieval techniques, this article implemented a naive and advanced RAG pipeline using LlamaIndex for orchestration.\nThe RAG pipeline components were language models from [OpenAI](https://openai.com/), a reranker model from [BAAI](https://www.baai.ac.cn/english.html) hosted on [Hugging Face](https://huggingface.co/), and a [Weaviate](https://weaviate.io/) vector database.\nWe implemented the following selection of techniques using LlamaIndex in Python:\n  * [Pre-retrieval optimization: Sentence window retrieval](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c968)\n  * [Retrieval optimization: Hybrid search](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#3275)\n  * [Post-retrieval optimization: Re-ranking](https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c1e2)\n\n\nYou can find the Jupyter Notebooks containing the full end-to-end pipelines here:\n  * [Naive RAG in LlamaIndex](https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/naive_rag.ipynb)\n  * [Advanced RAG in LlamaIndex](https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/advanced_rag.ipynb)\n\n\n## Enjoyed This Story?\n_[Subscribe for free](https://medium.com/subscribe/@iamleonie) to get notified when I publish a new story._\n> [**Get an email whenever Leonie Monigatti publishes.**](https://medium.com/@iamleonie/subscribe)\n_Find me on[LinkedIn](https://www.linkedin.com/in/804250ab/)_, _[Twitter](https://twitter.com/helloiamleonie), and [Kaggle](https://www.kaggle.com/iamleonie)!_\n## Disclaimer\nI am a Developer Advocate at Weaviate at the time of this writing.\n## References\n### Literature\n[1] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., … & Wang, H. (2023). Retrieval-augmented generation for large language models: A survey. _[arXiv preprint arXiv:2312.10997](https://arxiv.org/pdf/2312.10997.pdf)_.\n### Images\nIf not otherwise stated, all images are created by the author.\nWritten By\nLeonie Monigatti\n[See all from Leonie Monigatti](https://towardsdatascience.com/author/iamleonie/)\nTopics:\n[Artificial Intelligence](https://towardsdatascience.com/tag/artificial-intelligence/), [Data Science](https://towardsdatascience.com/tag/data-science/), [Editors Pick](https://towardsdatascience.com/tag/editors-pick/), [Machine Learning](https://towardsdatascience.com/tag/machine-learning/), [Programming](https://towardsdatascience.com/tag/programming/)\nShare this article:\n  * [ Share on Facebook  ](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&title=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation)\n  * [ Share on LinkedIn  ](https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&title=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation)\n  * [ Share on X  ](https://x.com/share?url=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&text=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation)\n\n\n## Related Articles\n  * ![](https://towardsdatascience.com/wp-content/uploads/2024/08/0c09RmbCCpfjAbSMq.png)\n## [Implementing Convolutional Neural Networks in TensorFlow](https://towardsdatascience.com/implementing-convolutional-neural-networks-in-tensorflow-bc1c4f00bd34/)\n[ Artificial Intelligence ](https://towardsdatascience.com/category/artificial-intelligence/)\nStep-by-step code guide to building a Convolutional Neural Network \n[Shreya Rao](https://towardsdatascience.com/author/shreya-rao/)\nAugust 20, 2024\n6 min read\n  * ## [What Do Large Language Models “Understand”?](https://towardsdatascience.com/what-do-large-language-models-understand-befdb4411b77/)\n[ Artificial Intelligence ](https://towardsdatascience.com/category/artificial-intelligence/)\nA deep dive on the meaning of understanding and how it applies to LLMs \n[Tarik Dzekman](https://towardsdatascience.com/author/tarikdzekman/)\nAugust 21, 2024\n31 min read\n  * ![Photo by Krista Mangulsone on Unsplash](https://towardsdatascience.com/wp-content/uploads/2024/08/0GyVVTbgotH-DhGPH-scaled.jpg)\n## [How to Forecast Hierarchical Time Series](https://towardsdatascience.com/how-to-forecast-hierarchical-time-series-75f223f79793/)\n[ Artificial Intelligence ](https://towardsdatascience.com/category/artificial-intelligence/)\nA beginner’s guide to forecast reconciliation \n[Dr. Robert Kübler](https://towardsdatascience.com/author/dr-robert-kuebler/)\nAugust 20, 2024\n13 min read\n  * ![Photo by davisuko on Unsplash](https://towardsdatascience.com/wp-content/uploads/2024/08/1bAABgtZtAIG5YW1oEjW3pA-scaled.jpeg)\n## [Hands-on Time Series Anomaly Detection using Autoencoders, with Python](https://towardsdatascience.com/hands-on-time-series-anomaly-detection-using-autoencoders-with-python-7cd893bbc122/)\n[ Data Science ](https://towardsdatascience.com/category/data-science/)\nHere’s how to use Autoencoders to detect signals with anomalies in a few lines of… \n[Piero Paialunga](https://towardsdatascience.com/author/piero-paialunga/)\nAugust 21, 2024\n12 min read\n  * ![Image from Canva.](https://towardsdatascience.com/wp-content/uploads/2024/08/1UAA9jQVdqMXnwzYiz8Q53Q.png)\n## [3 AI Use Cases (That Are Not a Chatbot)](https://towardsdatascience.com/3-ai-use-cases-that-are-not-a-chatbot-f4f328a2707a/)\n[ Machine Learning ](https://towardsdatascience.com/category/artificial-intelligence/machine-learning/)\nFeature engineering, structuring unstructured data, and lead scoring \n[Shaw Talebi](https://towardsdatascience.com/author/shawhin/)\nAugust 21, 2024\n7 min read\n  * ## [Solving a Constrained Project Scheduling Problem with Quantum Annealing](https://towardsdatascience.com/solving-a-constrained-project-scheduling-problem-with-quantum-annealing-d0640e657a3b/)\n[ Data Science ](https://towardsdatascience.com/category/data-science/)\nSolving the resource constrained project scheduling problem (RCPSP) with D-Wave’s hybrid constrained quadratic model (CQM) \n[Luis Fernando PÉREZ ARMAS, Ph.D.](https://towardsdatascience.com/author/luisfernandopa1212/)\nAugust 20, 2024\n29 min read\n  * ![](https://towardsdatascience.com/wp-content/uploads/2023/02/1VEUgT5T4absnTqBMOEuNig.png)\n## [Back To Basics, Part Uno: Linear Regression and Cost Function](https://towardsdatascience.com/back-to-basics-part-uno-linear-regression-cost-function-and-gradient-descent-590dcb3eee46/)\n[ Data Science ](https://towardsdatascience.com/category/data-science/)\nAn illustrated guide on essential machine learning concepts \n[Shreya Rao](https://towardsdatascience.com/author/shreya-rao/)\nFebruary 3, 2023\n6 min read\n  * ![](https://towardsdatascience.com/wp-content/uploads/2024/08/1kM8tfYcdaoccB1HX71YDig.png)\n## [Must-Know in Statistics: The Bivariate Normal Projection Explained](https://towardsdatascience.com/must-know-in-statistics-the-bivariate-normal-projection-explained-ace7b2f70b5b/)\n[ Data Science ](https://towardsdatascience.com/category/data-science/)\nDerivation and practical examples of this powerful concept \n[Luigi Battistoni](https://towardsdatascience.com/author/lu-battistoni/)\nAugust 14, 2024\n7 min read\n  * ![Photo by Jess Bailey on Unsplash](https://towardsdatascience.com/wp-content/uploads/2022/09/11tHmNYFaWWtWG5I7bNeN6g-scaled.jpeg)\n## [How to Make the Most of Your Experience as a TDS Author](https://towardsdatascience.com/how-to-make-the-most-of-your-experience-as-a-tds-author-b1e056be63f1/)\n[ Data Science ](https://towardsdatascience.com/category/data-science/)\nA quick guide to our resources and FAQ \n[TDS Editors](https://towardsdatascience.com/author/towardsdatascience/)\nSeptember 13, 2022\n4 min read\n\n\n  * [YouTube](https://www.youtube.com/c/TowardsDataScience)\n  * [X](https://x.com/TDataScience)\n  * [LinkedIn](https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca)\n  * [Threads](https://www.threads.net/@towardsdatascience)\n  * [Bluesky](https://bsky.app/profile/towardsdatascience.com)\n\n\n[![Towards Data Science](https://towardsdatascience.com/wp-content/uploads/2025/02/TDS-Vector-Logo.svg)](https://towardsdatascience.com/)\nYour home for data science and Al. The world’s leading publication for data science, data analytics, data engineering, machine learning, and artificial intelligence professionals.\n©  Insight Media Group, LLC 2025 \n  * [About](https://towardsdatascience.com/about-towards-data-science-d691af11cc2f/)\n  * [Privacy Policy](https://towardsdatascience.com/privacy-policy/)\n  * [Terms of Use](https://towardsdatascience.com/website-terms-of-use/)\n\n\n[Towards Data Science is now independent!](https://towardsdatascience.com/towards-data-science-is-launching-as-an-independent-publication/)\nCookies Settings\n## Sign up to our newsletter\nEmail address*\nFirst name*\nLast name*\nJob title*\nJob level*\nPlease SelectC-LevelVP/DirectorManager/SupervisorMid Level or Senior Non-Managerial StaffEntry Level/Junior StaffFreelancer/ContractorStudent/InternOther\nCompany name*\n  * I consent to receive newsletters and other communications from Towards Data Science publications.*\n\n\n![Company Logo](https://cdn.cookielaw.org/logos/static/ot_company_logo.png)\n## Privacy Preference Center\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer. [More information](https://cookiepedia.co.uk/giving-consent-to-cookies)\nAllow All\n###  Manage Consent Preferences\n#### Functional Cookies\nFunctional Cookies Active\nThese cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.\n#### Strictly Necessary Cookies\nAlways Active\nThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.\n#### Performance Cookies\nPerformance Cookies Active\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.\n#### Targeting Cookies\nTargeting Cookies Active\nThese cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.\nBack Button\n### Cookie List\nSearch Icon\nFilter Icon\nClear\ncheckbox label label\nApply Cancel\nConsent Leg.Interest\ncheckbox label label\ncheckbox label label\ncheckbox label label\nReject All Confirm My Choices\n[![Powered by Onetrust](https://cdn.cookielaw.org/logos/static/powered_by_logo.svg)](https://www.onetrust.com/products/cookie-consent/)\nSome areas of this page may shift around if you resize the browser window. Be sure to check heading and document order.\n",
    "content_quality_score": 0.9,
    "summary": null,
    "child_urls": [
        "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#wp--skip-link--target",
        "https://towardsdatascience.com/",
        "https://towardsdatascience.com/latest/",
        "https://towardsdatascience.com/tag/editors-pick/",
        "https://towardsdatascience.com/tag/deep-dives/",
        "https://towardsdatascience.com/questions-96667b06af5/",
        "https://newsletter.towardsdatascience.com/subscription-to-the-newsletter",
        "https://towardsdatascience.com/category/artificial-intelligence/",
        "https://towardsdatascience.com/author/iamleonie/",
        "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c968",
        "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#3275",
        "https://towardsdatascience.com/advanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930/#c1e2",
        "https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2",
        "https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5",
        "https://towardsdatascience.com/tag/machine-learning/",
        "https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439",
        "https://towardsdatascience.com/advanced-rag-01-small-to-big-retrieval-172181b396d4",
        "https://towardsdatascience.com/tag/artificial-intelligence/",
        "https://towardsdatascience.com/tag/data-science/",
        "https://towardsdatascience.com/tag/programming/",
        "https://towardsdatascience.com/implementing-convolutional-neural-networks-in-tensorflow-bc1c4f00bd34/",
        "https://towardsdatascience.com/author/shreya-rao/",
        "https://towardsdatascience.com/what-do-large-language-models-understand-befdb4411b77/",
        "https://towardsdatascience.com/author/tarikdzekman/",
        "https://towardsdatascience.com/how-to-forecast-hierarchical-time-series-75f223f79793/",
        "https://towardsdatascience.com/author/dr-robert-kuebler/",
        "https://towardsdatascience.com/hands-on-time-series-anomaly-detection-using-autoencoders-with-python-7cd893bbc122/",
        "https://towardsdatascience.com/category/data-science/",
        "https://towardsdatascience.com/author/piero-paialunga/",
        "https://towardsdatascience.com/3-ai-use-cases-that-are-not-a-chatbot-f4f328a2707a/",
        "https://towardsdatascience.com/category/artificial-intelligence/machine-learning/",
        "https://towardsdatascience.com/author/shawhin/",
        "https://towardsdatascience.com/solving-a-constrained-project-scheduling-problem-with-quantum-annealing-d0640e657a3b/",
        "https://towardsdatascience.com/author/luisfernandopa1212/",
        "https://towardsdatascience.com/back-to-basics-part-uno-linear-regression-cost-function-and-gradient-descent-590dcb3eee46/",
        "https://towardsdatascience.com/must-know-in-statistics-the-bivariate-normal-projection-explained-ace7b2f70b5b/",
        "https://towardsdatascience.com/author/lu-battistoni/",
        "https://towardsdatascience.com/how-to-make-the-most-of-your-experience-as-a-tds-author-b1e056be63f1/",
        "https://towardsdatascience.com/author/towardsdatascience/",
        "https://towardsdatascience.com/about-towards-data-science-d691af11cc2f/",
        "https://towardsdatascience.com/privacy-policy/",
        "https://towardsdatascience.com/website-terms-of-use/",
        "https://towardsdatascience.com/towards-data-science-is-launching-as-an-independent-publication/",
        "https://contributor.insightmediagroup.io/",
        "https://www.linkedin.com/company/towards-data-science/?originalSubdomain=ca",
        "https://x.com/TDataScience",
        "https://medium.com/towards-data-science/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2",
        "https://www.llamaindex.ai/",
        "https://betterprogramming.pub/fine-tuning-your-embedding-model-to-maximize-relevance-retrieval-in-rag-pipeline-2ea3fa231149",
        "http://weaviate.io",
        "https://openai.com/",
        "https://platform.openai.com/account/api-keys",
        "https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/naive_rag.ipynb",
        "https://github.com/run-llama/llama_index",
        "https://weaviate.io/",
        "https://weaviate.io/developers/weaviate/installation/embedded",
        "https://weaviate.io/developers/weaviate/installation/docker-compose",
        "https://weaviate.io/developers/weaviate/installation/weaviate-cloud-services",
        "https://github.com/weaviate/recipes/blob/main/integrations/llamaindex/retrieval-augmented-generation/advanced_rag.ipynb",
        "https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo.html",
        "https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/",
        "https://www.baai.ac.cn/english.html",
        "https://huggingface.co/",
        "https://medium.com/subscribe/@iamleonie",
        "https://medium.com/@iamleonie/subscribe",
        "https://www.linkedin.com/in/804250ab/",
        "https://twitter.com/helloiamleonie",
        "https://www.kaggle.com/iamleonie",
        "https://arxiv.org/pdf/2312.10997.pdf",
        "https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&title=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation",
        "https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&title=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation",
        "https://x.com/share?url=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-retrieval-augmented-generation-from-theory-to-llamaindex-implementation-4de1464a9930%2F&text=Advanced%20Retrieval-Augmented%20Generation%3A%20From%20Theory%20to%20LlamaIndex%20Implementation",
        "https://www.youtube.com/c/TowardsDataScience",
        "https://www.threads.net/@towardsdatascience",
        "https://bsky.app/profile/towardsdatascience.com",
        "https://cookiepedia.co.uk/giving-consent-to-cookies",
        "https://www.onetrust.com/products/cookie-consent/"
    ]
}