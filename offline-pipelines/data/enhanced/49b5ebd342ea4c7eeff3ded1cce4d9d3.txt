[Skip to content](https://github.com/NVIDIA/nv-ingest/#start-of-content)
## Navigation Menu
Toggle navigation
[ ](https://github.com/)
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fnv-ingest%2F)
  * Product 
    * [ GitHub Copilot Write better code with AI  ](https://github.com/features/copilot)
    * [ Security Find and fix vulnerabilities  ](https://github.com/features/security)
    * [ Actions Automate any workflow  ](https://github.com/features/actions)
    * [ Codespaces Instant dev environments  ](https://github.com/features/codespaces)
    * [ Issues Plan and track work  ](https://github.com/features/issues)
    * [ Code Review Manage code changes  ](https://github.com/features/code-review)
    * [ Discussions Collaborate outside of code  ](https://github.com/features/discussions)
    * [ Code Search Find more, search less  ](https://github.com/features/code-search)
Explore
    * [ All features ](https://github.com/features)
    * [ Documentation ](https://docs.github.com)
    * [ GitHub Skills ](https://skills.github.com)
    * [ Blog ](https://github.blog)
  * Solutions 
By company size
    * [ Enterprises ](https://github.com/enterprise)
    * [ Small and medium teams ](https://github.com/team)
    * [ Startups ](https://github.com/enterprise/startups)
    * [ Nonprofits ](https://github.com/solutions/industry/nonprofits)
By use case
    * [ DevSecOps ](https://github.com/solutions/use-case/devsecops)
    * [ DevOps ](https://github.com/solutions/use-case/devops)
    * [ CI/CD ](https://github.com/solutions/use-case/ci-cd)
    * [ View all use cases ](https://github.com/solutions/use-case)
By industry
    * [ Healthcare ](https://github.com/solutions/industry/healthcare)
    * [ Financial services ](https://github.com/solutions/industry/financial-services)
    * [ Manufacturing ](https://github.com/solutions/industry/manufacturing)
    * [ Government ](https://github.com/solutions/industry/government)
    * [ View all industries ](https://github.com/solutions/industry)
[ View all solutions ](https://github.com/solutions)
  * Resources 
Topics
    * [ AI ](https://github.com/resources/articles/ai)
    * [ DevOps ](https://github.com/resources/articles/devops)
    * [ Security ](https://github.com/resources/articles/security)
    * [ Software Development ](https://github.com/resources/articles/software-development)
    * [ View all ](https://github.com/resources/articles)
Explore
    * [ Learning Pathways ](https://resources.github.com/learn/pathways)
    * [ Events & Webinars ](https://resources.github.com)
    * [ Ebooks & Whitepapers ](https://github.com/resources/whitepapers)
    * [ Customer Stories ](https://github.com/customer-stories)
    * [ Partners ](https://partner.github.com)
    * [ Executive Insights ](https://github.com/solutions/executive-insights)
  * Open Source 
    * [ GitHub Sponsors Fund open source developers  ](https://github.com/sponsors)
    * [ The ReadME Project GitHub community articles  ](https://github.com/readme)
Repositories
    * [ Topics ](https://github.com/topics)
    * [ Trending ](https://github.com/trending)
    * [ Collections ](https://github.com/collections)
  * Enterprise 
    * [ Enterprise platform AI-powered developer platform  ](https://github.com/enterprise)
Available add-ons
    * [ Advanced Security Enterprise-grade security features  ](https://github.com/enterprise/advanced-security)
    * [ Copilot for business Enterprise-grade AI features  ](https://github.com/features/copilot/copilot-business)
    * [ Premium Support Enterprise-grade 24/7 support  ](https://github.com/premium-support)
  * [Pricing](https://github.com/pricing)


Search or jump to...
# Search code, repositories, users, issues, pull requests...
Search 
Clear
[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)
#  Provide feedback 
We read every piece of feedback, and take your input very seriously.
Include my email address so I can be contacted
Cancel  Submit feedback 
#  Saved searches 
## Use saved searches to filter your results more quickly
Name
Query
To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax). 
Cancel  Create saved search 
[ Sign in ](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fnv-ingest%2F)
[ Sign up ](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NVIDIA%2Fnv-ingest) Reseting focus
You signed in with another tab or window. [Reload](https://github.com/NVIDIA/nv-ingest/) to refresh your session. You signed out in another tab or window. [Reload](https://github.com/NVIDIA/nv-ingest/) to refresh your session. You switched accounts on another tab or window. [Reload](https://github.com/NVIDIA/nv-ingest/) to refresh your session. Dismiss alert
{{ message }}
[ NVIDIA ](https://github.com/NVIDIA) / **[nv-ingest](https://github.com/NVIDIA/nv-ingest) ** Public
  * [ Notifications ](https://github.com/login?return_to=%2FNVIDIA%2Fnv-ingest) You must be signed in to change notification settings
  * [ Fork 227 ](https://github.com/login?return_to=%2FNVIDIA%2Fnv-ingest)
  * [ Star  2.6k ](https://github.com/login?return_to=%2FNVIDIA%2Fnv-ingest)


NVIDIA Ingest is an early access set of microservices for parsing hundreds of thousands of complex, messy unstructured PDFs and other enterprise documents into metadata and text to embed into retrieval systems. 
### License
[ Apache-2.0 license ](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/LICENSE)
[ 2.6k stars ](https://github.com/NVIDIA/nv-ingest/stargazers) [ 227 forks ](https://github.com/NVIDIA/nv-ingest/forks) [ Branches ](https://github.com/NVIDIA/nv-ingest/branches) [ Tags ](https://github.com/NVIDIA/nv-ingest/tags) [ Activity ](https://github.com/NVIDIA/nv-ingest/activity)
[ Star  ](https://github.com/login?return_to=%2FNVIDIA%2Fnv-ingest)
[ Notifications ](https://github.com/login?return_to=%2FNVIDIA%2Fnv-ingest) You must be signed in to change notification settings
  * [ Code ](https://github.com/NVIDIA/nv-ingest)
  * [ Issues 74 ](https://github.com/NVIDIA/nv-ingest/issues)
  * [ Pull requests 7 ](https://github.com/NVIDIA/nv-ingest/pulls)
  * [ Discussions ](https://github.com/NVIDIA/nv-ingest/discussions)
  * [ Actions ](https://github.com/NVIDIA/nv-ingest/actions)
  * [ Projects 0 ](https://github.com/NVIDIA/nv-ingest/projects)
  * [ Security ](https://github.com/NVIDIA/nv-ingest/security)
  * [ Insights ](https://github.com/NVIDIA/nv-ingest/pulse)


Additional navigation options
  * [ Code  ](https://github.com/NVIDIA/nv-ingest)
  * [ Issues  ](https://github.com/NVIDIA/nv-ingest/issues)
  * [ Pull requests  ](https://github.com/NVIDIA/nv-ingest/pulls)
  * [ Discussions  ](https://github.com/NVIDIA/nv-ingest/discussions)
  * [ Actions  ](https://github.com/NVIDIA/nv-ingest/actions)
  * [ Projects  ](https://github.com/NVIDIA/nv-ingest/projects)
  * [ Security  ](https://github.com/NVIDIA/nv-ingest/security)
  * [ Insights  ](https://github.com/NVIDIA/nv-ingest/pulse)


# NVIDIA/nv-ingest
release/25.3.0
[**37** Branches](https://github.com/NVIDIA/nv-ingest/branches)[**5** Tags](https://github.com/NVIDIA/nv-ingest/tags)
[](https://github.com/NVIDIA/nv-ingest/branches)[](https://github.com/NVIDIA/nv-ingest/tags)
Go to file
Code
## Folders and files
Name| Name| Last commit message| Last commit date  
---|---|---|---  
## Latest commit
[![randerzander](https://avatars.githubusercontent.com/u/1692914?v=4&size=40)](https://github.com/randerzander)[randerzander](https://github.com/NVIDIA/nv-ingest/commits?author=randerzander)[fixing nemoretriever-parse container location & version tags (](https://github.com/NVIDIA/nv-ingest/commit/c889feb1dab2cdd1348a18e138af9b3fa052e09e)[#612](https://github.com/NVIDIA/nv-ingest/pull/612)[)](https://github.com/NVIDIA/nv-ingest/commit/c889feb1dab2cdd1348a18e138af9b3fa052e09e)Mar 20, 2025[c889feb](https://github.com/NVIDIA/nv-ingest/commit/c889feb1dab2cdd1348a18e138af9b3fa052e09e) Â· Mar 20, 2025
## History
[422 Commits](https://github.com/NVIDIA/nv-ingest/commits/release/25.3.0/)[](https://github.com/NVIDIA/nv-ingest/commits/release/25.3.0/)  
[.devcontainer](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/.devcontainer ".devcontainer")| [.devcontainer](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/.devcontainer ".devcontainer")| [Adjust openapi docs to be /docs instead of /v1/docs URL (](https://github.com/NVIDIA/nv-ingest/commit/eaa6e2ef88460b83cd09f8dcf00eb4a6fe7d38d3 "Adjust openapi docs to be /docs instead of /v1/docs URL \(#574\)")[#574](https://github.com/NVIDIA/nv-ingest/pull/574)[)](https://github.com/NVIDIA/nv-ingest/commit/eaa6e2ef88460b83cd09f8dcf00eb4a6fe7d38d3 "Adjust openapi docs to be /docs instead of /v1/docs URL \(#574\)")| Mar 13, 2025  
[.github](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/.github ".github")| [.github](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/.github ".github")| [Enable manual trigger for pypi publishing (](https://github.com/NVIDIA/nv-ingest/commit/bb20ce3580877967963e0289ad6c6b9e65176150 "Enable manual trigger for pypi publishing \(#541\)")[#541](https://github.com/NVIDIA/nv-ingest/pull/541)[)](https://github.com/NVIDIA/nv-ingest/commit/bb20ce3580877967963e0289ad6c6b9e65176150 "Enable manual trigger for pypi publishing \(#541\)")| Mar 10, 2025  
[api](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/api "api")| [api](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/api "api")| [Conda client build fix (](https://github.com/NVIDIA/nv-ingest/commit/51ed7506841ef885c5fd384a9f66ac2cf2964df0 "Conda client build fix \(#537\)")[#537](https://github.com/NVIDIA/nv-ingest/pull/537)[)](https://github.com/NVIDIA/nv-ingest/commit/51ed7506841ef885c5fd384a9f66ac2cf2964df0 "Conda client build fix \(#537\)")| Mar 10, 2025  
[ci](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/ci "ci")| [ci](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/ci "ci")| [Create nv-ingest-api wheel and publish nightly to artifactory (](https://github.com/NVIDIA/nv-ingest/commit/0ac0593749da703f836ad5fa58a4ccd6439bf237 "Create nv-ingest-api wheel and publish nightly to artifactory \(#430\)")[#430](https://github.com/NVIDIA/nv-ingest/pull/430)[)](https://github.com/NVIDIA/nv-ingest/commit/0ac0593749da703f836ad5fa58a4ccd6439bf237 "Create nv-ingest-api wheel and publish nightly to artifactory \(#430\)")| Feb 11, 2025  
[client](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/client "client")| [client](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/client "client")| [update python client usage notebook (](https://github.com/NVIDIA/nv-ingest/commit/85c841f49a5d9673bdd349d56c97b6a6d9c7bba6 "update python client usage notebook \(#582\)")[#582](https://github.com/NVIDIA/nv-ingest/pull/582)[)](https://github.com/NVIDIA/nv-ingest/commit/85c841f49a5d9673bdd349d56c97b6a6d9c7bba6 "update python client usage notebook \(#582\)")| Mar 15, 2025  
[conda](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/conda "conda")| [conda](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/conda "conda")| [Remove use of wand/image magick (](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")[#573](https://github.com/NVIDIA/nv-ingest/pull/573)[)](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")| Mar 13, 2025  
[config](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/config "config")| [config](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/config "config")| [Add missing receivers configuration for http protocol (](https://github.com/NVIDIA/nv-ingest/commit/0f4a869df59708aaef5e9878e8a598343b32341d "Add missing receivers configuration for http protocol \(#298\)")[#298](https://github.com/NVIDIA/nv-ingest/pull/298)[)](https://github.com/NVIDIA/nv-ingest/commit/0f4a869df59708aaef5e9878e8a598343b32341d "Add missing receivers configuration for http protocol \(#298\)")| Dec 18, 2024  
[data](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/data "data")| [data](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/data "data")| [Update json output examples and add link to metadata page (](https://github.com/NVIDIA/nv-ingest/commit/e254588cbd9a4f49fccdd1e2915f8e6d7b118ab2 "Update json output examples and add link to metadata page \(#570\)")[#570](https://github.com/NVIDIA/nv-ingest/pull/570)[)](https://github.com/NVIDIA/nv-ingest/commit/e254588cbd9a4f49fccdd1e2915f8e6d7b118ab2 "Update json output examples and add link to metadata page \(#570\)")| Mar 13, 2025  
[deploy](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/deploy "deploy")| [deploy](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/deploy "deploy")| [VDR changes round 3 (](https://github.com/NVIDIA/nv-ingest/commit/58f2cefa60001a8dbdc2cb9be195733c42807ca0 "VDR changes round 3 \(#578\)")[#578](https://github.com/NVIDIA/nv-ingest/pull/578)[)](https://github.com/NVIDIA/nv-ingest/commit/58f2cefa60001a8dbdc2cb9be195733c42807ca0 "VDR changes round 3 \(#578\)")| Mar 14, 2025  
[docker/scripts](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/docker/scripts "This path skips through empty directories")| [docker/scripts](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/docker/scripts "This path skips through empty directories")| [Remove use of wand/image magick (](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")[#573](https://github.com/NVIDIA/nv-ingest/pull/573)[)](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")| Mar 13, 2025  
[docs](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/docs "docs")| [docs](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/docs "docs")| [Fixing docker-compose & release docs Release/25.3.0 (](https://github.com/NVIDIA/nv-ingest/commit/52bdefc3025229633dcfb15e5271e6e9dc701538 "Fixing docker-compose & release docs Release/25.3.0 \(#609\)")[#609](https://github.com/NVIDIA/nv-ingest/pull/609)[)](https://github.com/NVIDIA/nv-ingest/commit/52bdefc3025229633dcfb15e5271e6e9dc701538 "Fixing docker-compose & release docs Release/25.3.0 \(#609\)")| Mar 19, 2025  
[evaluation](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/evaluation "evaluation")| [evaluation](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/evaluation "evaluation")| [Add notebooks that use LlamaIndex to calculate recall scores for NV-Iâ¦](https://github.com/NVIDIA/nv-ingest/commit/000601046e5b6744ea6605e36fb77ddd507a0598 "Add notebooks that use LlamaIndex to calculate recall scores for NV-Ingest chart and table extraction \(#157\)
Co-authored-by: Chris Jarrett <cjarrett@ipp1-3302.aselab.nvidia.com>
Co-authored-by: Chris Jarrett <cjarrett@dgx-a100-01.aselab.nvidia.com>")| Feb 6, 2025  
[examples](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/examples "examples")| [examples](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/examples "examples")| [Remove references to store task from docs and examples (](https://github.com/NVIDIA/nv-ingest/commit/dd65d0f9f2eb2e011514121b85bc4c03ff50df22 "Remove references to store task from docs and examples \(#561\)
Co-authored-by: Chris Jarrett <cjarrett@dgx-a100-01.aselab.nvidia.com>")[#561](https://github.com/NVIDIA/nv-ingest/pull/561)[)](https://github.com/NVIDIA/nv-ingest/commit/dd65d0f9f2eb2e011514121b85bc4c03ff50df22 "Remove references to store task from docs and examples \(#561\)
Co-authored-by: Chris Jarrett <cjarrett@dgx-a100-01.aselab.nvidia.com>")| Mar 12, 2025  
[helm](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/helm "helm")| [helm](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/helm "helm")| [Helm chart updates for 25.3.0 Release (](https://github.com/NVIDIA/nv-ingest/commit/4d1825aa37f89177689a07e25f7edf4e3446ae54 "Helm chart updates for 25.3.0 Release \(#589\)")[#589](https://github.com/NVIDIA/nv-ingest/pull/589)[)](https://github.com/NVIDIA/nv-ingest/commit/4d1825aa37f89177689a07e25f7edf4e3446ae54 "Helm chart updates for 25.3.0 Release \(#589\)")| Mar 15, 2025  
[skaffold](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/skaffold "skaffold")| [skaffold](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/skaffold "skaffold")| [Remove Kubernetes and Deployment pages (](https://github.com/NVIDIA/nv-ingest/commit/76433ee8769018369f0a987da2215b920b823a7c "Remove Kubernetes and Deployment pages \(#556\)
Co-authored-by: Nicole McAllister <nmcallister@nvidia.com>")[#556](https://github.com/NVIDIA/nv-ingest/pull/556)[)](https://github.com/NVIDIA/nv-ingest/commit/76433ee8769018369f0a987da2215b920b823a7c "Remove Kubernetes and Deployment pages \(#556\)
Co-authored-by: Nicole McAllister <nmcallister@nvidia.com>")| Mar 12, 2025  
[src](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/src "src")| [src](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/src "src")| [add external parkeet endpoint for library mode (](https://github.com/NVIDIA/nv-ingest/commit/271b9251a3cdc9601e4e4ff8b0938a622fe31b4b "add external parkeet endpoint for library mode \(#588\)")[#588](https://github.com/NVIDIA/nv-ingest/pull/588)[)](https://github.com/NVIDIA/nv-ingest/commit/271b9251a3cdc9601e4e4ff8b0938a622fe31b4b "add external parkeet endpoint for library mode \(#588\)")| Mar 15, 2025  
[tests](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/tests "tests")| [tests](https://github.com/NVIDIA/nv-ingest/tree/release/25.3.0/tests "tests")| [Remove use of wand/image magick (](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")[#573](https://github.com/NVIDIA/nv-ingest/pull/573)[)](https://github.com/NVIDIA/nv-ingest/commit/0a95814d857709e8a09e536c4aec9050c3dcf7aa "Remove use of wand/image magick \(#573\)")| Mar 13, 2025  
[.gitignore](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/.gitignore ".gitignore")| [.gitignore](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/.gitignore ".gitignore")| [Build nv-ingest docs with CI (](https://github.com/NVIDIA/nv-ingest/commit/38ff6ea9e9701fd88e78a71fc520c9e3509739d8 "Build nv-ingest docs with CI \(#338\)")[#338](https://github.com/NVIDIA/nv-ingest/pull/338)[)](https://github.com/NVIDIA/nv-ingest/commit/38ff6ea9e9701fd88e78a71fc520c9e3509739d8 "Build nv-ingest docs with CI \(#338\)")| Jan 17, 2025  
[.pre-commit-config.yaml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/.pre-commit-config.yaml ".pre-commit-config.yaml")| [.pre-commit-config.yaml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/.pre-commit-config.yaml ".pre-commit-config.yaml")| [Adjust trailing-whitespace hook to ignore the data directory (](https://github.com/NVIDIA/nv-ingest/commit/ca16e39be7c23a2a88c45d74988107139502856e "Adjust trailing-whitespace hook to ignore the data directory \(#410\)")[#410](https://github.com/NVIDIA/nv-ingest/pull/410)[)](https://github.com/NVIDIA/nv-ingest/commit/ca16e39be7c23a2a88c45d74988107139502856e "Adjust trailing-whitespace hook to ignore the data directory \(#410\)")| Feb 6, 2025  
[CHANGELOG.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CHANGELOG.md "CHANGELOG.md")| [CHANGELOG.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CHANGELOG.md "CHANGELOG.md")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[CITATION.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CITATION.md "CITATION.md")| [CITATION.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CITATION.md "CITATION.md")| [Barebones workflow to trigger pre-commit github action (](https://github.com/NVIDIA/nv-ingest/commit/8a2a202b9b3e3aebf7b1390d0002a821f83b8cca "Barebones workflow to trigger pre-commit github action \(#64\)
Co-authored-by: Edward Kim <109497216+edknv@users.noreply.github.com>")[#64](https://github.com/NVIDIA/nv-ingest/pull/64)[)](https://github.com/NVIDIA/nv-ingest/commit/8a2a202b9b3e3aebf7b1390d0002a821f83b8cca "Barebones workflow to trigger pre-commit github action \(#64\)
Co-authored-by: Edward Kim <109497216+edknv@users.noreply.github.com>")| Dec 10, 2024  
[CODE_OF_CONDUCT.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CODE_OF_CONDUCT.md "CODE_OF_CONDUCT.md")| [CODE_OF_CONDUCT.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CODE_OF_CONDUCT.md "CODE_OF_CONDUCT.md")| [Barebones workflow to trigger pre-commit github action (](https://github.com/NVIDIA/nv-ingest/commit/8a2a202b9b3e3aebf7b1390d0002a821f83b8cca "Barebones workflow to trigger pre-commit github action \(#64\)
Co-authored-by: Edward Kim <109497216+edknv@users.noreply.github.com>")[#64](https://github.com/NVIDIA/nv-ingest/pull/64)[)](https://github.com/NVIDIA/nv-ingest/commit/8a2a202b9b3e3aebf7b1390d0002a821f83b8cca "Barebones workflow to trigger pre-commit github action \(#64\)
Co-authored-by: Edward Kim <109497216+edknv@users.noreply.github.com>")| Dec 10, 2024  
[CONTRIBUTING.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CONTRIBUTING.md "CONTRIBUTING.md")| [CONTRIBUTING.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/CONTRIBUTING.md "CONTRIBUTING.md")| [VDR changes round 3 (](https://github.com/NVIDIA/nv-ingest/commit/58f2cefa60001a8dbdc2cb9be195733c42807ca0 "VDR changes round 3 \(#578\)")[#578](https://github.com/NVIDIA/nv-ingest/pull/578)[)](https://github.com/NVIDIA/nv-ingest/commit/58f2cefa60001a8dbdc2cb9be195733c42807ca0 "VDR changes round 3 \(#578\)")| Mar 14, 2025  
[Dockerfile](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/Dockerfile "Dockerfile")| [Dockerfile](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/Dockerfile "Dockerfile")| [Remove graphviz and its dependencies from Dockerfile to reduce image â¦](https://github.com/NVIDIA/nv-ingest/commit/79396db84c3ee56f9ff9afea269b7cc9ed84ecae "Remove graphviz and its dependencies from Dockerfile to reduce image size \(#579\)")| Mar 14, 2025  
[LICENSE](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/LICENSE "LICENSE")| [LICENSE](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/LICENSE "LICENSE")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[README.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/README.md "README.md")| [README.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/README.md "README.md")| [Fixing docker-compose & release docs Release/25.3.0 (](https://github.com/NVIDIA/nv-ingest/commit/52bdefc3025229633dcfb15e5271e6e9dc701538 "Fixing docker-compose & release docs Release/25.3.0 \(#609\)")[#609](https://github.com/NVIDIA/nv-ingest/pull/609)[)](https://github.com/NVIDIA/nv-ingest/commit/52bdefc3025229633dcfb15e5271e6e9dc701538 "Fixing docker-compose & release docs Release/25.3.0 \(#609\)")| Mar 19, 2025  
[SECURITY.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/SECURITY.md "SECURITY.md")| [SECURITY.md](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/SECURITY.md "SECURITY.md")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[docker-compose.yaml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/docker-compose.yaml "docker-compose.yaml")| [docker-compose.yaml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/docker-compose.yaml "docker-compose.yaml")| [fixing nemoretriever-parse container location & version tags (](https://github.com/NVIDIA/nv-ingest/commit/c889feb1dab2cdd1348a18e138af9b3fa052e09e "fixing nemoretriever-parse container location & version tags \(#612\)")[#612](https://github.com/NVIDIA/nv-ingest/pull/612)[)](https://github.com/NVIDIA/nv-ingest/commit/c889feb1dab2cdd1348a18e138af9b3fa052e09e "fixing nemoretriever-parse container location & version tags \(#612\)")| Mar 20, 2025  
[print_env.sh](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/print_env.sh "print_env.sh")| [print_env.sh](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/print_env.sh "print_env.sh")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[pyproject.toml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/pyproject.toml "pyproject.toml")| [pyproject.toml](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/pyproject.toml "pyproject.toml")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[pytest.ini](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/pytest.ini "pytest.ini")| [pytest.ini](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/pytest.ini "pytest.ini")| [introduce nv-ingest-api package (](https://github.com/NVIDIA/nv-ingest/commit/8d02d1025402ddc636f523b73ce044ac49034b2c "introduce nv-ingest-api package \(#385\)")[#385](https://github.com/NVIDIA/nv-ingest/pull/385)[)](https://github.com/NVIDIA/nv-ingest/commit/8d02d1025402ddc636f523b73ce044ac49034b2c "introduce nv-ingest-api package \(#385\)")| Jan 29, 2025  
[setup.cfg](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/setup.cfg "setup.cfg")| [setup.cfg](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/setup.cfg "setup.cfg")| [Initial commit](https://github.com/NVIDIA/nv-ingest/commit/87950ff449b89274676c49ab6b2fad05dcd724a4 "Initial commit")| Aug 27, 2024  
[setup.py](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/setup.py "setup.py")| [setup.py](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/setup.py "setup.py")| [Add the ability to build and publish Conda packages. (](https://github.com/NVIDIA/nv-ingest/commit/6689b656389f646099a82654cde10ecc9c178ffd "Add the ability to build and publish Conda packages. \(#285\)")[#285](https://github.com/NVIDIA/nv-ingest/pull/285)[)](https://github.com/NVIDIA/nv-ingest/commit/6689b656389f646099a82654cde10ecc9c178ffd "Add the ability to build and publish Conda packages. \(#285\)")| Dec 16, 2024  
View all files  
## Repository files navigation
  * [README](https://github.com/NVIDIA/nv-ingest/)
  * [Code of conduct](https://github.com/NVIDIA/nv-ingest/)
  * [Apache-2.0 license](https://github.com/NVIDIA/nv-ingest/)
  * [Security](https://github.com/NVIDIA/nv-ingest/)


## NVIDIA-Ingest: Multi-modal data extraction
[](https://github.com/NVIDIA/nv-ingest/#nvidia-ingest-multi-modal-data-extraction)
NVIDIA-Ingest is a scalable, performance-oriented content and metadata extraction SDK for a variety of input formats. NV-Ingest includes support for parsing PDFs, text files, Microsoft Word and PowerPoint documents, plain images, and audio files. NV-Ingest uses specialized NVIDIA NIMs (self-hosted microservices, or hosted on build.nvidia.com) to find, contextualize, and extract text, tables, charts, and unstructured images that you can use in downstream generative applications.
Note
NVIDIA Ingest is also known as NV-Ingest and [NeMo Retriever Extraction](https://docs.nvidia.com/nemo/retriever/extraction/overview/).
NVIDIA Ingest enables parallelization of the process of splitting documents into pages where contents are classified (as tables, charts, images, text), extracted into discrete content, and further contextualized via optical character recognition (OCR) into a well defined JSON schema. From there, NVIDIA Ingest can optionally manage computation of embeddings for the extracted content, and also optionally manage storing into a vector database [Milvus](https://milvus.io/).
[![Pipeline Overview](https://camo.githubusercontent.com/2bd5170792fa9b64a19b774fb50dcdf8acef3d37cf5fdf5a91e3531583a45d7a/68747470733a2f2f646f63732e6e76696469612e636f6d2f6e656d6f2f7265747269657665722f65787472616374696f6e2f696d616765732f6f766572766965772d65787472616374696f6e2e706e67)](https://camo.githubusercontent.com/2bd5170792fa9b64a19b774fb50dcdf8acef3d37cf5fdf5a91e3531583a45d7a/68747470733a2f2f646f63732e6e76696469612e636f6d2f6e656d6f2f7265747269657665722f65787472616374696f6e2f696d616765732f6f766572766965772d65787472616374696f6e2e706e67)
### Table of Contents
[](https://github.com/NVIDIA/nv-ingest/#table-of-contents)
  1. [Introduction](https://github.com/NVIDIA/nv-ingest/#introduction)
  2. [Prerequisites](https://github.com/NVIDIA/nv-ingest/#prerequisites)
  3. [Quickstart](https://github.com/NVIDIA/nv-ingest/#quickstart)
  4. [Repo Structure](https://github.com/NVIDIA/nv-ingest/#repo-structure)
  5. [Notices](https://github.com/NVIDIA/nv-ingest/#notices)


## Introduction
[](https://github.com/NVIDIA/nv-ingest/#introduction)
## What NVIDIA-Ingest Is âï¸
[](https://github.com/NVIDIA/nv-ingest/#what-nvidia-ingest-is-ï¸)
NV-Ingest is a library and microservice service that does the following:
  * Accept a job specification that contains a document payload and a set of ingestion tasks to perform on that payload.
  * Store the result of each job to retrieve later. The result is a dictionary that contains a list of metadata that describes the objects extracted from the base document, and processing annotations and timing/trace data.
  * Support multiple methods of extraction for each document type to balance trade-offs between throughput and accuracy. For example, for .pdf documents nv-ingest supports extraction through pdfium, [nemoretriever-parse](https://build.nvidia.com/nvidia/nemoretriever-parse), Unstructured.io, and Adobe Content Extraction Services.
  * Support various types of before and after processing operations, including text splitting and chunking, transform and filtering, embedding generation, and image offloading to storage.


NV-Ingest supports the following file types:
  * `pdf`
  * `docx`
  * `pptx`
  * `jpeg`
  * `png`
  * `svg`
  * `tiff`
  * `txt`


## Prerequisites
[](https://github.com/NVIDIA/nv-ingest/#prerequisites)
For production-level performance and scalability, we recommend that you deploy the pipeline and supporting NIMs by using Docker Compose or Kubernetes ([helm charts](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/helm)). For more information, refer to [prerequisites](https://docs.nvidia.com/nv-ingest/user-guide/getting-started/prerequisites).
## Library Mode Quickstart
[](https://github.com/NVIDIA/nv-ingest/#library-mode-quickstart)
For small-scale workloads, such as workloads of fewer than 100 PDFs, you can use library mode setup. Library mode set up depends on NIMs that are already self-hosted, or, by default, NIMs that are hosted on build.nvidia.com.
Library mode deployment of nv-ingest requires:
  * Linux operating systems (Ubuntu 22.04 or later recommended)
  * [Conda Python environment and package manager](https://github.com/conda-forge/miniforge)
  * Python 3.10


### Step 1: Prepare Your Environment
[](https://github.com/NVIDIA/nv-ingest/#step-1-prepare-your-environment)
Create a fresh conda environment in which to install nv-ingest and dependencies.
```
conda create -y --name nvingest python=3.10 && \
  conda activate nvingest && \
  conda install -y -c rapidsai -c conda-forge -c nvidia nv_ingest=25.3.0 nv_ingest_client=25.3.0 nv_ingest_api=25.3.0 && \
  pip install opencv-python llama-index-embeddings-nvidia pymilvus 'pymilvus[bulk_writer, model]' milvus-lite nvidia-riva-client unstructured-client
```

Make sure to set your NVIDIA_BUILD_API_KEY and NVIDIA_API_KEY. If you don't have one, you can get one on [build.nvidia.com](https://build.nvidia.com/nvidia/llama-3_2-nv-embedqa-1b-v2?snippet_tab=Python&signin=true&api_key=true).
```
#Note: these should be the same value
export NVIDIA_BUILD_API_KEY=nvapi-...
export NVIDIA_API_KEY=nvapi-...

```

### Step 2: Ingest Documents
[](https://github.com/NVIDIA/nv-ingest/#step-2-ingest-documents)
You can submit jobs programmatically in Python.
Note: Make sure your conda environment is activated. `which python` should indicate that you're using the conda provided python installation (not an OS provided python).
```
which python
/home/dev/miniforge3/envs/nvingest/bin/python

```

If you have a very high number of CPUs and see the process hang without progress, we recommend using taskset to limit the number of CPUs visible to the process:
```
taskset -c 0-3 python your_ingestion_script.py

```

On a 4 CPU core low end laptop, the following should take about 10 seconds:
```
import logging, os, time, sys
        
from nv_ingest.util.pipeline.pipeline_runners import start_pipeline_subprocess
from nv_ingest_client.client import Ingestor, NvIngestClient
from nv_ingest_client.message_clients.simple.simple_client import SimpleClient
from nv_ingest.util.pipeline.pipeline_runners import PipelineCreationSchema
from nv_ingest_client.util.process_json_files import ingest_json_results_to_blob
# Start the pipeline subprocess for library mode
config = PipelineCreationSchema()
pipeline_process = start_pipeline_subprocess(config)
# you can configure the subprocesses to log stderr to stdout for debugging purposes
#pipeline_process = start_pipeline_subprocess(config, stderr=sys.stderr, stdout=sys.stdout)
client = NvIngestClient(
  message_client_allocator=SimpleClient,
  message_client_port=7671,
  message_client_hostname="localhost"
)
                      
# Note: gpu_cagra accelerated indexing is not yet available in milvus-lite
# Provide a filename for milvus_uri to use milvus-lite
milvus_uri = "milvus.db"
collection_name = "test"
sparse=False
# do content extraction from files
ingestor = (
  Ingestor(client=client)
  .files("data/multimodal_test.pdf")
  .extract(
    extract_text=True,
    extract_tables=True,
    extract_charts=True,
    extract_images=True,
    paddle_output_format="markdown",
    extract_infographics=True,
    # Slower, but maximally accurate, especially for PDFs with pages that are scanned images
    #extract_method="nemoretriever_parse",
    text_depth="page"
  ).embed()
  .vdb_upload(
    collection_name=collection_name,
    milvus_uri=milvus_uri,
    sparse=sparse,
    # for llama-3.2 embedder, use 1024 for e5-v5
    dense_dim=2048
  )
)
print("Starting ingestion..")
t0 = time.time()
results = ingestor.ingest(show_progress=True)
t1 = time.time()
print(f"Time taken: {t1-t0} seconds")
# results blob is directly inspectable
print(ingest_json_results_to_blob(results[0]))
```

You can see the extracted text that represents the content of the ingested test document.
```
Starting ingestion..
Time taken: 9.243880033493042 seconds
TestingDocument
A sample document with headings and placeholder text
Introduction
This is a placeholder document that can be used for any purpose. It contains some 
headings and some placeholder text to fill the space. The text is not important and contains 
no real value, but it is useful for testing. Below, we will have some simple tables and charts 
that we can use to confirm Ingest is working as expected.
Table 1
This table describes some animals, and some activities they might be doing in specific 
locations.
Animal Activity Place
Gira@e Driving a car At the beach
Lion Putting on sunscreen At the park
Cat Jumping onto a laptop In a home o@ice
Dog Chasing a squirrel In the front yard
Chart 1
This chart shows some gadgets, and some very fictitious costs.
... document extract continues ...
```

### Step 3: Query Ingested Content
[](https://github.com/NVIDIA/nv-ingest/#step-3-query-ingested-content)
Below is an example snippet demonstrating how to query for relevant snippets of the ingested content and insert them into a basic prompt for use with an LLM to generate answers.
```
from openai import OpenAI
from nv_ingest_client.util.milvus import nvingest_retrieval
import os
milvus_uri = "milvus.db"
collection_name = "test"
sparse=False
queries = ["Which animal is responsible for the typos?"]
retrieved_docs = nvingest_retrieval(
  queries,
  collection_name,
  milvus_uri=milvus_uri,
  hybrid=sparse,
  top_k=1,
)
# simple generation example
extract = retrieved_docs[0][0]["entity"]["text"]
client = OpenAI(
 base_url = "https://integrate.api.nvidia.com/v1",
 api_key = os.environ["NVIDIA_BUILD_API_KEY"]
)
prompt = f"Using the following content: {extract}\n\n Answer the user query: {queries[0]}"
print(f"Prompt: {prompt}")
completion = client.chat.completions.create(
 model="nvidia/llama-3.1-nemotron-70b-instruct",
 messages=[{"role":"user","content": prompt}],
)
response = completion.choices[0].message.content
print(f"Answer: {response}")
```

```
Prompt: Using the following content: TestingDocument
A sample document with headings and placeholder text
Introduction
This is a placeholder document that can be used for any purpose. It contains some 
headings and some placeholder text to fill the space. The text is not important and contains 
no real value, but it is useful for testing. Below, we will have some simple tables and charts 
that we can use to confirm Ingest is working as expected.
Table 1
This table describes some animals, and some activities they might be doing in specific 
locations.
Animal Activity Place
Gira@e Driving a car At the beach
Lion Putting on sunscreen At the park
Cat Jumping onto a laptop In a home o@ice
Dog Chasing a squirrel In the front yard
Chart 1
This chart shows some gadgets, and some very fictitious costs.
 Answer the user query: Which animal is responsible for the typos?
Answer: A clever query!
After carefully examining the provided content, I'd like to point out the potential "typos" (assuming you're referring to the unusual or intentionally incorrect text) and attempt to playfully "assign blame" to an animal based on the context:
1. **Gira@e** (instead of Giraffe) - **Animal blamed: Giraffe** (Table 1, first row)
	* The "@" symbol in "Gira@e" suggests a possible typo or placeholder character, which we'll humorously attribute to the Giraffe's alleged carelessness.
2. **o@ice** (instead of Office) - **Animal blamed: Cat**
	* The same "@" symbol appears in "o@ice", which is related to the Cat's activity in the same table. Perhaps the Cat was in a hurry while typing and introduced the error?
So, according to this whimsical analysis, both the **Giraffe** and the **Cat** are "responsible" for the typos, with the Giraffe possibly being the more egregious offender given the more blatant character substitution in its name.
```

For more information, please check out the [official documentation](https://docs.nvidia.com/nemo/retriever/extraction/overview/).
Tip
Beyond inspecting the results, you can read them into things like [llama-index](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/examples/llama_index_multimodal_rag.ipynb) or [langchain](https://github.com/NVIDIA/nv-ingest/blob/release/25.3.0/examples/langchain_multimodal_rag.ipynb) retrieval pipelines.
Please also checkout our [demo using a retrieval pipeline on build.nvidia.com](https://build.nvidia.com/nvidia/multimodal-pdf-data-extraction-for-enterprise-rag) to query over document content pre-extracted w/ NVIDIA Ingest.
## Repo Structure
[](https://github.com/NVIDIA/nv-ingest/#repo-structure)
Beyond the relevant documentation, examples, and other links above, below is a description of the contents in this repo's folders:
  * [.github](https://github.com/NVIDIA/nv-ingest/tree/main/.github): GitHub repo configuration files
  * [api](https://github.com/NVIDIA/nv-ingest/tree/main/api): Core API python logic shared across python modules
  * [ci](https://github.com/NVIDIA/nv-ingest/tree/main/ci): Scripts used to build the NV-Ingest container and other packages
  * [client](https://github.com/NVIDIA/nv-ingest/tree/main/client): Docs and source code for the nv-ingest-cli utility
  * [conda](https://github.com/NVIDIA/nv-ingest/tree/main/conda): Conda environment and packaging definitions
  * [config](https://github.com/NVIDIA/nv-ingest/tree/main/config): Various .yaml files defining configuration for OTEL, Prometheus
  * [data](https://github.com/NVIDIA/nv-ingest/tree/main/data): Sample PDFs provided for testing convenience
  * [deploy](https://github.com/NVIDIA/nv-ingest/tree/main/deploy): Brev.dev hosted launchable
  * [docker](https://github.com/NVIDIA/nv-ingest/tree/main/docker): Houses scripts used by the nv-ingest docker container
  * [docs](https://github.com/NVIDIA/nv-ingest/tree/main/docs/docs): Various READMEs describing deployment, metadata schemas, auth and telemetry setup
  * [evaluation](https://github.com/NVIDIA/nv-ingest/tree/main/evaluation): Contains notebooks demonstrating how to test recall accuracy
  * [examples](https://github.com/NVIDIA/nv-ingest/tree/main/examples): Example notebooks, scripts, and longer-form tutorial content
  * [helm](https://github.com/NVIDIA/nv-ingest/tree/main/helm): Documentation for deploying NV-Ingest to a Kubernetes cluster via Helm chart
  * [skaffold](https://github.com/NVIDIA/nv-ingest/tree/main/skaffold): Skaffold configuration
  * [src](https://github.com/NVIDIA/nv-ingest/tree/main/src): Source code for the NV-Ingest pipelines and service
  * [.devcontainer](https://github.com/NVIDIA/nv-ingest/tree/main/.devcontainer): VSCode containers for local development
  * [tests](https://github.com/NVIDIA/nv-ingest/tree/main/tests): Unit tests for NV-Ingest


## Notices
[](https://github.com/NVIDIA/nv-ingest/#notices)
### Third Party License Notice:
[](https://github.com/NVIDIA/nv-ingest/#third-party-license-notice)
If configured to do so, this project will download and install additional third-party open source software projects. Review the license terms of these open source projects before use:
<https://pypi.org/project/pdfservices-sdk/>
  * **`INSTALL_ADOBE_SDK`**:
    * **Description** : If set to `true`, the Adobe SDK will be installed in the container at launch time. This is required if you want to use the Adobe extraction service for PDF decomposition. Please review the [license agreement](https://github.com/adobe/pdfservices-python-sdk?tab=License-1-ov-file) for the pdfservices-sdk before enabling this option.
  * **`DOWNLOAD_LLAMA_TOKENIZER`(Built With Llama):** : 
    * **Description** : The Split task uses the `meta-llama/Llama-3.2-1B` tokenizer, which will be downloaded from HuggingFace at build time if `DOWNLOAD_LLAMA_TOKENIZER` is set to `True`. Please review the [license agreement](https://huggingface.co/meta-llama/Llama-3.2-1B) for Llama 3.2 materials before using this. This is a gated model so you'll need to [request access](https://huggingface.co/meta-llama/Llama-3.2-1B) and set `HF_ACCESS_TOKEN` to your HuggingFace access token in order to use it.


### Contributing
[](https://github.com/NVIDIA/nv-ingest/#contributing)
We require that all contributors "sign-off" on their commits. This certifies that the contribution is your original work, or you have rights to submit it under the same license, or a compatible license.
Any contribution which contains commits that are not Signed-Off will not be accepted.
To sign off on a commit you simply use the --signoff (or -s) option when committing your changes:
```
$ git commit -s -m "Add cool feature."

```

This will append the following to your commit message:
```
Signed-off-by: Your Name <your@email.com>

```

#### Full text of the DCO:
[](https://github.com/NVIDIA/nv-ingest/#full-text-of-the-dco)
```
 Developer Certificate of Origin
 Version 1.1
 Copyright (C) 2004, 2006 The Linux Foundation and its contributors.
 1 Letterman Drive
 Suite D4700
 San Francisco, CA, 94129
 Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.

```

```
 Developer's Certificate of Origin 1.1
 By making a contribution to this project, I certify that:
 (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or
 (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or
 (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it.
 (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved.

```

## About
NVIDIA Ingest is an early access set of microservices for parsing hundreds of thousands of complex, messy unstructured PDFs and other enterprise documents into metadata and text to embed into retrieval systems. 
### Resources
[ Readme ](https://github.com/NVIDIA/nv-ingest/#readme-ov-file)
### License
[ Apache-2.0 license ](https://github.com/NVIDIA/nv-ingest/#Apache-2.0-1-ov-file)
### Code of conduct
[ Code of conduct ](https://github.com/NVIDIA/nv-ingest/#coc-ov-file)
### Security policy
[ Security policy ](https://github.com/NVIDIA/nv-ingest/#security-ov-file)
### Citation
Cite this repository 
Loading
Something went wrong. 
[ Activity](https://github.com/NVIDIA/nv-ingest/activity)
[ Custom properties](https://github.com/NVIDIA/nv-ingest/custom-properties)
### Stars
[ **2.6k** stars](https://github.com/NVIDIA/nv-ingest/stargazers)
### Watchers
[ **29** watching](https://github.com/NVIDIA/nv-ingest/watchers)
### Forks
[ **227** forks](https://github.com/NVIDIA/nv-ingest/forks)
[ Report repository ](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNVIDIA%2Fnv-ingest&report=NVIDIA+%28user%29)
##  [Releases 4](https://github.com/NVIDIA/nv-ingest/releases)
[ 25.3.0 Latest  Mar 16, 2025 ](https://github.com/NVIDIA/nv-ingest/releases/tag/25.3.0)
[+ 3 releases](https://github.com/NVIDIA/nv-ingest/releases)
##  [Packages 0](https://github.com/orgs/NVIDIA/packages?repo_name=nv-ingest)
No packages published 
##  [Contributors 25](https://github.com/NVIDIA/nv-ingest/graphs/contributors)
  * [ ![@jdye64](https://avatars.githubusercontent.com/u/2127235?s=64&v=4) ](https://github.com/jdye64)
  * [ ![@drobison00](https://avatars.githubusercontent.com/u/5256797?s=64&v=4) ](https://github.com/drobison00)
  * [ ![@edknv](https://avatars.githubusercontent.com/u/109497216?s=64&v=4) ](https://github.com/edknv)
  * [ ![@jperez999](https://avatars.githubusercontent.com/u/37191411?s=64&v=4) ](https://github.com/jperez999)
  * [ ![@nkmcalli](https://avatars.githubusercontent.com/u/8868032?s=64&v=4) ](https://github.com/nkmcalli)
  * [ ![@randerzander](https://avatars.githubusercontent.com/u/1692914?s=64&v=4) ](https://github.com/randerzander)
  * [ ![@ChrisJar](https://avatars.githubusercontent.com/u/13131098?s=64&v=4) ](https://github.com/ChrisJar)
  * [ ![@sosahi](https://avatars.githubusercontent.com/u/179180905?s=64&v=4) ](https://github.com/sosahi)
  * [ ![@mpenn](https://avatars.githubusercontent.com/u/9770524?s=64&v=4) ](https://github.com/mpenn)
  * [ ![@soluwalana](https://avatars.githubusercontent.com/u/558812?s=64&v=4) ](https://github.com/soluwalana)
  * [ ![@zredeaux07](https://avatars.githubusercontent.com/u/161058543?s=64&v=4) ](https://github.com/zredeaux07)
  * [ ![@jarmak-nv](https://avatars.githubusercontent.com/u/104460670?s=64&v=4) ](https://github.com/jarmak-nv)
  * [ ![@dependabot\[bot\]](https://avatars.githubusercontent.com/in/29110?s=64&v=4) ](https://github.com/apps/dependabot)
  * [ ![@guilherme-pombo](https://avatars.githubusercontent.com/u/22048961?s=64&v=4) ](https://github.com/guilherme-pombo)


[+ 11 contributors](https://github.com/NVIDIA/nv-ingest/graphs/contributors)
## Languages
  * [ Python 67.3% ](https://github.com/NVIDIA/nv-ingest/search?l=python)
  * [ Jupyter Notebook 31.8% ](https://github.com/NVIDIA/nv-ingest/search?l=jupyter-notebook)
  * Other 0.9%


## Footer
[ ](https://github.com "GitHub") Â© 2025 GitHub, Inc. 
### Footer navigation
  * [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
  * [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
  * [Security](https://github.com/security)
  * [Status](https://www.githubstatus.com/)
  * [Docs](https://docs.github.com/)
  * [Contact](https://support.github.com?tags=dotcom-footer)
  * Manage cookies 
  * Do not share my personal information 


You canât perform that action at this time. 
