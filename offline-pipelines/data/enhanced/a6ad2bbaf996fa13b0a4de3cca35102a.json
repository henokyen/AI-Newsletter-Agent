{
    "id": "a6ad2bbaf996fa13b0a4de3cca35102a",
    "metadata": {
        "id": "a6ad2bbaf996fa13b0a4de3cca35102a",
        "url": "https://teetracker.medium.com/langchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83/",
        "title": "LangChain / Llama-Index: RAG with Multi-Query Retrieval | by TeeTracker | Medium",
        "properties": {
            "description": "Enhance query context with intermediate queries during RAG to improve information retrieval for the original query. Query expansion works by extending the original query with additional terms or…",
            "keywords": null,
            "author": "TeeTracker",
            "og:site_name": "Medium",
            "og:type": "article",
            "og:title": "LangChain / Llama-Index: RAG with Multi-Query Retrieval",
            "og:description": "Enhance query context with intermediate queries during RAG to improve information retrieval for the original query.",
            "og:url": "https://teetracker.medium.com/langchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83",
            "og:image": "https://miro.medium.com/v2/resize:fit:1200/1*wa27F8CbKqYtaRRGyRKy0Q.png",
            "twitter:app:name:iphone": "Medium",
            "twitter:app:id:iphone": "828256236",
            "twitter:site": "@Medium",
            "twitter:app:url:iphone": "medium://p/4e7df1a62f83",
            "twitter:image:src": "https://miro.medium.com/v2/resize:fit:1200/1*wa27F8CbKqYtaRRGyRKy0Q.png",
            "twitter:card": "summary_large_image",
            "twitter:creator": "@ChrisXYZhao",
            "twitter:label1": "Reading time",
            "twitter:data1": "4 min read"
        }
    },
    "parent_metadata": {
        "id": "5e8adc9ab553fe3fcaaee73987dbccdc",
        "url": "https://www.notion.so/RAG-5e8adc9ab553fe3fcaaee73987dbccdc",
        "title": "RAG",
        "properties": {
            "Type": [
                "Leaf"
            ]
        }
    },
    "content": "[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4e7df1a62f83&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n[](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n[](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n[Home](https://medium.com/?source=post_page--------------------------------------------)\nFollowing\nLibrary\n[Your lists](https://medium.com/me/lists?source=post_page--------------------------------------------)[Saved lists](https://medium.com/me/lists/saved?source=post_page--------------------------------------------)[Highlights](https://medium.com/me/list/highlights?source=post_page--------------------------------------------)[Reading history](https://medium.com/me/lists/reading-history?source=post_page--------------------------------------------)\n[Stories](https://medium.com/me/stories/drafts?source=post_page--------------------------------------------)[Stats](https://medium.com/me/stats?source=post_page--------------------------------------------)\n# LangChain / Llama-Index: RAG with Multi-Query Retrieval\n[![TeeTracker](https://miro.medium.com/v2/resize:fill:88:88/1*yYq5U3pKuZKMAs0UTQc_HA.png)](https://teetracker.medium.com/?source=post_page---byline--4e7df1a62f83---------------------------------------)\n[TeeTracker](https://teetracker.medium.com/?source=post_page---byline--4e7df1a62f83---------------------------------------)\n·\n[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F984171777958&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=post_page-984171777958--byline--4e7df1a62f83---------------------post_header------------------)\n4 min read\n·\nFeb 14, 2024\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---header_actions--4e7df1a62f83---------------------clap_footer------------------)\n--\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---header_actions--4e7df1a62f83---------------------bookmark_footer------------------)\nListen\nShare\nEnhance query context with intermediate queries during RAG to improve information retrieval for the original query.\n# Query Expansion\nQuery expansion works by extending the original query with additional terms or phrases that are related or synonymous.\n**Multi-Query Retrieva** l is a type of query expansion.\n# Mechanisms\nWhen I input a query request, we first use a large language model to generate a similar query. I will use a similar query to retrieve relevant documents (nodes in the llama-index). This retrieved information will be used to query the context of the original query.\n![](https://miro.medium.com/v2/resize:fit:700/1*wa27F8CbKqYtaRRGyRKy0Q.png)\n## 2 times LLM interactions\nTo generate queries, we need to make additional parallel requests to LLM. This means adding a total of 2 requests, with the option of using gpt3 as the first request and gpt4 or better for the final one.\n# Implementation method\n## LangChain\n```\nloader = UnstructuredPDFLoader(FILE_NAME)docs = loader.load()text_splitter = SentenceTransformersTokenTextSplitter()texts = text_splitter.split_documents(docs)emb = OpenAIEmbeddings(openai_api_key=openai.api_key)vec_db = Chroma.from_documents(documents=texts, embedding=emb)lc_model = ChatOpenAI(openai_api_key=openai.api_key, temperature=1.5)base_retriever = vec_db.as_retriever(k=K)final_retriever = MultiQueryRetriever.from_llm(base_retriever, lc_model)tmpl = \"\"\"You are an assistant to answer a question from user with a context.Context:{context}Question:{question}The response should be presented as a list of key points, after creating the title of the content,  formatted in HTML with appropriate markup for clarity and organization.\"\"\"prompt = ChatPromptTemplate.from_template(tmpl)chain = {\"question\": RunnablePassthrough(), \"context\": final_retriever} \\    | prompt \\    | lc_model \\    | StrOutputParser() \\result = chain.invoke(\"Waht is the doc talking about?\") \n```\n\n**MultiQueryRetriever** provides ready-made classes to accomplish this task. The key point is to provide a**base retriever**. All “generated queries” will be automatically implemented, by default 3 of them. Their retrieval process will also be securely encapsulated.\nAs you can see in the [colab](https://colab.research.google.com/drive/1HKv85boODXbU944s3tanL-nBRwin7JAq?usp=sharing), You will observe the intermediate generated queries such as:\n```\nINFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the main topic discussed in the document?', '2. Could you provide a brief summary of the subject matter of the document?', '3. What does the document primarily cover and discuss?']\n```\n\nThose queries will be used later to retrieve the relevant from the indices.\n## Llama-Index\nThe implementation of Llama-Index is quite tricky because we have to manually generate “generated queries” and their retrieval process is manually implemented. Since there are multiple queries, we will use the necessary coroutine mechanism.\n```\nvector_index: BaseIndex = VectorStoreIndex.from_documents(  docs,  service_context=service_context,   show_progress=True,)base_retriever = vector_index.as_retriever(similarity_top_k=K)class MultiQueriesRetriever(BaseRetriever):  def __init__(self, base_retriever: BaseRetriever, model:OpenAI):    self.template = PromptTemplate(\"\"\"You are an AI language model assistant. Your task is to generate Five  different versions of the given user question to retrieve relevant documents from a vector  database. By generating multiple perspectives on the user question, your goal is to help  the user overcome some of the limitations of the distance-based similarity search.  Provide these alternative questions seperated by newlines.  Original question: {question}\"\"\")    self._retrievers = [base_retriever]    self.base_retriever = base_retriever    self.model = model    def gen_queries(self, query) -> List[str]:    gen_queries_model = OpenAI(model=\"gpt-3-turbo\", temperature=1.5)    prompt = self.template.format(question=query)    res = self.model.complete(prompt)    return res.text.split(\"\\n\")  async def run_gen_queries(self,generated_queries: List[str]) -> List[NodeWithScore]:    tasks = list(map(lambda q: self.base_retriever.aretrieve(q), generated_queries))     res = await tqdm.gather(*tasks)    return res[0]  def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:    return list()  async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:    query = query_bundle.query_str    generated_queries = self.gen_queries(query)    query_res = await self.run_gen_queries(generated_queries)    return query_res  mr = MultiQueriesRetriever(base_retriever, li_model)final_res = await RetrieverQueryEngine(mr).aquery(query_text)\n```\n\nThe key point is that we inherit BaseRetriever, which means we combine it with a base retriever to query relevant information based on generated queries. _aretrieve must be overridden because generated queries are implemented through coroutine. No further details are explained here.\nFurthermore, you have the opportunity to view the queries that were generated at an intermediate stage, if you print.\n## SubQuestionQueryEngine\nLlama-Index provides a class called **SubQuestionQueryEngine** that basically meets our needs, the difference is, it’s break-down, not generate a “similar” query. According to the documentation, you can use the following code:\n```\nquery_engine_tools = [  QueryEngineTool(    query_engine=vector_query_engine,    metadata=ToolMetadata(      name=\"pg_essay\",      description=\"Paul Graham essay on What I Worked On\",    ),  ),]query_engine = SubQuestionQueryEngine.from_defaults(  query_engine_tools=query_engine_tools,  use_async=True,)response = query_engine.query(  \"How was Paul Grahams life different before, during, and after YC?\")\n```\n\n[Full notebook](https://github.com/run-llama/llama_index/blob/main/docs/examples/query_engine/sub_question_query_engine.ipynb)\nThe **SubQuestionQueryEngine** works by**breaking down** the original query into sub-questions, each of which is directed to a relevant data source. The intermediate answers from these sub-questions are used **to provide context** and **contribute to the overall answer**. Each sub-question is designed to extract a specific piece of information from the data source it is directed to. The responses to these sub-questions are then combined to form a comprehensive answer to the original query.\nOn the other hand, the **SubQuestionQueryEngine** breaks down a complex query into many sub-questions and their target query engine for execution. After executing all sub-questions, _all responses are gathered and sent to a response synthesizer to produce the final response_. The **SubQuestionQueryEngine** decides which **QueryEngineTool** to use for each sub-question based on the **tool_name** attribute of the SubQuestion object.\n# Code\n[colab](https://github.com/XinyueZ/chat-your-doc/blob/master/notebooks/multi_queries_retrieval.ipynb)\n[direct-run](https://colab.research.google.com/drive/1HKv85boODXbU944s3tanL-nBRwin7JAq?usp=sharing)\n![](https://miro.medium.com/v2/da:true/resize:fit:0/5c50caa54067fd622d2f0fac18392213bf92f6e2fae89b691e62bceb40885e74)\n## Sign up to discover human stories that deepen your understanding of the world.\n## Free\nDistraction-free reading. No ads.\nOrganize your knowledge with lists and highlights.\nTell your story. Find your audience.\nSign up for free\n## Membership\nRead member-only stories\nSupport writers you read most\nEarn money for your writing\nListen to audio narrations\nRead offline with the Medium app\nTry for $5/month\n[Langchain](https://medium.com/tag/langchain?source=post_page-----4e7df1a62f83---------------------------------------)\n[Llamaindex](https://medium.com/tag/llamaindex?source=post_page-----4e7df1a62f83---------------------------------------)\n[Retrieval Augmented](https://medium.com/tag/retrieval-augmented?source=post_page-----4e7df1a62f83---------------------------------------)\n[AI](https://medium.com/tag/ai?source=post_page-----4e7df1a62f83---------------------------------------)\n[Artificial Intelligence](https://medium.com/tag/artificial-intelligence?source=post_page-----4e7df1a62f83---------------------------------------)\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---footer_actions--4e7df1a62f83---------------------clap_footer------------------)\n--\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---footer_actions--4e7df1a62f83---------------------clap_footer------------------)\n--\n[](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---footer_actions--4e7df1a62f83---------------------bookmark_footer------------------)\n[![TeeTracker](https://miro.medium.com/v2/resize:fill:96:96/1*yYq5U3pKuZKMAs0UTQc_HA.png)](https://teetracker.medium.com/?source=post_page---post_author_info--4e7df1a62f83---------------------------------------)\n[![TeeTracker](https://miro.medium.com/v2/resize:fill:128:128/1*yYq5U3pKuZKMAs0UTQc_HA.png)](https://teetracker.medium.com/?source=post_page---post_author_info--4e7df1a62f83---------------------------------------)\nFollow\n## [Written by TeeTracker](https://teetracker.medium.com/?source=post_page---post_author_info--4e7df1a62f83---------------------------------------)\n[438 Followers](https://teetracker.medium.com/followers?source=post_page---post_author_info--4e7df1a62f83---------------------------------------)\n·[87 Following](https://teetracker.medium.com/following?source=post_page---post_author_info--4e7df1a62f83---------------------------------------)\nAI advocate // All about AI\nFollow\n## No responses yet\n[](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--4e7df1a62f83---------------------------------------)\n![](https://miro.medium.com/v2/resize:fill:32:32/1*dmbNkD5D-u45r44go_cf0g.png)\nWrite a response\n[What are your thoughts?](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---post_responses--4e7df1a62f83---------------------respond_sidebar------------------)\nCancel\nRespond\nAlso publish to my profile\n[Help](https://help.medium.com/hc/en-us?source=post_page-----4e7df1a62f83---------------------------------------)\n[Status](https://medium.statuspage.io/?source=post_page-----4e7df1a62f83---------------------------------------)\n[About](https://medium.com/about?autoplay=1&source=post_page-----4e7df1a62f83---------------------------------------)\n[Careers](https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4e7df1a62f83---------------------------------------)\nPress\n[Blog](https://blog.medium.com/?source=post_page-----4e7df1a62f83---------------------------------------)\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4e7df1a62f83---------------------------------------)\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----4e7df1a62f83---------------------------------------)\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4e7df1a62f83---------------------------------------)\n[Text to speech](https://speechify.com/medium?source=post_page-----4e7df1a62f83---------------------------------------)\n",
    "content_quality_score": 0.1,
    "summary": null,
    "child_urls": [
        "https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=post_page---top_nav_layout_nav-----------------------global_nav------------------",
        "https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------",
        "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------",
        "https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------",
        "https://medium.com/?source=post_page--------------------------------------------",
        "https://medium.com/me/lists?source=post_page--------------------------------------------",
        "https://medium.com/me/lists/saved?source=post_page--------------------------------------------",
        "https://medium.com/me/list/highlights?source=post_page--------------------------------------------",
        "https://medium.com/me/lists/reading-history?source=post_page--------------------------------------------",
        "https://medium.com/me/stories/drafts?source=post_page--------------------------------------------",
        "https://medium.com/me/stats?source=post_page--------------------------------------------",
        "https://teetracker.medium.com/?source=post_page---byline--4e7df1a62f83---------------------------------------",
        "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F984171777958&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=post_page-984171777958--byline--4e7df1a62f83---------------------post_header------------------",
        "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---header_actions--4e7df1a62f83---------------------clap_footer------------------",
        "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---header_actions--4e7df1a62f83---------------------bookmark_footer------------------",
        "https://medium.com/tag/langchain?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/tag/llamaindex?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/tag/retrieval-augmented?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/tag/ai?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/tag/artificial-intelligence?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&user=TeeTracker&userId=984171777958&source=---footer_actions--4e7df1a62f83---------------------clap_footer------------------",
        "https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F4e7df1a62f83&operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---footer_actions--4e7df1a62f83---------------------bookmark_footer------------------",
        "https://teetracker.medium.com/?source=post_page---post_author_info--4e7df1a62f83---------------------------------------",
        "https://teetracker.medium.com/followers?source=post_page---post_author_info--4e7df1a62f83---------------------------------------",
        "https://teetracker.medium.com/following?source=post_page---post_author_info--4e7df1a62f83---------------------------------------",
        "https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page---post_responses--4e7df1a62f83---------------------------------------",
        "https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fteetracker.medium.com%2Flangchain-llama-index-rag-with-multi-query-retrieval-4e7df1a62f83&source=---post_responses--4e7df1a62f83---------------------respond_sidebar------------------",
        "https://help.medium.com/hc/en-us?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/about?autoplay=1&source=post_page-----4e7df1a62f83---------------------------------------",
        "https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://blog.medium.com/?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----4e7df1a62f83---------------------------------------",
        "https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F4e7df1a62f83&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&source=post_page---top_nav_layout_nav-----------------------------------------",
        "https://colab.research.google.com/drive/1HKv85boODXbU944s3tanL-nBRwin7JAq?usp=sharing",
        "https://github.com/run-llama/llama_index/blob/main/docs/examples/query_engine/sub_question_query_engine.ipynb",
        "https://github.com/XinyueZ/chat-your-doc/blob/master/notebooks/multi_queries_retrieval.ipynb",
        "https://medium.statuspage.io/?source=post_page-----4e7df1a62f83---------------------------------------",
        "mailto:pressinquiries@medium.com",
        "https://speechify.com/medium?source=post_page-----4e7df1a62f83---------------------------------------"
    ]
}